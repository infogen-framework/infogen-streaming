[framework] 2015-12-18 14:53:23,737 - com.infogen.hdfs.InfoGen_LZOOutputStream -4297 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/-0.4641635
[framework] 2015-12-18 14:53:23,934 - com.hadoop.compression.lzo.GPLNativeCodeLoader -4494 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-18 14:53:23,936 - com.hadoop.compression.lzo.LzoCodec -4496 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-18 14:53:23,938 - org.apache.hadoop.conf.Configuration.deprecation -4498 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-18 14:53:23,940 - org.apache.hadoop.io.compress.CodecPool -4500 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:24,088 - com.infogen.hdfs.InfoGen_LZOOutputStream -4648 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/18/-0.4642557
[framework] 2015-12-18 14:53:24,163 - org.apache.hadoop.io.compress.CodecPool -4723 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:24,270 - com.infogen.hdfs.InfoGen_LZOOutputStream -4830 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/19/-0.4643236
[framework] 2015-12-18 14:53:24,346 - org.apache.hadoop.io.compress.CodecPool -4906 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:24,437 - com.infogen.hdfs.InfoGen_LZOOutputStream -4997 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/20/-0.4643751
[framework] 2015-12-18 14:53:24,514 - org.apache.hadoop.io.compress.CodecPool -5074 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:24,586 - com.infogen.hdfs.InfoGen_LZOOutputStream -5146 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/21/-0.4643763
[framework] 2015-12-18 14:53:24,655 - org.apache.hadoop.io.compress.CodecPool -5215 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:24,726 - com.infogen.hdfs.InfoGen_LZOOutputStream -5286 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/22/-0.4643788
[framework] 2015-12-18 14:53:24,807 - org.apache.hadoop.io.compress.CodecPool -5367 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:24,886 - com.infogen.hdfs.InfoGen_LZOOutputStream -5446 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/23/-0.4643803
[framework] 2015-12-18 14:53:24,968 - org.apache.hadoop.io.compress.CodecPool -5528 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:25,044 - com.infogen.hdfs.InfoGen_LZOOutputStream -5604 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/0/-0.4643825
[framework] 2015-12-18 14:53:25,122 - org.apache.hadoop.io.compress.CodecPool -5682 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:25,185 - com.infogen.hdfs.InfoGen_LZOOutputStream -5745 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/1/-0.4643833
[framework] 2015-12-18 14:53:25,265 - org.apache.hadoop.io.compress.CodecPool -5825 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:25,335 - com.infogen.hdfs.InfoGen_LZOOutputStream -5895 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/2/-0.4643855
[framework] 2015-12-18 14:53:25,513 - org.apache.hadoop.io.compress.CodecPool -6073 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:25,585 - com.infogen.hdfs.InfoGen_LZOOutputStream -6145 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/3/-0.4643857
[framework] 2015-12-18 14:53:25,667 - org.apache.hadoop.io.compress.CodecPool -6227 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:25,982 - com.infogen.hdfs.InfoGen_LZOOutputStream -6542 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/4/-0.4643858
[framework] 2015-12-18 14:53:26,063 - org.apache.hadoop.io.compress.CodecPool -6623 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:26,122 - com.infogen.hdfs.InfoGen_LZOOutputStream -6682 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/6/-0.4643860
[framework] 2015-12-18 14:53:26,196 - org.apache.hadoop.io.compress.CodecPool -6756 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:26,269 - com.infogen.hdfs.InfoGen_LZOOutputStream -6829 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/7/-0.4643868
[framework] 2015-12-18 14:53:26,350 - org.apache.hadoop.io.compress.CodecPool -6910 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:28,586 - com.infogen.hdfs.InfoGen_LZOOutputStream -9146 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/8/-0.4661716
[framework] 2015-12-18 14:53:28,668 - org.apache.hadoop.io.compress.CodecPool -9228 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:28,767 - com.infogen.hdfs.InfoGen_LZOOutputStream -9327 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/9/-0.4661724
[framework] 2015-12-18 14:53:28,921 - org.apache.hadoop.io.compress.CodecPool -9481 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:28,989 - com.infogen.hdfs.InfoGen_LZOOutputStream -9549 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/10/-0.4661915
[framework] 2015-12-18 14:53:29,080 - org.apache.hadoop.io.compress.CodecPool -9640 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:29,150 - com.infogen.hdfs.InfoGen_LZOOutputStream -9710 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/11/-0.4662395
[framework] 2015-12-18 14:53:29,230 - org.apache.hadoop.io.compress.CodecPool -9790 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:29,302 - com.infogen.hdfs.InfoGen_LZOOutputStream -9862 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/12/-0.4662765
[framework] 2015-12-18 14:53:29,418 - org.apache.hadoop.io.compress.CodecPool -9978 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:29,518 - com.infogen.hdfs.InfoGen_LZOOutputStream -10078 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/13/-0.4662775
[framework] 2015-12-18 14:53:29,611 - org.apache.hadoop.io.compress.CodecPool -10171 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:29,680 - com.infogen.hdfs.InfoGen_LZOOutputStream -10240 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/14/-0.4662908
[framework] 2015-12-18 14:53:29,851 - org.apache.hadoop.io.compress.CodecPool -10411 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:30,952 - com.infogen.hdfs.InfoGen_LZOOutputStream -11512 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/15/-0.4663451
[framework] 2015-12-18 14:53:31,040 - org.apache.hadoop.io.compress.CodecPool -11600 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:31,102 - com.infogen.hdfs.InfoGen_LZOOutputStream -11662 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/16/-0.4663753
[framework] 2015-12-18 14:53:31,185 - org.apache.hadoop.io.compress.CodecPool -11745 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:31,252 - com.infogen.hdfs.InfoGen_LZOOutputStream -11812 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/17/-0.4664228
[framework] 2015-12-18 14:53:31,373 - org.apache.hadoop.io.compress.CodecPool -11933 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:31,443 - com.infogen.hdfs.InfoGen_LZOOutputStream -12003 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/18/-0.4665083
[framework] 2015-12-18 14:53:31,541 - org.apache.hadoop.io.compress.CodecPool -12101 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:31,615 - com.infogen.hdfs.InfoGen_LZOOutputStream -12175 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/19/-0.4665212
[framework] 2015-12-18 14:53:31,703 - org.apache.hadoop.io.compress.CodecPool -12263 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:31,776 - com.infogen.hdfs.InfoGen_LZOOutputStream -12336 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/20/-0.4665239
[framework] 2015-12-18 14:53:31,862 - org.apache.hadoop.io.compress.CodecPool -12422 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:31,926 - com.infogen.hdfs.InfoGen_LZOOutputStream -12486 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/21/-0.4665424
[framework] 2015-12-18 14:53:32,021 - org.apache.hadoop.io.compress.CodecPool -12581 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:32,086 - com.infogen.hdfs.InfoGen_LZOOutputStream -12646 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/22/-0.4665605
[framework] 2015-12-18 14:53:32,170 - org.apache.hadoop.io.compress.CodecPool -12730 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:32,238 - com.infogen.hdfs.InfoGen_LZOOutputStream -12798 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/23/-0.4665630
[framework] 2015-12-18 14:53:32,366 - org.apache.hadoop.io.compress.CodecPool -12926 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:32,442 - com.infogen.hdfs.InfoGen_LZOOutputStream -13002 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/0/-0.4665650
[framework] 2015-12-18 14:53:32,526 - org.apache.hadoop.io.compress.CodecPool -13086 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:32,596 - com.infogen.hdfs.InfoGen_LZOOutputStream -13156 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/1/-0.4665716
[framework] 2015-12-18 14:53:32,672 - org.apache.hadoop.io.compress.CodecPool -13232 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:32,734 - com.infogen.hdfs.InfoGen_LZOOutputStream -13294 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/3/-0.4665722
[framework] 2015-12-18 14:53:32,820 - org.apache.hadoop.io.compress.CodecPool -13380 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:32,914 - com.infogen.hdfs.InfoGen_LZOOutputStream -13474 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/4/-0.4665727
[framework] 2015-12-18 14:53:33,028 - org.apache.hadoop.io.compress.CodecPool -13588 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:33,095 - com.infogen.hdfs.InfoGen_LZOOutputStream -13655 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/6/-0.4665730
[framework] 2015-12-18 14:53:33,178 - org.apache.hadoop.io.compress.CodecPool -13738 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:33,253 - com.infogen.hdfs.InfoGen_LZOOutputStream -13813 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/7/-0.4665733
[framework] 2015-12-18 14:53:33,346 - org.apache.hadoop.io.compress.CodecPool -13906 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:36,305 - com.infogen.hdfs.InfoGen_LZOOutputStream -16865 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/8/-0.4683311
[framework] 2015-12-18 14:53:36,386 - org.apache.hadoop.io.compress.CodecPool -16946 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:36,450 - com.infogen.hdfs.InfoGen_LZOOutputStream -17010 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/9/-0.4683320
[framework] 2015-12-18 14:53:36,527 - org.apache.hadoop.io.compress.CodecPool -17087 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:36,585 - com.infogen.hdfs.InfoGen_LZOOutputStream -17145 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/10/-0.4683732
[framework] 2015-12-18 14:53:36,727 - org.apache.hadoop.io.compress.CodecPool -17287 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:36,789 - com.infogen.hdfs.InfoGen_LZOOutputStream -17349 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/11/-0.4684410
[framework] 2015-12-18 14:53:36,906 - org.apache.hadoop.io.compress.CodecPool -17466 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:36,963 - com.infogen.hdfs.InfoGen_LZOOutputStream -17523 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/12/-0.4684675
[framework] 2015-12-18 14:53:37,153 - org.apache.hadoop.io.compress.CodecPool -17713 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:37,219 - com.infogen.hdfs.InfoGen_LZOOutputStream -17779 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/13/-0.4684765
[framework] 2015-12-18 14:53:37,310 - org.apache.hadoop.io.compress.CodecPool -17870 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:38,725 - com.infogen.hdfs.InfoGen_LZOOutputStream -19285 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/14/-0.4684950
[framework] 2015-12-18 14:53:38,827 - org.apache.hadoop.io.compress.CodecPool -19387 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:38,906 - com.infogen.hdfs.InfoGen_LZOOutputStream -19466 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/15/-0.4685295
[framework] 2015-12-18 14:53:38,986 - org.apache.hadoop.io.compress.CodecPool -19546 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:39,078 - com.infogen.hdfs.InfoGen_LZOOutputStream -19638 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/16/-0.4686939
[framework] 2015-12-18 14:53:39,161 - org.apache.hadoop.io.compress.CodecPool -19721 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:39,243 - com.infogen.hdfs.InfoGen_LZOOutputStream -19803 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/17/-0.4687810
[framework] 2015-12-18 14:53:39,539 - org.apache.hadoop.io.compress.CodecPool -20099 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:39,626 - com.infogen.hdfs.InfoGen_LZOOutputStream -20186 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/18/-0.4689182
[framework] 2015-12-18 14:53:39,702 - org.apache.hadoop.io.compress.CodecPool -20262 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:39,799 - com.infogen.hdfs.InfoGen_LZOOutputStream -20359 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/19/-0.4689903
[framework] 2015-12-18 14:53:39,886 - org.apache.hadoop.io.compress.CodecPool -20446 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:39,978 - com.infogen.hdfs.InfoGen_LZOOutputStream -20538 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/20/-0.4690044
[framework] 2015-12-18 14:53:40,061 - org.apache.hadoop.io.compress.CodecPool -20621 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:40,160 - com.infogen.hdfs.InfoGen_LZOOutputStream -20720 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/21/-0.4690193
[framework] 2015-12-18 14:53:40,477 - org.apache.hadoop.io.compress.CodecPool -21037 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:40,575 - com.infogen.hdfs.InfoGen_LZOOutputStream -21135 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/22/-0.4690343
[framework] 2015-12-18 14:53:40,916 - org.apache.hadoop.io.compress.CodecPool -21476 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:40,983 - com.infogen.hdfs.InfoGen_LZOOutputStream -21543 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/23/-0.4690476
[framework] 2015-12-18 14:53:41,056 - org.apache.hadoop.io.compress.CodecPool -21616 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:41,124 - com.infogen.hdfs.InfoGen_LZOOutputStream -21684 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/0/-0.4690601
[framework] 2015-12-18 14:53:41,202 - org.apache.hadoop.io.compress.CodecPool -21762 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:41,318 - com.infogen.hdfs.InfoGen_LZOOutputStream -21878 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/1/-0.4690719
[framework] 2015-12-18 14:53:41,483 - org.apache.hadoop.io.compress.CodecPool -22043 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:41,555 - com.infogen.hdfs.InfoGen_LZOOutputStream -22115 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/2/-0.4690833
[framework] 2015-12-18 14:53:41,782 - org.apache.hadoop.io.compress.CodecPool -22342 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:41,872 - com.infogen.hdfs.InfoGen_LZOOutputStream -22432 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/3/-0.4690938
[framework] 2015-12-18 14:53:42,059 - org.apache.hadoop.io.compress.CodecPool -22619 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:42,357 - com.infogen.hdfs.InfoGen_LZOOutputStream -22917 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/4/-0.4691052
[framework] 2015-12-18 14:53:42,466 - org.apache.hadoop.io.compress.CodecPool -23026 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:42,534 - com.infogen.hdfs.InfoGen_LZOOutputStream -23094 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/5/-0.4691140
[framework] 2015-12-18 14:53:42,674 - org.apache.hadoop.io.compress.CodecPool -23234 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:42,737 - com.infogen.hdfs.InfoGen_LZOOutputStream -23297 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/6/-0.4691250
[framework] 2015-12-18 14:53:42,808 - org.apache.hadoop.io.compress.CodecPool -23368 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:42,877 - com.infogen.hdfs.InfoGen_LZOOutputStream -23437 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/7/-0.4691361
[framework] 2015-12-18 14:53:42,949 - org.apache.hadoop.io.compress.CodecPool -23509 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:43,019 - com.infogen.hdfs.InfoGen_LZOOutputStream -23579 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/8/-0.4691454
[framework] 2015-12-18 14:53:43,098 - org.apache.hadoop.io.compress.CodecPool -23658 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:43,182 - com.infogen.hdfs.InfoGen_LZOOutputStream -23742 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/9/-0.4691576
[framework] 2015-12-18 14:53:43,274 - org.apache.hadoop.io.compress.CodecPool -23834 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:43,336 - com.infogen.hdfs.InfoGen_LZOOutputStream -23896 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/10/-0.4691790
[framework] 2015-12-18 14:53:43,641 - org.apache.hadoop.io.compress.CodecPool -24201 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:43,723 - com.infogen.hdfs.InfoGen_LZOOutputStream -24283 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/11/-0.4692128
[framework] 2015-12-18 14:53:43,817 - org.apache.hadoop.io.compress.CodecPool -24377 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:45,196 - com.infogen.hdfs.InfoGen_LZOOutputStream -25756 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/12/-0.4695448
[framework] 2015-12-18 14:53:45,284 - org.apache.hadoop.io.compress.CodecPool -25844 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:47,827 - com.infogen.hdfs.InfoGen_LZOOutputStream -28387 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/13/-0.4707441
[framework] 2015-12-18 14:53:47,953 - org.apache.hadoop.io.compress.CodecPool -28513 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:48,021 - com.infogen.hdfs.InfoGen_LZOOutputStream -28581 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/14/-0.4708847
[framework] 2015-12-18 14:53:48,096 - org.apache.hadoop.io.compress.CodecPool -28656 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:48,157 - com.infogen.hdfs.InfoGen_LZOOutputStream -28717 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/15/-0.4709940
[framework] 2015-12-18 14:53:48,254 - org.apache.hadoop.io.compress.CodecPool -28814 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:48,317 - com.infogen.hdfs.InfoGen_LZOOutputStream -28877 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/16/-0.4711460
[framework] 2015-12-18 14:53:48,632 - org.apache.hadoop.io.compress.CodecPool -29192 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:48,718 - com.infogen.hdfs.InfoGen_LZOOutputStream -29278 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/17/-0.4713722
[framework] 2015-12-18 14:53:49,489 - org.apache.hadoop.io.compress.CodecPool -30049 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:50,162 - com.infogen.hdfs.InfoGen_LZOOutputStream -30722 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/18/-0.4715104
[framework] 2015-12-18 14:53:50,255 - org.apache.hadoop.io.compress.CodecPool -30815 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:50,318 - com.infogen.hdfs.InfoGen_LZOOutputStream -30878 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/19/-0.4715526
[framework] 2015-12-18 14:53:50,410 - org.apache.hadoop.io.compress.CodecPool -30970 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:50,484 - com.infogen.hdfs.InfoGen_LZOOutputStream -31044 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/20/-0.4715998
[framework] 2015-12-18 14:53:50,564 - org.apache.hadoop.io.compress.CodecPool -31124 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:50,656 - com.infogen.hdfs.InfoGen_LZOOutputStream -31216 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/21/-0.4716505
[framework] 2015-12-18 14:53:50,755 - org.apache.hadoop.io.compress.CodecPool -31315 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:50,822 - com.infogen.hdfs.InfoGen_LZOOutputStream -31382 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/22/-0.4716543
[framework] 2015-12-18 14:53:50,913 - org.apache.hadoop.io.compress.CodecPool -31473 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:51,899 - com.infogen.hdfs.InfoGen_LZOOutputStream -32459 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/23/-0.4716567
[framework] 2015-12-18 14:53:51,989 - org.apache.hadoop.io.compress.CodecPool -32549 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:52,292 - com.infogen.hdfs.InfoGen_LZOOutputStream -32852 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/0/-0.4716603
[framework] 2015-12-18 14:53:52,398 - org.apache.hadoop.io.compress.CodecPool -32958 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:52,465 - com.infogen.hdfs.InfoGen_LZOOutputStream -33025 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/1/-0.4716624
[framework] 2015-12-18 14:53:52,568 - org.apache.hadoop.io.compress.CodecPool -33128 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:52,857 - com.infogen.hdfs.InfoGen_LZOOutputStream -33417 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/2/-0.4716639
[framework] 2015-12-18 14:53:52,947 - org.apache.hadoop.io.compress.CodecPool -33507 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:53,019 - com.infogen.hdfs.InfoGen_LZOOutputStream -33579 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/3/-0.4716654
[framework] 2015-12-18 14:53:53,355 - org.apache.hadoop.io.compress.CodecPool -33915 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:53,431 - com.infogen.hdfs.InfoGen_LZOOutputStream -33991 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/4/-0.4716666
[framework] 2015-12-18 14:53:53,613 - org.apache.hadoop.io.compress.CodecPool -34173 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:53,680 - com.infogen.hdfs.InfoGen_LZOOutputStream -34240 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/5/-0.4716671
[framework] 2015-12-18 14:53:53,898 - org.apache.hadoop.io.compress.CodecPool -34458 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:53,970 - com.infogen.hdfs.InfoGen_LZOOutputStream -34530 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/6/-0.4716679
[framework] 2015-12-18 14:53:54,309 - org.apache.hadoop.io.compress.CodecPool -34869 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:54,377 - com.infogen.hdfs.InfoGen_LZOOutputStream -34937 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/7/-0.4716687
[framework] 2015-12-18 14:53:54,474 - org.apache.hadoop.io.compress.CodecPool -35034 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:54,539 - com.infogen.hdfs.InfoGen_LZOOutputStream -35099 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/8/-0.4716704
[framework] 2015-12-18 14:53:54,663 - org.apache.hadoop.io.compress.CodecPool -35223 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:54,725 - com.infogen.hdfs.InfoGen_LZOOutputStream -35285 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/9/-0.4716728
[framework] 2015-12-18 14:53:54,890 - org.apache.hadoop.io.compress.CodecPool -35450 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:55,183 - com.infogen.hdfs.InfoGen_LZOOutputStream -35743 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/10/-0.4717077
[framework] 2015-12-18 14:53:55,272 - org.apache.hadoop.io.compress.CodecPool -35832 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:55,403 - com.infogen.hdfs.InfoGen_LZOOutputStream -35963 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/11/-0.4717494
[framework] 2015-12-18 14:53:55,488 - org.apache.hadoop.io.compress.CodecPool -36048 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:55,571 - com.infogen.hdfs.InfoGen_LZOOutputStream -36131 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/12/-0.4718108
[framework] 2015-12-18 14:53:55,704 - org.apache.hadoop.io.compress.CodecPool -36264 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:55,778 - com.infogen.hdfs.InfoGen_LZOOutputStream -36338 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/13/-0.4718207
[framework] 2015-12-18 14:53:55,863 - org.apache.hadoop.io.compress.CodecPool -36423 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 14:53:55,932 - com.infogen.hdfs.InfoGen_LZOOutputStream -36492 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/14/-0.4718242
[framework] 2015-12-18 14:53:56,307 - org.apache.hadoop.io.compress.CodecPool -36867 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:22:59,191 - com.infogen.zookeeper.InfoGen_ZooKeeper -0    [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-18 15:22:59,233 - org.apache.zookeeper.ZooKeeper -42   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[framework] 2015-12-18 15:22:59,233 - org.apache.zookeeper.ZooKeeper -42   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:host.name=localhost
[framework] 2015-12-18 15:22:59,233 - org.apache.zookeeper.ZooKeeper -42   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_20
[framework] 2015-12-18 15:22:59,233 - org.apache.zookeeper.ZooKeeper -42   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
[framework] 2015-12-18 15:22:59,234 - org.apache.zookeeper.ZooKeeper -43   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/lib/jvm/java-8-sun/jre
[framework] 2015-12-18 15:22:59,234 - org.apache.zookeeper.ZooKeeper -43   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/home/juxinli/workspace/infogen_etl/target/classes:/home/juxinli/workspace/infogen_etl/lib/hadoop-lzo-0.4.20-SNAPSHOT.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-client/2.7.1/hadoop-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-common/2.7.1/hadoop-common-2.7.1.jar:/home/juxinli/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/juxinli/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/juxinli/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/juxinli/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/juxinli/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/juxinli/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/juxinli/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/juxinli/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/juxinli/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/juxinli/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/juxinli/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/juxinli/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/juxinli/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/juxinli/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/juxinli/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/juxinli/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/juxinli/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.1/hadoop-auth-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/home/juxinli/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/juxinli/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/juxinli/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.1/hadoop-hdfs-2.7.1.jar:/home/juxinli/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/juxinli/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/juxinli/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/juxinli/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/juxinli/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.1/hadoop-mapreduce-client-app-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.1/hadoop-mapreduce-client-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.1/hadoop-yarn-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.1/hadoop-yarn-server-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.1/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.1/hadoop-yarn-api-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.1/hadoop-mapreduce-client-core-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.1/hadoop-yarn-common-2.7.1.jar:/home/juxinli/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/juxinli/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/juxinli/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/juxinli/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.1/hadoop-mapreduce-client-jobclient-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.1/hadoop-annotations-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka_2.11/0.8.2.2/kafka_2.11-0.8.2.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/juxinli/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar:/home/juxinli/.m2/repository/org/scala-lang/scala-library/2.11.5/scala-library-2.11.5.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.2/kafka-clients-0.8.2.2.jar:/home/juxinli/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/juxinli/.m2/repository/net/jpountz/lz4/lz4/1.2.0/lz4-1.2.0.jar:/home/juxinli/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/juxinli/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/juxinli/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/juxinli/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar
[framework] 2015-12-18 15:22:59,234 - org.apache.zookeeper.ZooKeeper -43   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[framework] 2015-12-18 15:22:59,235 - org.apache.zookeeper.ZooKeeper -44   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp
[framework] 2015-12-18 15:22:59,235 - org.apache.zookeeper.ZooKeeper -44   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
[framework] 2015-12-18 15:22:59,235 - org.apache.zookeeper.ZooKeeper -44   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
[framework] 2015-12-18 15:22:59,235 - org.apache.zookeeper.ZooKeeper -44   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
[framework] 2015-12-18 15:22:59,235 - org.apache.zookeeper.ZooKeeper -44   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.2.0-21-generic
[framework] 2015-12-18 15:22:59,235 - org.apache.zookeeper.ZooKeeper -44   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.name=juxinli
[framework] 2015-12-18 15:22:59,235 - org.apache.zookeeper.ZooKeeper -44   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/juxinli
[framework] 2015-12-18 15:22:59,236 - org.apache.zookeeper.ZooKeeper -45   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/home/juxinli/workspace/infogen_etl
[framework] 2015-12-18 15:22:59,238 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@5ae63ade
[framework] 2015-12-18 15:22:59,275 - com.infogen.zookeeper.InfoGen_ZooKeeper -84   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-18 15:22:59,278 - org.apache.zookeeper.ClientCnxn -87   [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.98/172.16.8.98:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-18 15:22:59,280 - com.infogen.zookeeper.InfoGen_ZooKeeper -89   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers
[framework] 2015-12-18 15:22:59,361 - org.apache.zookeeper.ClientCnxn -170  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.98/172.16.8.98:2181, initiating session
[framework] 2015-12-18 15:22:59,385 - org.apache.zookeeper.ClientCnxn -194  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.98/172.16.8.98:2181, sessionid = 0x6250c64e4256078a, negotiated timeout = 10000
[framework] 2015-12-18 15:22:59,389 - com.infogen.zookeeper.InfoGen_ZooKeeper -198  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-18 15:22:59,423 - com.infogen.zookeeper.InfoGen_ZooKeeper -232  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers
[framework] 2015-12-18 15:22:59,423 - com.infogen.zookeeper.InfoGen_ZooKeeper -232  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-18 15:22:59,437 - com.infogen.zookeeper.InfoGen_ZooKeeper -246  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-18 15:22:59,437 - com.infogen.zookeeper.InfoGen_ZooKeeper -246  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/infogen_etl
[framework] 2015-12-18 15:22:59,455 - com.infogen.zookeeper.InfoGen_ZooKeeper -264  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/infogen_etl
[framework] 2015-12-18 15:22:59,455 - com.infogen.zookeeper.InfoGen_ZooKeeper -264  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset
[framework] 2015-12-18 15:22:59,471 - com.infogen.zookeeper.InfoGen_ZooKeeper -280  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset
[framework] 2015-12-18 15:22:59,472 - com.infogen.zookeeper.InfoGen_ZooKeeper -281  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/infogen_etl/partition
[framework] 2015-12-18 15:22:59,485 - com.infogen.zookeeper.InfoGen_ZooKeeper -294  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/partition
[framework] 2015-12-18 15:22:59,486 - com.infogen.zookeeper.InfoGen_ZooKeeper -295  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/ids
[framework] 2015-12-18 15:22:59,504 - com.infogen.zookeeper.InfoGen_ZooKeeper -313  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/ids
[framework] 2015-12-18 15:22:59,504 - com.infogen.zookeeper.InfoGen_ZooKeeper -313  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/1
[framework] 2015-12-18 15:22:59,521 - com.infogen.zookeeper.InfoGen_ZooKeeper -330  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/1
[framework] 2015-12-18 15:22:59,522 - com.infogen.zookeeper.InfoGen_ZooKeeper -331  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/2
[framework] 2015-12-18 15:22:59,536 - com.infogen.zookeeper.InfoGen_ZooKeeper -345  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/2
[framework] 2015-12-18 15:22:59,537 - com.infogen.zookeeper.InfoGen_ZooKeeper -346  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/3
[framework] 2015-12-18 15:22:59,550 - com.infogen.zookeeper.InfoGen_ZooKeeper -359  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/3
[framework] 2015-12-18 15:22:59,551 - com.infogen.etl.InfoGen_Container -360  [main] INFO  com.infogen.etl.InfoGen_Container  - #broker为：172.16.8.97:10086,172.16.8.98:10086,172.16.8.99:10086
[framework] 2015-12-18 15:22:59,551 - com.infogen.zookeeper.InfoGen_ZooKeeper -360  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-18 15:22:59,565 - com.infogen.zookeeper.InfoGen_ZooKeeper -374  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-18 15:22:59,565 - com.infogen.zookeeper.InfoGen_ZooKeeper -374  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset/0
[framework] 2015-12-18 15:22:59,581 - com.infogen.zookeeper.InfoGen_ZooKeeper -390  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset/0
[framework] 2015-12-18 15:22:59,584 - com.infogen.zookeeper.InfoGen_ZooKeeper -393  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/infogen_etl/partition/0
[framework] 2015-12-18 15:22:59,604 - com.infogen.zookeeper.InfoGen_ZooKeeper -413  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/partition/0
[framework] 2015-12-18 15:22:59,607 - com.infogen.etl.InfoGen_Container -416  [main] INFO  com.infogen.etl.InfoGen_Container  - #获取partition成功:0
[framework] 2015-12-18 15:22:59,607 - com.infogen.etl.InfoGen_Container -416  [main] INFO  com.infogen.etl.InfoGen_Container  - #partition为：0
[framework] 2015-12-18 15:22:59,607 - com.infogen.zookeeper.InfoGen_ZooKeeper -416  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset/0
[framework] 2015-12-18 15:22:59,627 - com.infogen.zookeeper.InfoGen_ZooKeeper -436  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset/0
[framework] 2015-12-18 15:22:59,627 - com.infogen.etl.InfoGen_Container -436  [main] INFO  com.infogen.etl.InfoGen_Container  - #使用zookeeper 中 offset为:null
[framework] 2015-12-18 15:22:59,627 - com.infogen.etl.InfoGen_Container -436  [main] INFO  com.infogen.etl.InfoGen_Container  - #zookeeper_offset为：4641635
[framework] 2015-12-18 15:22:59,627 - com.infogen.zookeeper.InfoGen_ZooKeeper -436  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 关闭zookeeper
[framework] 2015-12-18 15:22:59,644 - org.apache.zookeeper.ZooKeeper -453  [main] INFO  org.apache.zookeeper.ZooKeeper  - Session: 0x6250c64e4256078a closed
[framework] 2015-12-18 15:22:59,644 - org.apache.zookeeper.ClientCnxn -453  [main-EventThread] INFO  org.apache.zookeeper.ClientCnxn  - EventThread shut down
[framework] 2015-12-18 15:22:59,645 - com.infogen.zookeeper.InfoGen_ZooKeeper -454  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 关闭zookeeper成功
[framework] 2015-12-18 15:22:59,645 - com.infogen.etl.InfoGen_Container -454  [main] INFO  com.infogen.etl.InfoGen_Container  - #执行ETL commit_offset为：4641635
[framework] 2015-12-18 15:22:59,654 - com.infogen.zookeeper.InfoGen_ZooKeeper -463  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-18 15:22:59,654 - org.apache.zookeeper.ZooKeeper -463  [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@4abdb505
[framework] 2015-12-18 15:22:59,655 - org.apache.zookeeper.ClientCnxn -464  [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.97/172.16.8.97:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-18 15:22:59,655 - com.infogen.zookeeper.InfoGen_ZooKeeper -464  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-18 15:22:59,656 - com.infogen.kafka.InfoGen_Consumer -465  [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #获取指定Topic partition的元数据：topic-infogen_topic_tracking partition-0
[framework] 2015-12-18 15:22:59,668 - org.apache.zookeeper.ClientCnxn -477  [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.97/172.16.8.97:2181, initiating session
[framework] 2015-12-18 15:22:59,683 - org.apache.zookeeper.ClientCnxn -492  [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.97/172.16.8.97:2181, sessionid = 0x614f1aad4d9c8267, negotiated timeout = 10000
[framework] 2015-12-18 15:22:59,684 - com.infogen.zookeeper.InfoGen_ZooKeeper -493  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-18 15:23:00,337 - com.infogen.kafka.InfoGen_Consumer -1146 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #leaderBroker：172.16.8.98
[framework] 2015-12-18 15:23:00,338 - com.infogen.kafka.InfoGen_Consumer -1147 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #leaderPort：10086
[framework] 2015-12-18 15:23:00,338 - com.infogen.kafka.InfoGen_Consumer -1147 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #clientId：Client_infogen_topic_tracking_0_1450423380338
[framework] 2015-12-18 15:23:00,448 - com.infogen.kafka.InfoGen_Consumer -1257 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #offset：4641635:earliestOffset-4590888 latestOffset-4719015
[framework] 2015-12-18 15:23:00,449 - com.infogen.kafka.InfoGen_Consumer -1258 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #开始ETL：单次获取字节数-2097152 最高重试fetch次数-5  最多未commit消息大小-67108864  最多未commit时间-300000
[framework] 2015-12-18 15:23:02,847 - org.apache.hadoop.util.NativeCodeLoader -3656 [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-18 15:23:03,823 - com.infogen.hdfs.InfoGen_LZOOutputStream -4632 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/-0.4641635
[framework] 2015-12-18 15:23:04,019 - com.hadoop.compression.lzo.GPLNativeCodeLoader -4828 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-18 15:23:04,022 - com.hadoop.compression.lzo.LzoCodec -4831 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-18 15:23:04,024 - org.apache.hadoop.conf.Configuration.deprecation -4833 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-18 15:23:04,025 - org.apache.hadoop.io.compress.CodecPool -4834 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:04,210 - com.infogen.hdfs.InfoGen_LZOOutputStream -5019 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/18/-0.4642557
[framework] 2015-12-18 15:23:04,299 - org.apache.hadoop.io.compress.CodecPool -5108 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:04,403 - com.infogen.hdfs.InfoGen_LZOOutputStream -5212 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/19/-0.4643236
[framework] 2015-12-18 15:23:04,482 - org.apache.hadoop.io.compress.CodecPool -5291 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:04,591 - com.infogen.hdfs.InfoGen_LZOOutputStream -5400 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/20/-0.4643751
[framework] 2015-12-18 15:23:04,676 - org.apache.hadoop.io.compress.CodecPool -5485 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:04,768 - com.infogen.hdfs.InfoGen_LZOOutputStream -5577 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/21/-0.4643763
[framework] 2015-12-18 15:23:04,848 - org.apache.hadoop.io.compress.CodecPool -5657 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:05,152 - com.infogen.hdfs.InfoGen_LZOOutputStream -5961 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/22/-0.4643788
[framework] 2015-12-18 15:23:05,246 - org.apache.hadoop.io.compress.CodecPool -6055 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:05,322 - com.infogen.hdfs.InfoGen_LZOOutputStream -6131 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/23/-0.4643803
[framework] 2015-12-18 15:23:05,446 - org.apache.hadoop.io.compress.CodecPool -6255 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:05,517 - com.infogen.hdfs.InfoGen_LZOOutputStream -6326 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/0/-0.4643825
[framework] 2015-12-18 15:23:05,945 - org.apache.hadoop.io.compress.CodecPool -6754 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:06,255 - com.infogen.hdfs.InfoGen_LZOOutputStream -7064 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/1/-0.4643833
[framework] 2015-12-18 15:23:06,395 - org.apache.hadoop.io.compress.CodecPool -7204 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:06,505 - com.infogen.hdfs.InfoGen_LZOOutputStream -7314 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/2/-0.4643855
[framework] 2015-12-18 15:23:06,832 - org.apache.hadoop.io.compress.CodecPool -7641 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:06,924 - com.infogen.hdfs.InfoGen_LZOOutputStream -7733 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/3/-0.4643857
[framework] 2015-12-18 15:23:07,050 - org.apache.hadoop.io.compress.CodecPool -7859 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:07,146 - com.infogen.hdfs.InfoGen_LZOOutputStream -7955 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/4/-0.4643858
[framework] 2015-12-18 15:23:07,493 - org.apache.hadoop.io.compress.CodecPool -8302 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:07,578 - com.infogen.hdfs.InfoGen_LZOOutputStream -8387 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/6/-0.4643860
[framework] 2015-12-18 15:23:07,671 - org.apache.hadoop.io.compress.CodecPool -8480 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:07,750 - com.infogen.hdfs.InfoGen_LZOOutputStream -8559 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/7/-0.4643868
[framework] 2015-12-18 15:23:07,876 - org.apache.hadoop.io.compress.CodecPool -8685 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:12,423 - com.infogen.hdfs.InfoGen_LZOOutputStream -13232 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/8/-0.4661716
[framework] 2015-12-18 15:23:12,586 - org.apache.hadoop.io.compress.CodecPool -13395 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:12,651 - com.infogen.hdfs.InfoGen_LZOOutputStream -13460 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/9/-0.4661724
[framework] 2015-12-18 15:23:12,728 - org.apache.hadoop.io.compress.CodecPool -13537 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:12,797 - com.infogen.hdfs.InfoGen_LZOOutputStream -13606 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/10/-0.4661915
[framework] 2015-12-18 15:23:12,906 - org.apache.hadoop.io.compress.CodecPool -13715 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:12,982 - com.infogen.hdfs.InfoGen_LZOOutputStream -13791 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/11/-0.4662395
[framework] 2015-12-18 15:23:13,060 - org.apache.hadoop.io.compress.CodecPool -13869 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:13,150 - com.infogen.hdfs.InfoGen_LZOOutputStream -13959 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/12/-0.4662765
[framework] 2015-12-18 15:23:13,360 - org.apache.hadoop.io.compress.CodecPool -14169 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:13,424 - com.infogen.hdfs.InfoGen_LZOOutputStream -14233 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/13/-0.4662775
[framework] 2015-12-18 15:23:13,493 - org.apache.hadoop.io.compress.CodecPool -14302 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:13,579 - com.infogen.hdfs.InfoGen_LZOOutputStream -14388 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/14/-0.4662908
[framework] 2015-12-18 15:23:13,659 - org.apache.hadoop.io.compress.CodecPool -14468 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:15,041 - com.infogen.hdfs.InfoGen_LZOOutputStream -15850 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/15/-0.4663451
[framework] 2015-12-18 15:23:15,142 - org.apache.hadoop.io.compress.CodecPool -15951 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:15,679 - com.infogen.hdfs.InfoGen_LZOOutputStream -16488 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/16/-0.4663753
[framework] 2015-12-18 15:23:15,779 - org.apache.hadoop.io.compress.CodecPool -16588 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:15,874 - com.infogen.hdfs.InfoGen_LZOOutputStream -16683 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/17/-0.4664228
[framework] 2015-12-18 15:23:16,061 - org.apache.hadoop.io.compress.CodecPool -16870 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:16,143 - com.infogen.hdfs.InfoGen_LZOOutputStream -16952 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/18/-0.4665083
[framework] 2015-12-18 15:23:16,219 - org.apache.hadoop.io.compress.CodecPool -17028 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:16,296 - com.infogen.hdfs.InfoGen_LZOOutputStream -17105 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/19/-0.4665212
[framework] 2015-12-18 15:23:16,395 - org.apache.hadoop.io.compress.CodecPool -17204 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:16,504 - com.infogen.hdfs.InfoGen_LZOOutputStream -17313 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/20/-0.4665239
[framework] 2015-12-18 15:23:16,593 - org.apache.hadoop.io.compress.CodecPool -17402 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:16,693 - com.infogen.hdfs.InfoGen_LZOOutputStream -17502 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/21/-0.4665424
[framework] 2015-12-18 15:23:16,799 - org.apache.hadoop.io.compress.CodecPool -17608 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:17,153 - com.infogen.hdfs.InfoGen_LZOOutputStream -17962 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/22/-0.4665605
[framework] 2015-12-18 15:23:17,263 - org.apache.hadoop.io.compress.CodecPool -18072 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:17,333 - com.infogen.hdfs.InfoGen_LZOOutputStream -18142 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/23/-0.4665630
[framework] 2015-12-18 15:23:17,704 - org.apache.hadoop.io.compress.CodecPool -18513 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:17,782 - com.infogen.hdfs.InfoGen_LZOOutputStream -18591 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/0/-0.4665650
[framework] 2015-12-18 15:23:18,109 - org.apache.hadoop.io.compress.CodecPool -18918 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:18,183 - com.infogen.hdfs.InfoGen_LZOOutputStream -18992 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/1/-0.4665716
[framework] 2015-12-18 15:23:18,272 - org.apache.hadoop.io.compress.CodecPool -19081 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:18,622 - com.infogen.hdfs.InfoGen_LZOOutputStream -19431 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/3/-0.4665722
[framework] 2015-12-18 15:23:18,717 - org.apache.hadoop.io.compress.CodecPool -19526 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:18,787 - com.infogen.hdfs.InfoGen_LZOOutputStream -19596 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/4/-0.4665727
[framework] 2015-12-18 15:23:18,875 - org.apache.hadoop.io.compress.CodecPool -19684 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:18,952 - com.infogen.hdfs.InfoGen_LZOOutputStream -19761 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/6/-0.4665730
[framework] 2015-12-18 15:23:19,040 - org.apache.hadoop.io.compress.CodecPool -19849 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:19,115 - com.infogen.hdfs.InfoGen_LZOOutputStream -19924 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/7/-0.4665733
[framework] 2015-12-18 15:23:19,234 - org.apache.hadoop.io.compress.CodecPool -20043 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:25,407 - com.infogen.hdfs.InfoGen_LZOOutputStream -26216 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/8/-0.4683311
[framework] 2015-12-18 15:23:25,540 - org.apache.hadoop.io.compress.CodecPool -26349 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:25,670 - com.infogen.hdfs.InfoGen_LZOOutputStream -26479 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/9/-0.4683320
[framework] 2015-12-18 15:23:26,027 - org.apache.hadoop.io.compress.CodecPool -26836 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:26,353 - com.infogen.hdfs.InfoGen_LZOOutputStream -27162 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/10/-0.4683732
[framework] 2015-12-18 15:23:26,440 - org.apache.hadoop.io.compress.CodecPool -27249 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:26,517 - com.infogen.hdfs.InfoGen_LZOOutputStream -27326 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/11/-0.4684410
[framework] 2015-12-18 15:23:26,589 - org.apache.hadoop.io.compress.CodecPool -27398 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:26,908 - com.infogen.hdfs.InfoGen_LZOOutputStream -27717 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/12/-0.4684675
[framework] 2015-12-18 15:23:26,998 - org.apache.hadoop.io.compress.CodecPool -27807 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:27,079 - com.infogen.hdfs.InfoGen_LZOOutputStream -27888 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/13/-0.4684765
[framework] 2015-12-18 15:23:27,157 - org.apache.hadoop.io.compress.CodecPool -27966 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:29,344 - com.infogen.hdfs.InfoGen_LZOOutputStream -30153 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/14/-0.4684950
[framework] 2015-12-18 15:23:29,433 - org.apache.hadoop.io.compress.CodecPool -30242 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:29,505 - com.infogen.hdfs.InfoGen_LZOOutputStream -30314 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/15/-0.4685295
[framework] 2015-12-18 15:23:29,585 - org.apache.hadoop.io.compress.CodecPool -30394 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:29,663 - com.infogen.hdfs.InfoGen_LZOOutputStream -30472 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/16/-0.4686939
[framework] 2015-12-18 15:23:29,788 - org.apache.hadoop.io.compress.CodecPool -30597 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:29,854 - com.infogen.hdfs.InfoGen_LZOOutputStream -30663 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/17/-0.4687810
[framework] 2015-12-18 15:23:30,021 - org.apache.hadoop.io.compress.CodecPool -30830 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:30,096 - com.infogen.hdfs.InfoGen_LZOOutputStream -30905 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/18/-0.4689182
[framework] 2015-12-18 15:23:30,205 - org.apache.hadoop.io.compress.CodecPool -31014 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:30,266 - com.infogen.hdfs.InfoGen_LZOOutputStream -31075 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/19/-0.4689903
[framework] 2015-12-18 15:23:30,346 - org.apache.hadoop.io.compress.CodecPool -31155 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:30,422 - com.infogen.hdfs.InfoGen_LZOOutputStream -31231 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/20/-0.4690044
[framework] 2015-12-18 15:23:30,511 - org.apache.hadoop.io.compress.CodecPool -31320 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:30,567 - com.infogen.hdfs.InfoGen_LZOOutputStream -31376 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/21/-0.4690193
[framework] 2015-12-18 15:23:30,682 - org.apache.hadoop.io.compress.CodecPool -31491 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:30,741 - com.infogen.hdfs.InfoGen_LZOOutputStream -31550 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/22/-0.4690343
[framework] 2015-12-18 15:23:30,838 - org.apache.hadoop.io.compress.CodecPool -31647 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:30,898 - com.infogen.hdfs.InfoGen_LZOOutputStream -31707 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/23/-0.4690476
[framework] 2015-12-18 15:23:30,998 - org.apache.hadoop.io.compress.CodecPool -31807 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:31,522 - com.infogen.hdfs.InfoGen_LZOOutputStream -32331 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/0/-0.4690601
[framework] 2015-12-18 15:23:31,621 - org.apache.hadoop.io.compress.CodecPool -32430 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:31,691 - com.infogen.hdfs.InfoGen_LZOOutputStream -32500 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/1/-0.4690719
[framework] 2015-12-18 15:23:32,007 - org.apache.hadoop.io.compress.CodecPool -32816 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:32,107 - com.infogen.hdfs.InfoGen_LZOOutputStream -32916 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/2/-0.4690833
[framework] 2015-12-18 15:23:32,186 - org.apache.hadoop.io.compress.CodecPool -32995 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:32,262 - com.infogen.hdfs.InfoGen_LZOOutputStream -33071 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/3/-0.4690938
[framework] 2015-12-18 15:23:32,388 - org.apache.hadoop.io.compress.CodecPool -33197 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:32,456 - com.infogen.hdfs.InfoGen_LZOOutputStream -33265 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/4/-0.4691052
[framework] 2015-12-18 15:23:32,550 - org.apache.hadoop.io.compress.CodecPool -33359 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:32,622 - com.infogen.hdfs.InfoGen_LZOOutputStream -33431 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/5/-0.4691140
[framework] 2015-12-18 15:23:32,694 - org.apache.hadoop.io.compress.CodecPool -33503 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:33,454 - com.infogen.hdfs.InfoGen_LZOOutputStream -34263 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/6/-0.4691250
[framework] 2015-12-18 15:23:33,559 - org.apache.hadoop.io.compress.CodecPool -34368 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:33,643 - com.infogen.hdfs.InfoGen_LZOOutputStream -34452 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/7/-0.4691361
[framework] 2015-12-18 15:23:33,952 - org.apache.hadoop.io.compress.CodecPool -34761 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:34,045 - com.infogen.hdfs.InfoGen_LZOOutputStream -34854 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/8/-0.4691454
[framework] 2015-12-18 15:23:34,136 - org.apache.hadoop.io.compress.CodecPool -34945 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:34,442 - com.infogen.hdfs.InfoGen_LZOOutputStream -35251 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/9/-0.4691576
[framework] 2015-12-18 15:23:34,527 - org.apache.hadoop.io.compress.CodecPool -35336 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:34,593 - com.infogen.hdfs.InfoGen_LZOOutputStream -35402 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/10/-0.4691790
[framework] 2015-12-18 15:23:34,669 - org.apache.hadoop.io.compress.CodecPool -35478 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:34,797 - com.infogen.hdfs.InfoGen_LZOOutputStream -35606 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/11/-0.4692128
[framework] 2015-12-18 15:23:34,889 - org.apache.hadoop.io.compress.CodecPool -35698 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:37,468 - com.infogen.hdfs.InfoGen_LZOOutputStream -38277 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/12/-0.4695448
[framework] 2015-12-18 15:23:37,545 - org.apache.hadoop.io.compress.CodecPool -38354 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:41,184 - com.infogen.hdfs.InfoGen_LZOOutputStream -41993 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/13/-0.4707441
[framework] 2015-12-18 15:23:41,501 - org.apache.hadoop.io.compress.CodecPool -42310 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:41,584 - com.infogen.hdfs.InfoGen_LZOOutputStream -42393 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/14/-0.4708847
[framework] 2015-12-18 15:23:41,835 - org.apache.hadoop.io.compress.CodecPool -42644 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:41,927 - com.infogen.hdfs.InfoGen_LZOOutputStream -42736 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/15/-0.4709940
[framework] 2015-12-18 15:23:42,033 - org.apache.hadoop.io.compress.CodecPool -42842 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:42,097 - com.infogen.hdfs.InfoGen_LZOOutputStream -42906 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/16/-0.4711460
[framework] 2015-12-18 15:23:42,286 - org.apache.hadoop.io.compress.CodecPool -43095 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:42,363 - com.infogen.hdfs.InfoGen_LZOOutputStream -43172 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/17/-0.4713722
[framework] 2015-12-18 15:23:42,518 - org.apache.hadoop.io.compress.CodecPool -43327 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:43,774 - com.infogen.hdfs.InfoGen_LZOOutputStream -44583 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/18/-0.4715104
[framework] 2015-12-18 15:23:43,867 - org.apache.hadoop.io.compress.CodecPool -44676 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:43,937 - com.infogen.hdfs.InfoGen_LZOOutputStream -44746 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/19/-0.4715526
[framework] 2015-12-18 15:23:44,092 - org.apache.hadoop.io.compress.CodecPool -44901 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:44,167 - com.infogen.hdfs.InfoGen_LZOOutputStream -44976 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/20/-0.4715998
[framework] 2015-12-18 15:23:44,275 - org.apache.hadoop.io.compress.CodecPool -45084 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:44,362 - com.infogen.hdfs.InfoGen_LZOOutputStream -45171 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/21/-0.4716505
[framework] 2015-12-18 15:23:44,475 - org.apache.hadoop.io.compress.CodecPool -45284 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:44,543 - com.infogen.hdfs.InfoGen_LZOOutputStream -45352 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/22/-0.4716543
[framework] 2015-12-18 15:23:44,650 - org.apache.hadoop.io.compress.CodecPool -45459 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:44,709 - com.infogen.hdfs.InfoGen_LZOOutputStream -45518 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/23/-0.4716567
[framework] 2015-12-18 15:23:44,837 - org.apache.hadoop.io.compress.CodecPool -45646 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:44,906 - com.infogen.hdfs.InfoGen_LZOOutputStream -45715 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/0/-0.4716603
[framework] 2015-12-18 15:23:45,073 - org.apache.hadoop.io.compress.CodecPool -45882 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:45,399 - com.infogen.hdfs.InfoGen_LZOOutputStream -46208 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/1/-0.4716624
[framework] 2015-12-18 15:23:45,773 - org.apache.hadoop.io.compress.CodecPool -46582 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:45,869 - com.infogen.hdfs.InfoGen_LZOOutputStream -46678 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/2/-0.4716639
[framework] 2015-12-18 15:23:46,263 - org.apache.hadoop.io.compress.CodecPool -47072 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:47,085 - com.infogen.hdfs.InfoGen_LZOOutputStream -47894 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/3/-0.4716654
[framework] 2015-12-18 15:23:47,169 - org.apache.hadoop.io.compress.CodecPool -47978 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:47,265 - com.infogen.hdfs.InfoGen_LZOOutputStream -48074 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/4/-0.4716666
[framework] 2015-12-18 15:23:47,390 - org.apache.hadoop.io.compress.CodecPool -48199 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:47,476 - com.infogen.hdfs.InfoGen_LZOOutputStream -48285 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/5/-0.4716671
[framework] 2015-12-18 15:23:47,590 - org.apache.hadoop.io.compress.CodecPool -48399 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:47,670 - com.infogen.hdfs.InfoGen_LZOOutputStream -48479 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/6/-0.4716679
[framework] 2015-12-18 15:23:47,783 - org.apache.hadoop.io.compress.CodecPool -48592 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:47,842 - com.infogen.hdfs.InfoGen_LZOOutputStream -48651 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/7/-0.4716687
[framework] 2015-12-18 15:23:47,925 - org.apache.hadoop.io.compress.CodecPool -48734 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:47,985 - com.infogen.hdfs.InfoGen_LZOOutputStream -48794 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/8/-0.4716704
[framework] 2015-12-18 15:23:48,085 - org.apache.hadoop.io.compress.CodecPool -48894 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:48,149 - com.infogen.hdfs.InfoGen_LZOOutputStream -48958 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/9/-0.4716728
[framework] 2015-12-18 15:23:48,357 - org.apache.hadoop.io.compress.CodecPool -49166 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:48,445 - com.infogen.hdfs.InfoGen_LZOOutputStream -49254 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/10/-0.4717077
[framework] 2015-12-18 15:23:48,761 - org.apache.hadoop.io.compress.CodecPool -49570 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:48,883 - com.infogen.hdfs.InfoGen_LZOOutputStream -49692 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/11/-0.4717494
[framework] 2015-12-18 15:23:48,958 - org.apache.hadoop.io.compress.CodecPool -49767 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:49,023 - com.infogen.hdfs.InfoGen_LZOOutputStream -49832 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/12/-0.4718108
[framework] 2015-12-18 15:23:49,111 - org.apache.hadoop.io.compress.CodecPool -49920 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:49,174 - com.infogen.hdfs.InfoGen_LZOOutputStream -49983 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/13/-0.4718207
[framework] 2015-12-18 15:23:49,269 - org.apache.hadoop.io.compress.CodecPool -50078 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:49,363 - com.infogen.hdfs.InfoGen_LZOOutputStream -50172 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/14/-0.4718242
[framework] 2015-12-18 15:23:49,450 - org.apache.hadoop.io.compress.CodecPool -50259 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:23:49,559 - com.infogen.hdfs.InfoGen_LZOOutputStream -50368 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/15/-0.4718928
[framework] 2015-12-18 15:23:49,882 - org.apache.hadoop.io.compress.CodecPool -50691 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:33,744 - com.infogen.zookeeper.InfoGen_ZooKeeper -0    [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-18 15:24:33,783 - org.apache.zookeeper.ZooKeeper -39   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[framework] 2015-12-18 15:24:33,783 - org.apache.zookeeper.ZooKeeper -39   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:host.name=localhost
[framework] 2015-12-18 15:24:33,783 - org.apache.zookeeper.ZooKeeper -39   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_20
[framework] 2015-12-18 15:24:33,783 - org.apache.zookeeper.ZooKeeper -39   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
[framework] 2015-12-18 15:24:33,783 - org.apache.zookeeper.ZooKeeper -39   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/lib/jvm/java-8-sun/jre
[framework] 2015-12-18 15:24:33,784 - org.apache.zookeeper.ZooKeeper -40   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/home/juxinli/workspace/infogen_etl/target/classes:/home/juxinli/workspace/infogen_etl/lib/hadoop-lzo-0.4.20-SNAPSHOT.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-client/2.7.1/hadoop-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-common/2.7.1/hadoop-common-2.7.1.jar:/home/juxinli/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/juxinli/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/juxinli/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/juxinli/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/juxinli/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/juxinli/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/juxinli/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/juxinli/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/juxinli/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/juxinli/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/juxinli/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/juxinli/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/juxinli/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/juxinli/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/juxinli/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/juxinli/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/juxinli/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.1/hadoop-auth-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/home/juxinli/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/juxinli/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/juxinli/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.1/hadoop-hdfs-2.7.1.jar:/home/juxinli/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/juxinli/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/juxinli/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/juxinli/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/juxinli/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.1/hadoop-mapreduce-client-app-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.1/hadoop-mapreduce-client-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.1/hadoop-yarn-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.1/hadoop-yarn-server-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.1/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.1/hadoop-yarn-api-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.1/hadoop-mapreduce-client-core-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.1/hadoop-yarn-common-2.7.1.jar:/home/juxinli/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/juxinli/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/juxinli/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/juxinli/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.1/hadoop-mapreduce-client-jobclient-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.1/hadoop-annotations-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka_2.11/0.8.2.2/kafka_2.11-0.8.2.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/juxinli/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar:/home/juxinli/.m2/repository/org/scala-lang/scala-library/2.11.5/scala-library-2.11.5.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.2/kafka-clients-0.8.2.2.jar:/home/juxinli/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/juxinli/.m2/repository/net/jpountz/lz4/lz4/1.2.0/lz4-1.2.0.jar:/home/juxinli/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/juxinli/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/juxinli/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/juxinli/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar
[framework] 2015-12-18 15:24:33,784 - org.apache.zookeeper.ZooKeeper -40   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[framework] 2015-12-18 15:24:33,784 - org.apache.zookeeper.ZooKeeper -40   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp
[framework] 2015-12-18 15:24:33,784 - org.apache.zookeeper.ZooKeeper -40   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
[framework] 2015-12-18 15:24:33,785 - org.apache.zookeeper.ZooKeeper -41   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
[framework] 2015-12-18 15:24:33,785 - org.apache.zookeeper.ZooKeeper -41   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
[framework] 2015-12-18 15:24:33,785 - org.apache.zookeeper.ZooKeeper -41   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.2.0-21-generic
[framework] 2015-12-18 15:24:33,785 - org.apache.zookeeper.ZooKeeper -41   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.name=juxinli
[framework] 2015-12-18 15:24:33,785 - org.apache.zookeeper.ZooKeeper -41   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/juxinli
[framework] 2015-12-18 15:24:33,785 - org.apache.zookeeper.ZooKeeper -41   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/home/juxinli/workspace/infogen_etl
[framework] 2015-12-18 15:24:33,787 - org.apache.zookeeper.ZooKeeper -43   [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@5ae63ade
[framework] 2015-12-18 15:24:33,819 - com.infogen.zookeeper.InfoGen_ZooKeeper -75   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-18 15:24:33,821 - com.infogen.zookeeper.InfoGen_ZooKeeper -77   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers
[framework] 2015-12-18 15:24:33,828 - org.apache.zookeeper.ClientCnxn -84   [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.97/172.16.8.97:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-18 15:24:33,905 - org.apache.zookeeper.ClientCnxn -161  [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.97/172.16.8.97:2181, initiating session
[framework] 2015-12-18 15:24:33,927 - org.apache.zookeeper.ClientCnxn -183  [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.97/172.16.8.97:2181, sessionid = 0x614f1aad4d9c8268, negotiated timeout = 10000
[framework] 2015-12-18 15:24:33,929 - com.infogen.zookeeper.InfoGen_ZooKeeper -185  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-18 15:24:33,944 - com.infogen.zookeeper.InfoGen_ZooKeeper -200  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers
[framework] 2015-12-18 15:24:33,944 - com.infogen.zookeeper.InfoGen_ZooKeeper -200  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-18 15:24:33,957 - com.infogen.zookeeper.InfoGen_ZooKeeper -213  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-18 15:24:33,957 - com.infogen.zookeeper.InfoGen_ZooKeeper -213  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/infogen_etl
[framework] 2015-12-18 15:24:33,989 - com.infogen.zookeeper.InfoGen_ZooKeeper -245  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/infogen_etl
[framework] 2015-12-18 15:24:33,989 - com.infogen.zookeeper.InfoGen_ZooKeeper -245  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset
[framework] 2015-12-18 15:24:34,007 - com.infogen.zookeeper.InfoGen_ZooKeeper -263  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset
[framework] 2015-12-18 15:24:34,007 - com.infogen.zookeeper.InfoGen_ZooKeeper -263  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/infogen_etl/partition
[framework] 2015-12-18 15:24:34,021 - com.infogen.zookeeper.InfoGen_ZooKeeper -277  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/partition
[framework] 2015-12-18 15:24:34,022 - com.infogen.zookeeper.InfoGen_ZooKeeper -278  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/ids
[framework] 2015-12-18 15:24:34,040 - com.infogen.zookeeper.InfoGen_ZooKeeper -296  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/ids
[framework] 2015-12-18 15:24:34,041 - com.infogen.zookeeper.InfoGen_ZooKeeper -297  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/1
[framework] 2015-12-18 15:24:34,063 - com.infogen.zookeeper.InfoGen_ZooKeeper -319  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/1
[framework] 2015-12-18 15:24:34,064 - com.infogen.zookeeper.InfoGen_ZooKeeper -320  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/2
[framework] 2015-12-18 15:24:34,081 - com.infogen.zookeeper.InfoGen_ZooKeeper -337  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/2
[framework] 2015-12-18 15:24:34,082 - com.infogen.zookeeper.InfoGen_ZooKeeper -338  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/3
[framework] 2015-12-18 15:24:34,097 - com.infogen.zookeeper.InfoGen_ZooKeeper -353  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/3
[framework] 2015-12-18 15:24:34,097 - com.infogen.etl.InfoGen_Container -353  [main] INFO  com.infogen.etl.InfoGen_Container  - #broker为：172.16.8.97:10086,172.16.8.98:10086,172.16.8.99:10086
[framework] 2015-12-18 15:24:34,097 - com.infogen.zookeeper.InfoGen_ZooKeeper -353  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-18 15:24:34,111 - com.infogen.zookeeper.InfoGen_ZooKeeper -367  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-18 15:24:34,111 - com.infogen.zookeeper.InfoGen_ZooKeeper -367  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset/0
[framework] 2015-12-18 15:24:34,124 - com.infogen.zookeeper.InfoGen_ZooKeeper -380  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset/0
[framework] 2015-12-18 15:24:34,127 - com.infogen.zookeeper.InfoGen_ZooKeeper -383  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/infogen_etl/partition/0
[framework] 2015-12-18 15:24:34,148 - com.infogen.zookeeper.InfoGen_ZooKeeper -404  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/partition/0
[framework] 2015-12-18 15:24:34,150 - com.infogen.etl.InfoGen_Container -406  [main] INFO  com.infogen.etl.InfoGen_Container  - #获取partition成功:0
[framework] 2015-12-18 15:24:34,150 - com.infogen.etl.InfoGen_Container -406  [main] INFO  com.infogen.etl.InfoGen_Container  - #partition为：0
[framework] 2015-12-18 15:24:34,151 - com.infogen.zookeeper.InfoGen_ZooKeeper -407  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset/0
[framework] 2015-12-18 15:24:34,169 - com.infogen.zookeeper.InfoGen_ZooKeeper -425  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset/0
[framework] 2015-12-18 15:24:34,169 - com.infogen.etl.InfoGen_Container -425  [main] INFO  com.infogen.etl.InfoGen_Container  - #使用zookeeper 中 offset为:null
[framework] 2015-12-18 15:24:34,170 - com.infogen.etl.InfoGen_Container -426  [main] INFO  com.infogen.etl.InfoGen_Container  - #zookeeper_offset为：4641635
[framework] 2015-12-18 15:24:34,170 - com.infogen.zookeeper.InfoGen_ZooKeeper -426  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 关闭zookeeper
[framework] 2015-12-18 15:24:34,186 - org.apache.zookeeper.ZooKeeper -442  [main] INFO  org.apache.zookeeper.ZooKeeper  - Session: 0x614f1aad4d9c8268 closed
[framework] 2015-12-18 15:24:34,186 - com.infogen.zookeeper.InfoGen_ZooKeeper -442  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 关闭zookeeper成功
[framework] 2015-12-18 15:24:34,186 - org.apache.zookeeper.ClientCnxn -442  [main-EventThread] INFO  org.apache.zookeeper.ClientCnxn  - EventThread shut down
[framework] 2015-12-18 15:24:34,186 - com.infogen.etl.InfoGen_Container -442  [main] INFO  com.infogen.etl.InfoGen_Container  - #执行ETL commit_offset为：4641635
[framework] 2015-12-18 15:24:34,192 - com.infogen.zookeeper.InfoGen_ZooKeeper -448  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-18 15:24:34,192 - org.apache.zookeeper.ZooKeeper -448  [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@4abdb505
[framework] 2015-12-18 15:24:34,193 - com.infogen.zookeeper.InfoGen_ZooKeeper -449  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-18 15:24:34,193 - com.infogen.kafka.InfoGen_Consumer -449  [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #获取指定Topic partition的元数据：topic-infogen_topic_tracking partition-0
[framework] 2015-12-18 15:24:34,194 - org.apache.zookeeper.ClientCnxn -450  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.99/172.16.8.99:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-18 15:24:34,209 - org.apache.zookeeper.ClientCnxn -465  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.99/172.16.8.99:2181, initiating session
[framework] 2015-12-18 15:24:34,226 - org.apache.zookeeper.ClientCnxn -482  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.99/172.16.8.99:2181, sessionid = 0x634f1aacb9811fdf, negotiated timeout = 10000
[framework] 2015-12-18 15:24:34,226 - com.infogen.zookeeper.InfoGen_ZooKeeper -482  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-18 15:24:34,792 - com.infogen.kafka.InfoGen_Consumer -1048 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #leaderBroker：172.16.8.98
[framework] 2015-12-18 15:24:34,793 - com.infogen.kafka.InfoGen_Consumer -1049 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #leaderPort：10086
[framework] 2015-12-18 15:24:34,793 - com.infogen.kafka.InfoGen_Consumer -1049 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #clientId：Client_infogen_topic_tracking_0_1450423474793
[framework] 2015-12-18 15:24:34,889 - com.infogen.kafka.InfoGen_Consumer -1145 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #offset：4641635:earliestOffset-4590888 latestOffset-4719017
[framework] 2015-12-18 15:24:34,889 - com.infogen.kafka.InfoGen_Consumer -1145 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #开始ETL：单次获取字节数-2097152 最高重试fetch次数-5  最多未commit消息大小-67108864  最多未commit时间-300000
[framework] 2015-12-18 15:24:37,325 - org.apache.hadoop.util.NativeCodeLoader -3581 [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-18 15:24:38,357 - com.infogen.hdfs.InfoGen_LZOOutputStream -4613 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/-0.4641635
[framework] 2015-12-18 15:24:38,532 - com.hadoop.compression.lzo.GPLNativeCodeLoader -4788 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-18 15:24:38,536 - com.hadoop.compression.lzo.LzoCodec -4792 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-18 15:24:38,540 - org.apache.hadoop.conf.Configuration.deprecation -4796 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-18 15:24:38,541 - org.apache.hadoop.io.compress.CodecPool -4797 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:38,775 - com.infogen.hdfs.InfoGen_LZOOutputStream -5031 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/18/-0.4642557
[framework] 2015-12-18 15:24:38,841 - org.apache.hadoop.io.compress.CodecPool -5097 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:39,037 - com.infogen.hdfs.InfoGen_LZOOutputStream -5293 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/19/-0.4643236
[framework] 2015-12-18 15:24:39,121 - org.apache.hadoop.io.compress.CodecPool -5377 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:39,283 - com.infogen.hdfs.InfoGen_LZOOutputStream -5539 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/20/-0.4643751
[framework] 2015-12-18 15:24:39,588 - org.apache.hadoop.io.compress.CodecPool -5844 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:39,723 - com.infogen.hdfs.InfoGen_LZOOutputStream -5979 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/21/-0.4643763
[framework] 2015-12-18 15:24:39,852 - org.apache.hadoop.io.compress.CodecPool -6108 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:40,218 - com.infogen.hdfs.InfoGen_LZOOutputStream -6474 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/22/-0.4643788
[framework] 2015-12-18 15:24:40,304 - org.apache.hadoop.io.compress.CodecPool -6560 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:40,457 - com.infogen.hdfs.InfoGen_LZOOutputStream -6713 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/23/-0.4643803
[framework] 2015-12-18 15:24:40,524 - org.apache.hadoop.io.compress.CodecPool -6780 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:40,645 - com.infogen.hdfs.InfoGen_LZOOutputStream -6901 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/0/-0.4643825
[framework] 2015-12-18 15:24:40,837 - org.apache.hadoop.io.compress.CodecPool -7093 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:41,036 - com.infogen.hdfs.InfoGen_LZOOutputStream -7292 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/1/-0.4643833
[framework] 2015-12-18 15:24:41,106 - org.apache.hadoop.io.compress.CodecPool -7362 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:41,214 - com.infogen.hdfs.InfoGen_LZOOutputStream -7470 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/2/-0.4643855
[framework] 2015-12-18 15:24:41,373 - org.apache.hadoop.io.compress.CodecPool -7629 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:41,493 - com.infogen.hdfs.InfoGen_LZOOutputStream -7749 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/3/-0.4643857
[framework] 2015-12-18 15:24:41,564 - org.apache.hadoop.io.compress.CodecPool -7820 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:41,719 - com.infogen.hdfs.InfoGen_LZOOutputStream -7975 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/4/-0.4643858
[framework] 2015-12-18 15:24:41,803 - org.apache.hadoop.io.compress.CodecPool -8059 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:41,914 - com.infogen.hdfs.InfoGen_LZOOutputStream -8170 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/6/-0.4643860
[framework] 2015-12-18 15:24:42,115 - org.apache.hadoop.io.compress.CodecPool -8371 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:42,242 - com.infogen.hdfs.InfoGen_LZOOutputStream -8498 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/7/-0.4643868
[framework] 2015-12-18 15:24:42,321 - org.apache.hadoop.io.compress.CodecPool -8577 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:45,203 - com.infogen.hdfs.InfoGen_LZOOutputStream -11459 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/8/-0.4661716
[framework] 2015-12-18 15:24:45,337 - org.apache.hadoop.io.compress.CodecPool -11593 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:45,672 - com.infogen.hdfs.InfoGen_LZOOutputStream -11928 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/9/-0.4661724
[framework] 2015-12-18 15:24:45,974 - org.apache.hadoop.io.compress.CodecPool -12230 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:46,308 - com.infogen.hdfs.InfoGen_LZOOutputStream -12564 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/10/-0.4661915
[framework] 2015-12-18 15:24:46,370 - org.apache.hadoop.io.compress.CodecPool -12626 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:47,371 - com.infogen.hdfs.InfoGen_LZOOutputStream -13627 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/11/-0.4662395
[framework] 2015-12-18 15:24:47,453 - org.apache.hadoop.io.compress.CodecPool -13709 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:47,573 - com.infogen.hdfs.InfoGen_LZOOutputStream -13829 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/12/-0.4662765
[framework] 2015-12-18 15:24:47,646 - org.apache.hadoop.io.compress.CodecPool -13902 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:47,748 - com.infogen.hdfs.InfoGen_LZOOutputStream -14004 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/13/-0.4662775
[framework] 2015-12-18 15:24:47,932 - org.apache.hadoop.io.compress.CodecPool -14188 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:48,058 - com.infogen.hdfs.InfoGen_LZOOutputStream -14314 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/14/-0.4662908
[framework] 2015-12-18 15:24:48,165 - org.apache.hadoop.io.compress.CodecPool -14421 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:50,224 - com.infogen.hdfs.InfoGen_LZOOutputStream -16480 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/15/-0.4663451
[framework] 2015-12-18 15:24:50,314 - org.apache.hadoop.io.compress.CodecPool -16570 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:50,893 - com.infogen.hdfs.InfoGen_LZOOutputStream -17149 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/16/-0.4663753
[framework] 2015-12-18 15:24:50,963 - org.apache.hadoop.io.compress.CodecPool -17219 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:51,168 - com.infogen.hdfs.InfoGen_LZOOutputStream -17424 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/17/-0.4664228
[framework] 2015-12-18 15:24:51,240 - org.apache.hadoop.io.compress.CodecPool -17496 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:51,700 - com.infogen.hdfs.InfoGen_LZOOutputStream -17956 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/18/-0.4665083
[framework] 2015-12-18 15:24:51,817 - org.apache.hadoop.io.compress.CodecPool -18073 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:52,157 - com.infogen.hdfs.InfoGen_LZOOutputStream -18413 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/19/-0.4665212
[framework] 2015-12-18 15:24:52,226 - org.apache.hadoop.io.compress.CodecPool -18482 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:52,582 - com.infogen.hdfs.InfoGen_LZOOutputStream -18838 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/20/-0.4665239
[framework] 2015-12-18 15:24:52,669 - org.apache.hadoop.io.compress.CodecPool -18925 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:52,954 - com.infogen.hdfs.InfoGen_LZOOutputStream -19210 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/21/-0.4665424
[framework] 2015-12-18 15:24:53,146 - org.apache.hadoop.io.compress.CodecPool -19402 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:53,352 - com.infogen.hdfs.InfoGen_LZOOutputStream -19608 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/22/-0.4665605
[framework] 2015-12-18 15:24:53,421 - org.apache.hadoop.io.compress.CodecPool -19677 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:53,748 - com.infogen.hdfs.InfoGen_LZOOutputStream -20004 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/23/-0.4665630
[framework] 2015-12-18 15:24:53,926 - org.apache.hadoop.io.compress.CodecPool -20182 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:54,263 - com.infogen.hdfs.InfoGen_LZOOutputStream -20519 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/0/-0.4665650
[framework] 2015-12-18 15:24:54,335 - org.apache.hadoop.io.compress.CodecPool -20591 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:54,457 - com.infogen.hdfs.InfoGen_LZOOutputStream -20713 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/1/-0.4665716
[framework] 2015-12-18 15:24:54,644 - org.apache.hadoop.io.compress.CodecPool -20900 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:54,759 - com.infogen.hdfs.InfoGen_LZOOutputStream -21015 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/3/-0.4665722
[framework] 2015-12-18 15:24:54,855 - org.apache.hadoop.io.compress.CodecPool -21111 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:55,334 - com.infogen.hdfs.InfoGen_LZOOutputStream -21590 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/4/-0.4665727
[framework] 2015-12-18 15:24:55,485 - org.apache.hadoop.io.compress.CodecPool -21741 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:55,590 - com.infogen.hdfs.InfoGen_LZOOutputStream -21846 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/6/-0.4665730
[framework] 2015-12-18 15:24:55,660 - org.apache.hadoop.io.compress.CodecPool -21916 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:55,788 - com.infogen.hdfs.InfoGen_LZOOutputStream -22044 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/7/-0.4665733
[framework] 2015-12-18 15:24:55,858 - org.apache.hadoop.io.compress.CodecPool -22114 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:59,397 - com.infogen.hdfs.InfoGen_LZOOutputStream -25653 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/8/-0.4683311
[framework] 2015-12-18 15:24:59,479 - org.apache.hadoop.io.compress.CodecPool -25735 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:59,603 - com.infogen.hdfs.InfoGen_LZOOutputStream -25859 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/9/-0.4683320
[framework] 2015-12-18 15:24:59,666 - org.apache.hadoop.io.compress.CodecPool -25922 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:59,799 - com.infogen.hdfs.InfoGen_LZOOutputStream -26055 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/10/-0.4683732
[framework] 2015-12-18 15:24:59,878 - org.apache.hadoop.io.compress.CodecPool -26134 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:24:59,989 - com.infogen.hdfs.InfoGen_LZOOutputStream -26245 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/11/-0.4684410
[framework] 2015-12-18 15:25:00,059 - org.apache.hadoop.io.compress.CodecPool -26315 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:00,918 - com.infogen.hdfs.InfoGen_LZOOutputStream -27174 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/12/-0.4684675
[framework] 2015-12-18 15:25:01,005 - org.apache.hadoop.io.compress.CodecPool -27261 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:01,217 - com.infogen.hdfs.InfoGen_LZOOutputStream -27473 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/13/-0.4684765
[framework] 2015-12-18 15:25:01,307 - org.apache.hadoop.io.compress.CodecPool -27563 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:03,774 - com.infogen.hdfs.InfoGen_LZOOutputStream -30030 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/14/-0.4684950
[framework] 2015-12-18 15:25:03,845 - org.apache.hadoop.io.compress.CodecPool -30101 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:03,946 - com.infogen.hdfs.InfoGen_LZOOutputStream -30202 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/15/-0.4685295
[framework] 2015-12-18 15:25:04,015 - org.apache.hadoop.io.compress.CodecPool -30271 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:04,156 - com.infogen.hdfs.InfoGen_LZOOutputStream -30412 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/16/-0.4686939
[framework] 2015-12-18 15:25:04,232 - org.apache.hadoop.io.compress.CodecPool -30488 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:04,328 - com.infogen.hdfs.InfoGen_LZOOutputStream -30584 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/17/-0.4687810
[framework] 2015-12-18 15:25:04,433 - org.apache.hadoop.io.compress.CodecPool -30689 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:04,546 - com.infogen.hdfs.InfoGen_LZOOutputStream -30802 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/18/-0.4689182
[framework] 2015-12-18 15:25:04,718 - org.apache.hadoop.io.compress.CodecPool -30974 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:04,826 - com.infogen.hdfs.InfoGen_LZOOutputStream -31082 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/19/-0.4689903
[framework] 2015-12-18 15:25:04,896 - org.apache.hadoop.io.compress.CodecPool -31152 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:05,021 - com.infogen.hdfs.InfoGen_LZOOutputStream -31277 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/20/-0.4690044
[framework] 2015-12-18 15:25:05,105 - org.apache.hadoop.io.compress.CodecPool -31361 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:05,216 - com.infogen.hdfs.InfoGen_LZOOutputStream -31472 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/21/-0.4690193
[framework] 2015-12-18 15:25:05,966 - org.apache.hadoop.io.compress.CodecPool -32222 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:06,065 - com.infogen.hdfs.InfoGen_LZOOutputStream -32321 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/22/-0.4690343
[framework] 2015-12-18 15:25:06,373 - org.apache.hadoop.io.compress.CodecPool -32629 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:06,545 - com.infogen.hdfs.InfoGen_LZOOutputStream -32801 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/23/-0.4690476
[framework] 2015-12-18 15:25:06,735 - org.apache.hadoop.io.compress.CodecPool -32991 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:06,857 - com.infogen.hdfs.InfoGen_LZOOutputStream -33113 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/0/-0.4690601
[framework] 2015-12-18 15:25:06,926 - org.apache.hadoop.io.compress.CodecPool -33182 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:07,029 - com.infogen.hdfs.InfoGen_LZOOutputStream -33285 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/1/-0.4690719
[framework] 2015-12-18 15:25:07,098 - org.apache.hadoop.io.compress.CodecPool -33354 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:07,250 - com.infogen.hdfs.InfoGen_LZOOutputStream -33506 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/2/-0.4690833
[framework] 2015-12-18 15:25:07,424 - org.apache.hadoop.io.compress.CodecPool -33680 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:07,544 - com.infogen.hdfs.InfoGen_LZOOutputStream -33800 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/3/-0.4690938
[framework] 2015-12-18 15:25:07,618 - org.apache.hadoop.io.compress.CodecPool -33874 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:07,827 - com.infogen.hdfs.InfoGen_LZOOutputStream -34083 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/4/-0.4691052
[framework] 2015-12-18 15:25:07,890 - org.apache.hadoop.io.compress.CodecPool -34146 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:07,994 - com.infogen.hdfs.InfoGen_LZOOutputStream -34250 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/5/-0.4691140
[framework] 2015-12-18 15:25:08,064 - org.apache.hadoop.io.compress.CodecPool -34320 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:08,180 - com.infogen.hdfs.InfoGen_LZOOutputStream -34436 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/6/-0.4691250
[framework] 2015-12-18 15:25:08,248 - org.apache.hadoop.io.compress.CodecPool -34504 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:08,344 - com.infogen.hdfs.InfoGen_LZOOutputStream -34600 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/7/-0.4691361
[framework] 2015-12-18 15:25:08,415 - org.apache.hadoop.io.compress.CodecPool -34671 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:08,519 - com.infogen.hdfs.InfoGen_LZOOutputStream -34775 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/8/-0.4691454
[framework] 2015-12-18 15:25:08,598 - org.apache.hadoop.io.compress.CodecPool -34854 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:08,702 - com.infogen.hdfs.InfoGen_LZOOutputStream -34958 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/9/-0.4691576
[framework] 2015-12-18 15:25:08,764 - org.apache.hadoop.io.compress.CodecPool -35020 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:08,866 - com.infogen.hdfs.InfoGen_LZOOutputStream -35122 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/10/-0.4691790
[framework] 2015-12-18 15:25:08,939 - org.apache.hadoop.io.compress.CodecPool -35195 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:09,051 - com.infogen.hdfs.InfoGen_LZOOutputStream -35307 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/11/-0.4692128
[framework] 2015-12-18 15:25:09,156 - org.apache.hadoop.io.compress.CodecPool -35412 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:11,298 - com.infogen.hdfs.InfoGen_LZOOutputStream -37554 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/12/-0.4695448
[framework] 2015-12-18 15:25:11,396 - org.apache.hadoop.io.compress.CodecPool -37652 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:15,818 - com.infogen.hdfs.InfoGen_LZOOutputStream -42074 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/13/-0.4707441
[framework] 2015-12-18 15:25:15,898 - org.apache.hadoop.io.compress.CodecPool -42154 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:16,010 - com.infogen.hdfs.InfoGen_LZOOutputStream -42266 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/14/-0.4708847
[framework] 2015-12-18 15:25:16,082 - org.apache.hadoop.io.compress.CodecPool -42338 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:16,320 - com.infogen.hdfs.InfoGen_LZOOutputStream -42576 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/15/-0.4709940
[framework] 2015-12-18 15:25:16,503 - org.apache.hadoop.io.compress.CodecPool -42759 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:16,636 - com.infogen.hdfs.InfoGen_LZOOutputStream -42892 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/16/-0.4711460
[framework] 2015-12-18 15:25:16,728 - org.apache.hadoop.io.compress.CodecPool -42984 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:16,900 - com.infogen.hdfs.InfoGen_LZOOutputStream -43156 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/17/-0.4713722
[framework] 2015-12-18 15:25:17,052 - org.apache.hadoop.io.compress.CodecPool -43308 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:19,399 - com.infogen.hdfs.InfoGen_LZOOutputStream -45655 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/18/-0.4715104
[framework] 2015-12-18 15:25:19,537 - org.apache.hadoop.io.compress.CodecPool -45793 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:19,660 - com.infogen.hdfs.InfoGen_LZOOutputStream -45916 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/19/-0.4715526
[framework] 2015-12-18 15:25:19,816 - org.apache.hadoop.io.compress.CodecPool -46072 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:19,915 - com.infogen.hdfs.InfoGen_LZOOutputStream -46171 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/20/-0.4715998
[framework] 2015-12-18 15:25:20,087 - org.apache.hadoop.io.compress.CodecPool -46343 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:20,205 - com.infogen.hdfs.InfoGen_LZOOutputStream -46461 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/21/-0.4716505
[framework] 2015-12-18 15:25:20,409 - org.apache.hadoop.io.compress.CodecPool -46665 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:20,530 - com.infogen.hdfs.InfoGen_LZOOutputStream -46786 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/22/-0.4716543
[framework] 2015-12-18 15:25:20,894 - org.apache.hadoop.io.compress.CodecPool -47150 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:20,995 - com.infogen.hdfs.InfoGen_LZOOutputStream -47251 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/23/-0.4716567
[framework] 2015-12-18 15:25:21,136 - org.apache.hadoop.io.compress.CodecPool -47392 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:21,247 - com.infogen.hdfs.InfoGen_LZOOutputStream -47503 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/0/-0.4716603
[framework] 2015-12-18 15:25:21,321 - org.apache.hadoop.io.compress.CodecPool -47577 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:21,748 - com.infogen.hdfs.InfoGen_LZOOutputStream -48004 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/1/-0.4716624
[framework] 2015-12-18 15:25:21,814 - org.apache.hadoop.io.compress.CodecPool -48070 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:21,936 - com.infogen.hdfs.InfoGen_LZOOutputStream -48192 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/2/-0.4716639
[framework] 2015-12-18 15:25:22,011 - org.apache.hadoop.io.compress.CodecPool -48267 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:22,120 - com.infogen.hdfs.InfoGen_LZOOutputStream -48376 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/3/-0.4716654
[framework] 2015-12-18 15:25:22,190 - org.apache.hadoop.io.compress.CodecPool -48446 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:25:22,309 - com.infogen.hdfs.InfoGen_LZOOutputStream -48565 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/4/-0.4716666
[framework] 2015-12-18 15:25:22,612 - org.apache.hadoop.io.compress.CodecPool -48868 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:51:26,898 - com.infogen.zookeeper.InfoGen_ZooKeeper -1    [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-18 15:51:26,944 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[framework] 2015-12-18 15:51:26,945 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:host.name=localhost
[framework] 2015-12-18 15:51:26,945 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_20
[framework] 2015-12-18 15:51:26,945 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
[framework] 2015-12-18 15:51:26,945 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/lib/jvm/java-8-sun/jre
[framework] 2015-12-18 15:51:26,945 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/home/juxinli/workspace/infogen_etl/target/classes:/home/juxinli/workspace/infogen_etl/lib/hadoop-lzo-0.4.20-SNAPSHOT.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-client/2.7.1/hadoop-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-common/2.7.1/hadoop-common-2.7.1.jar:/home/juxinli/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/juxinli/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/juxinli/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/juxinli/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/juxinli/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/juxinli/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/juxinli/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/juxinli/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/juxinli/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/juxinli/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/juxinli/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/juxinli/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/juxinli/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/juxinli/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/juxinli/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/juxinli/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/juxinli/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.1/hadoop-auth-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/home/juxinli/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/juxinli/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/juxinli/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.1/hadoop-hdfs-2.7.1.jar:/home/juxinli/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/juxinli/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/juxinli/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/juxinli/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/juxinli/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.1/hadoop-mapreduce-client-app-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.1/hadoop-mapreduce-client-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.1/hadoop-yarn-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.1/hadoop-yarn-server-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.1/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.1/hadoop-yarn-api-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.1/hadoop-mapreduce-client-core-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.1/hadoop-yarn-common-2.7.1.jar:/home/juxinli/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/juxinli/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/juxinli/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/juxinli/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.1/hadoop-mapreduce-client-jobclient-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.1/hadoop-annotations-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka_2.11/0.8.2.2/kafka_2.11-0.8.2.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/juxinli/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar:/home/juxinli/.m2/repository/org/scala-lang/scala-library/2.11.5/scala-library-2.11.5.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.2/kafka-clients-0.8.2.2.jar:/home/juxinli/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/juxinli/.m2/repository/net/jpountz/lz4/lz4/1.2.0/lz4-1.2.0.jar:/home/juxinli/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/juxinli/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/juxinli/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/juxinli/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar
[framework] 2015-12-18 15:51:26,946 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[framework] 2015-12-18 15:51:26,946 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp
[framework] 2015-12-18 15:51:26,946 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
[framework] 2015-12-18 15:51:26,946 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
[framework] 2015-12-18 15:51:26,946 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
[framework] 2015-12-18 15:51:26,946 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.2.0-21-generic
[framework] 2015-12-18 15:51:26,946 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.name=juxinli
[framework] 2015-12-18 15:51:26,946 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/juxinli
[framework] 2015-12-18 15:51:26,946 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/home/juxinli/workspace/infogen_etl
[framework] 2015-12-18 15:51:26,948 - org.apache.zookeeper.ZooKeeper -51   [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@5ae63ade
[framework] 2015-12-18 15:51:26,978 - com.infogen.zookeeper.InfoGen_ZooKeeper -81   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-18 15:51:26,981 - com.infogen.zookeeper.InfoGen_ZooKeeper -84   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers
[framework] 2015-12-18 15:51:26,982 - org.apache.zookeeper.ClientCnxn -85   [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.98/172.16.8.98:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-18 15:51:27,055 - org.apache.zookeeper.ClientCnxn -158  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.98/172.16.8.98:2181, initiating session
[framework] 2015-12-18 15:51:27,082 - org.apache.zookeeper.ClientCnxn -185  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.98/172.16.8.98:2181, sessionid = 0x6250c64e4256078f, negotiated timeout = 10000
[framework] 2015-12-18 15:51:27,085 - com.infogen.zookeeper.InfoGen_ZooKeeper -188  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-18 15:51:27,102 - com.infogen.zookeeper.InfoGen_ZooKeeper -205  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers
[framework] 2015-12-18 15:51:27,103 - com.infogen.zookeeper.InfoGen_ZooKeeper -206  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-18 15:51:27,124 - com.infogen.zookeeper.InfoGen_ZooKeeper -227  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-18 15:51:27,124 - com.infogen.zookeeper.InfoGen_ZooKeeper -227  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/infogen_etl
[framework] 2015-12-18 15:51:27,141 - com.infogen.zookeeper.InfoGen_ZooKeeper -244  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/infogen_etl
[framework] 2015-12-18 15:51:27,142 - com.infogen.zookeeper.InfoGen_ZooKeeper -245  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset
[framework] 2015-12-18 15:51:27,378 - com.infogen.zookeeper.InfoGen_ZooKeeper -481  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset
[framework] 2015-12-18 15:51:27,378 - com.infogen.zookeeper.InfoGen_ZooKeeper -481  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/infogen_etl/partition
[framework] 2015-12-18 15:51:27,396 - com.infogen.zookeeper.InfoGen_ZooKeeper -499  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/partition
[framework] 2015-12-18 15:51:27,396 - com.infogen.zookeeper.InfoGen_ZooKeeper -499  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/ids
[framework] 2015-12-18 15:51:27,419 - com.infogen.zookeeper.InfoGen_ZooKeeper -522  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/ids
[framework] 2015-12-18 15:51:27,419 - com.infogen.zookeeper.InfoGen_ZooKeeper -522  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/1
[framework] 2015-12-18 15:51:27,448 - com.infogen.zookeeper.InfoGen_ZooKeeper -551  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/1
[framework] 2015-12-18 15:51:27,448 - com.infogen.zookeeper.InfoGen_ZooKeeper -551  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/2
[framework] 2015-12-18 15:51:27,464 - com.infogen.zookeeper.InfoGen_ZooKeeper -567  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/2
[framework] 2015-12-18 15:51:27,464 - com.infogen.zookeeper.InfoGen_ZooKeeper -567  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/3
[framework] 2015-12-18 15:51:27,478 - com.infogen.zookeeper.InfoGen_ZooKeeper -581  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/3
[framework] 2015-12-18 15:51:27,479 - com.infogen.etl.InfoGen_Container -582  [main] INFO  com.infogen.etl.InfoGen_Container  - #broker为：172.16.8.97:10086,172.16.8.98:10086,172.16.8.99:10086
[framework] 2015-12-18 15:51:27,479 - com.infogen.zookeeper.InfoGen_ZooKeeper -582  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-18 15:51:27,492 - com.infogen.zookeeper.InfoGen_ZooKeeper -595  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-18 15:51:27,493 - com.infogen.zookeeper.InfoGen_ZooKeeper -596  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset/0
[framework] 2015-12-18 15:51:27,507 - com.infogen.zookeeper.InfoGen_ZooKeeper -610  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset/0
[framework] 2015-12-18 15:51:27,512 - com.infogen.zookeeper.InfoGen_ZooKeeper -615  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/infogen_etl/partition/0
[framework] 2015-12-18 15:51:27,531 - com.infogen.zookeeper.InfoGen_ZooKeeper -634  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/partition/0
[framework] 2015-12-18 15:51:27,533 - com.infogen.etl.InfoGen_Container -636  [main] INFO  com.infogen.etl.InfoGen_Container  - #获取partition成功:0
[framework] 2015-12-18 15:51:27,533 - com.infogen.etl.InfoGen_Container -636  [main] INFO  com.infogen.etl.InfoGen_Container  - #partition为：0
[framework] 2015-12-18 15:51:27,534 - com.infogen.zookeeper.InfoGen_ZooKeeper -637  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset/0
[framework] 2015-12-18 15:51:27,558 - com.infogen.zookeeper.InfoGen_ZooKeeper -661  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset/0
[framework] 2015-12-18 15:51:27,558 - com.infogen.etl.InfoGen_Container -661  [main] INFO  com.infogen.etl.InfoGen_Container  - #使用zookeeper 中 offset为:null
[framework] 2015-12-18 15:51:27,558 - com.infogen.etl.InfoGen_Container -661  [main] INFO  com.infogen.etl.InfoGen_Container  - #zookeeper_offset为：4641635
[framework] 2015-12-18 15:51:27,559 - com.infogen.zookeeper.InfoGen_ZooKeeper -662  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 关闭zookeeper
[framework] 2015-12-18 15:51:27,579 - org.apache.zookeeper.ClientCnxn -682  [main-EventThread] INFO  org.apache.zookeeper.ClientCnxn  - EventThread shut down
[framework] 2015-12-18 15:51:27,580 - org.apache.zookeeper.ZooKeeper -683  [main] INFO  org.apache.zookeeper.ZooKeeper  - Session: 0x6250c64e4256078f closed
[framework] 2015-12-18 15:51:27,580 - com.infogen.zookeeper.InfoGen_ZooKeeper -683  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 关闭zookeeper成功
[framework] 2015-12-18 15:51:27,580 - com.infogen.etl.InfoGen_Container -683  [main] INFO  com.infogen.etl.InfoGen_Container  - #执行ETL commit_offset为：4641635
[framework] 2015-12-18 15:51:27,587 - com.infogen.zookeeper.InfoGen_ZooKeeper -690  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-18 15:51:27,587 - org.apache.zookeeper.ZooKeeper -690  [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@23d2a7e8
[framework] 2015-12-18 15:51:27,588 - com.infogen.zookeeper.InfoGen_ZooKeeper -691  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-18 15:51:27,589 - com.infogen.kafka.InfoGen_Consumer -692  [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #获取指定Topic partition的元数据：topic-infogen_topic_tracking partition-0
[framework] 2015-12-18 15:51:27,589 - org.apache.zookeeper.ClientCnxn -692  [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.97/172.16.8.97:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-18 15:51:27,602 - org.apache.zookeeper.ClientCnxn -705  [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.97/172.16.8.97:2181, initiating session
[framework] 2015-12-18 15:51:27,620 - org.apache.zookeeper.ClientCnxn -723  [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.97/172.16.8.97:2181, sessionid = 0x614f1aad4d9c8275, negotiated timeout = 10000
[framework] 2015-12-18 15:51:27,620 - com.infogen.zookeeper.InfoGen_ZooKeeper -723  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-18 15:51:28,328 - com.infogen.kafka.InfoGen_Consumer -1431 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #leaderBroker：172.16.8.98
[framework] 2015-12-18 15:51:28,328 - com.infogen.kafka.InfoGen_Consumer -1431 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #leaderPort：10086
[framework] 2015-12-18 15:51:28,329 - com.infogen.kafka.InfoGen_Consumer -1432 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #clientId：Client_infogen_topic_tracking_0_1450425088329
[framework] 2015-12-18 15:51:28,435 - com.infogen.kafka.InfoGen_Consumer -1538 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #offset：4641635:earliestOffset-4590888 latestOffset-4726739
[framework] 2015-12-18 15:51:28,435 - com.infogen.kafka.InfoGen_Consumer -1538 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #开始ETL：单次获取字节数-2097152 最高重试fetch次数-5  最多未commit消息大小-67108864  最多未commit时间-300000
[framework] 2015-12-18 15:51:31,422 - org.apache.hadoop.util.NativeCodeLoader -4525 [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-18 15:51:32,561 - com.infogen.hdfs.InfoGen_LZOOutputStream -5664 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/-0.4641635
[framework] 2015-12-18 15:51:32,757 - com.hadoop.compression.lzo.GPLNativeCodeLoader -5860 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-18 15:51:32,759 - com.hadoop.compression.lzo.LzoCodec -5862 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-18 15:51:32,761 - org.apache.hadoop.conf.Configuration.deprecation -5864 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-18 15:51:32,763 - org.apache.hadoop.io.compress.CodecPool -5866 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:51:32,975 - com.infogen.hdfs.InfoGen_LZOOutputStream -6078 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/18/-0.4641635
[framework] 2015-12-18 15:51:33,722 - org.apache.hadoop.io.compress.CodecPool -6825 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:51:33,847 - com.infogen.hdfs.InfoGen_LZOOutputStream -6950 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/19/-0.4641635
[framework] 2015-12-18 15:51:34,053 - org.apache.hadoop.io.compress.CodecPool -7156 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:51:34,140 - com.infogen.hdfs.InfoGen_LZOOutputStream -7243 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/20/-0.4641635
[framework] 2015-12-18 15:51:34,238 - org.apache.hadoop.io.compress.CodecPool -7341 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:51:34,548 - com.infogen.hdfs.InfoGen_LZOOutputStream -7651 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/21/-0.4641635
[framework] 2015-12-18 15:51:34,626 - org.apache.hadoop.io.compress.CodecPool -7729 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:51:34,720 - com.infogen.hdfs.InfoGen_LZOOutputStream -7823 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/22/-0.4641635
[framework] 2015-12-18 15:51:34,810 - org.apache.hadoop.io.compress.CodecPool -7913 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:51:34,910 - com.infogen.hdfs.InfoGen_LZOOutputStream -8013 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/23/-0.4641635
[framework] 2015-12-18 15:51:35,013 - org.apache.hadoop.io.compress.CodecPool -8116 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:51:35,108 - com.infogen.hdfs.InfoGen_LZOOutputStream -8211 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/0/-0.4641635
[framework] 2015-12-18 15:51:35,207 - org.apache.hadoop.io.compress.CodecPool -8310 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:51:35,306 - com.infogen.hdfs.InfoGen_LZOOutputStream -8409 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/1/-0.4641635
[framework] 2015-12-18 15:51:35,400 - org.apache.hadoop.io.compress.CodecPool -8503 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:51:35,484 - com.infogen.hdfs.InfoGen_LZOOutputStream -8587 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/2/-0.4641635
[framework] 2015-12-18 15:51:35,564 - org.apache.hadoop.io.compress.CodecPool -8667 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:51:35,628 - com.infogen.hdfs.InfoGen_LZOOutputStream -8731 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/3/-0.4641635
[framework] 2015-12-18 15:51:35,715 - org.apache.hadoop.io.compress.CodecPool -8818 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:51:35,784 - com.infogen.hdfs.InfoGen_LZOOutputStream -8887 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/4/-0.4641635
[framework] 2015-12-18 15:51:35,875 - org.apache.hadoop.io.compress.CodecPool -8978 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:51:35,949 - com.infogen.hdfs.InfoGen_LZOOutputStream -9052 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/6/-0.4641635
[framework] 2015-12-18 15:51:36,038 - org.apache.hadoop.io.compress.CodecPool -9141 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:51:36,106 - com.infogen.hdfs.InfoGen_LZOOutputStream -9209 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/7/-0.4641635
[framework] 2015-12-18 15:51:36,548 - org.apache.hadoop.io.compress.CodecPool -9651 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:51:41,275 - com.infogen.hdfs.InfoGen_LZOOutputStream -14378 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/8/-0.4641635
[framework] 2015-12-18 15:51:42,125 - org.apache.hadoop.io.compress.CodecPool -15228 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:51:42,191 - com.infogen.hdfs.InfoGen_LZOOutputStream -15294 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/9/-0.4641635
[framework] 2015-12-18 15:51:42,264 - org.apache.hadoop.io.compress.CodecPool -15367 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:51:42,585 - com.infogen.hdfs.InfoGen_LZOOutputStream -15688 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/10/-0.4641635
[framework] 2015-12-18 15:51:42,672 - org.apache.hadoop.io.compress.CodecPool -15775 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:51:43,013 - com.infogen.hdfs.InfoGen_LZOOutputStream -16116 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/11/-0.4641635
[framework] 2015-12-18 15:51:43,095 - org.apache.hadoop.io.compress.CodecPool -16198 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 15:51:43,184 - com.infogen.hdfs.InfoGen_LZOOutputStream -16287 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/12/-0.4641635
[framework] 2015-12-18 15:53:13,758 - com.infogen.zookeeper.InfoGen_ZooKeeper -0    [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-18 15:53:13,805 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[framework] 2015-12-18 15:53:13,805 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:host.name=localhost
[framework] 2015-12-18 15:53:13,805 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_20
[framework] 2015-12-18 15:53:13,805 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
[framework] 2015-12-18 15:53:13,805 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/lib/jvm/java-8-sun/jre
[framework] 2015-12-18 15:53:13,805 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/home/juxinli/workspace/infogen_etl/target/classes:/home/juxinli/workspace/infogen_etl/lib/hadoop-lzo-0.4.20-SNAPSHOT.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-client/2.7.1/hadoop-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-common/2.7.1/hadoop-common-2.7.1.jar:/home/juxinli/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/juxinli/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/juxinli/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/juxinli/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/juxinli/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/juxinli/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/juxinli/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/juxinli/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/juxinli/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/juxinli/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/juxinli/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/juxinli/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/juxinli/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/juxinli/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/juxinli/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/juxinli/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/juxinli/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.1/hadoop-auth-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/home/juxinli/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/juxinli/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/juxinli/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.1/hadoop-hdfs-2.7.1.jar:/home/juxinli/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/juxinli/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/juxinli/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/juxinli/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/juxinli/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.1/hadoop-mapreduce-client-app-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.1/hadoop-mapreduce-client-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.1/hadoop-yarn-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.1/hadoop-yarn-server-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.1/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.1/hadoop-yarn-api-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.1/hadoop-mapreduce-client-core-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.1/hadoop-yarn-common-2.7.1.jar:/home/juxinli/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/juxinli/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/juxinli/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/juxinli/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.1/hadoop-mapreduce-client-jobclient-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.1/hadoop-annotations-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka_2.11/0.8.2.2/kafka_2.11-0.8.2.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/juxinli/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar:/home/juxinli/.m2/repository/org/scala-lang/scala-library/2.11.5/scala-library-2.11.5.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.2/kafka-clients-0.8.2.2.jar:/home/juxinli/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/juxinli/.m2/repository/net/jpountz/lz4/lz4/1.2.0/lz4-1.2.0.jar:/home/juxinli/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/juxinli/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/juxinli/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/juxinli/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar
[framework] 2015-12-18 15:53:13,806 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[framework] 2015-12-18 15:53:13,806 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp
[framework] 2015-12-18 15:53:13,806 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
[framework] 2015-12-18 15:53:13,806 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
[framework] 2015-12-18 15:53:13,806 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
[framework] 2015-12-18 15:53:13,807 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.2.0-21-generic
[framework] 2015-12-18 15:53:13,807 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.name=juxinli
[framework] 2015-12-18 15:53:13,807 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/juxinli
[framework] 2015-12-18 15:53:13,807 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/home/juxinli/workspace/infogen_etl
[framework] 2015-12-18 15:53:13,808 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@5ae63ade
[framework] 2015-12-18 15:53:13,844 - com.infogen.zookeeper.InfoGen_ZooKeeper -86   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-18 15:53:13,847 - com.infogen.zookeeper.InfoGen_ZooKeeper -89   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers
[framework] 2015-12-18 15:53:13,858 - org.apache.zookeeper.ClientCnxn -100  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.98/172.16.8.98:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-18 15:53:13,934 - org.apache.zookeeper.ClientCnxn -176  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.98/172.16.8.98:2181, initiating session
[framework] 2015-12-18 15:53:13,960 - org.apache.zookeeper.ClientCnxn -202  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.98/172.16.8.98:2181, sessionid = 0x6250c64e42560790, negotiated timeout = 10000
[framework] 2015-12-18 15:53:13,963 - com.infogen.zookeeper.InfoGen_ZooKeeper -205  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-18 15:53:13,984 - com.infogen.zookeeper.InfoGen_ZooKeeper -226  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers
[framework] 2015-12-18 15:53:13,984 - com.infogen.zookeeper.InfoGen_ZooKeeper -226  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-18 15:53:14,002 - com.infogen.zookeeper.InfoGen_ZooKeeper -244  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-18 15:53:14,002 - com.infogen.zookeeper.InfoGen_ZooKeeper -244  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/infogen_etl
[framework] 2015-12-18 15:53:14,025 - com.infogen.zookeeper.InfoGen_ZooKeeper -267  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/infogen_etl
[framework] 2015-12-18 15:53:14,025 - com.infogen.zookeeper.InfoGen_ZooKeeper -267  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset
[framework] 2015-12-18 15:53:14,044 - com.infogen.zookeeper.InfoGen_ZooKeeper -286  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset
[framework] 2015-12-18 15:53:14,045 - com.infogen.zookeeper.InfoGen_ZooKeeper -287  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/infogen_etl/partition
[framework] 2015-12-18 15:53:14,075 - com.infogen.zookeeper.InfoGen_ZooKeeper -317  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/partition
[framework] 2015-12-18 15:53:14,075 - com.infogen.zookeeper.InfoGen_ZooKeeper -317  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/ids
[framework] 2015-12-18 15:53:14,100 - com.infogen.zookeeper.InfoGen_ZooKeeper -342  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/ids
[framework] 2015-12-18 15:53:14,100 - com.infogen.zookeeper.InfoGen_ZooKeeper -342  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/1
[framework] 2015-12-18 15:53:14,165 - com.infogen.zookeeper.InfoGen_ZooKeeper -407  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/1
[framework] 2015-12-18 15:53:14,166 - com.infogen.zookeeper.InfoGen_ZooKeeper -408  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/2
[framework] 2015-12-18 15:53:14,186 - com.infogen.zookeeper.InfoGen_ZooKeeper -428  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/2
[framework] 2015-12-18 15:53:14,186 - com.infogen.zookeeper.InfoGen_ZooKeeper -428  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/3
[framework] 2015-12-18 15:53:14,200 - com.infogen.zookeeper.InfoGen_ZooKeeper -442  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/3
[framework] 2015-12-18 15:53:14,201 - com.infogen.etl.InfoGen_Container -443  [main] INFO  com.infogen.etl.InfoGen_Container  - #broker为：172.16.8.97:10086,172.16.8.98:10086,172.16.8.99:10086
[framework] 2015-12-18 15:53:14,201 - com.infogen.zookeeper.InfoGen_ZooKeeper -443  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-18 15:53:14,219 - com.infogen.zookeeper.InfoGen_ZooKeeper -461  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-18 15:53:14,219 - com.infogen.zookeeper.InfoGen_ZooKeeper -461  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset/0
[framework] 2015-12-18 15:53:14,246 - com.infogen.zookeeper.InfoGen_ZooKeeper -488  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset/0
[framework] 2015-12-18 15:53:14,250 - com.infogen.zookeeper.InfoGen_ZooKeeper -492  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/infogen_etl/partition/0
[framework] 2015-12-18 15:53:14,269 - com.infogen.zookeeper.InfoGen_ZooKeeper -511  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/partition/0
[framework] 2015-12-18 15:53:14,271 - com.infogen.etl.InfoGen_Container -513  [main] INFO  com.infogen.etl.InfoGen_Container  - #获取partition成功:0
[framework] 2015-12-18 15:53:14,271 - com.infogen.etl.InfoGen_Container -513  [main] INFO  com.infogen.etl.InfoGen_Container  - #partition为：0
[framework] 2015-12-18 15:53:14,271 - com.infogen.zookeeper.InfoGen_ZooKeeper -513  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset/0
[framework] 2015-12-18 15:53:14,313 - com.infogen.zookeeper.InfoGen_ZooKeeper -555  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset/0
[framework] 2015-12-18 15:53:14,314 - com.infogen.etl.InfoGen_Container -556  [main] INFO  com.infogen.etl.InfoGen_Container  - #使用zookeeper 中 offset为:null
[framework] 2015-12-18 15:53:14,314 - com.infogen.etl.InfoGen_Container -556  [main] INFO  com.infogen.etl.InfoGen_Container  - #zookeeper_offset为：4641635
[framework] 2015-12-18 15:53:14,314 - com.infogen.zookeeper.InfoGen_ZooKeeper -556  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 关闭zookeeper
[framework] 2015-12-18 15:53:14,338 - org.apache.zookeeper.ZooKeeper -580  [main] INFO  org.apache.zookeeper.ZooKeeper  - Session: 0x6250c64e42560790 closed
[framework] 2015-12-18 15:53:14,338 - org.apache.zookeeper.ClientCnxn -580  [main-EventThread] INFO  org.apache.zookeeper.ClientCnxn  - EventThread shut down
[framework] 2015-12-18 15:53:14,338 - com.infogen.zookeeper.InfoGen_ZooKeeper -580  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 关闭zookeeper成功
[framework] 2015-12-18 15:53:14,339 - com.infogen.etl.InfoGen_Container -581  [main] INFO  com.infogen.etl.InfoGen_Container  - #执行ETL commit_offset为：4641635
[framework] 2015-12-18 15:53:14,347 - com.infogen.zookeeper.InfoGen_ZooKeeper -589  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-18 15:53:14,348 - org.apache.zookeeper.ZooKeeper -590  [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@23d2a7e8
[framework] 2015-12-18 15:53:14,349 - com.infogen.zookeeper.InfoGen_ZooKeeper -591  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-18 15:53:14,349 - org.apache.zookeeper.ClientCnxn -591  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.98/172.16.8.98:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-18 15:53:14,349 - com.infogen.kafka.InfoGen_Consumer -591  [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #获取指定Topic partition的元数据：topic-infogen_topic_tracking partition-0
[framework] 2015-12-18 15:53:14,366 - org.apache.zookeeper.ClientCnxn -608  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.98/172.16.8.98:2181, initiating session
[framework] 2015-12-18 15:53:14,618 - org.apache.zookeeper.ClientCnxn -860  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.98/172.16.8.98:2181, sessionid = 0x6250c64e42560791, negotiated timeout = 10000
[framework] 2015-12-18 15:53:14,618 - com.infogen.zookeeper.InfoGen_ZooKeeper -860  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-18 15:53:14,968 - com.infogen.kafka.InfoGen_Consumer -1210 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #leaderBroker：172.16.8.98
[framework] 2015-12-18 15:53:14,968 - com.infogen.kafka.InfoGen_Consumer -1210 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #leaderPort：10086
[framework] 2015-12-18 15:53:14,969 - com.infogen.kafka.InfoGen_Consumer -1211 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #clientId：Client_infogen_topic_tracking_0_1450425194969
[framework] 2015-12-18 15:53:15,079 - com.infogen.kafka.InfoGen_Consumer -1321 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #offset：4641635:earliestOffset-4590888 latestOffset-4726800
[framework] 2015-12-18 15:53:15,079 - com.infogen.kafka.InfoGen_Consumer -1321 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #开始ETL：单次获取字节数-2097152 最高重试fetch次数-5  最多未commit消息大小-67108864  最多未commit时间-300000
[framework] 2015-12-18 15:53:18,000 - org.apache.hadoop.util.NativeCodeLoader -4242 [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-18 15:53:20,050 - com.infogen.hdfs.InfoGen_LZOOutputStream -6292 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/-0.4641635
[framework] 2015-12-18 15:53:20,298 - com.hadoop.compression.lzo.GPLNativeCodeLoader -6540 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-18 15:53:20,301 - com.hadoop.compression.lzo.LzoCodec -6543 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-18 15:53:20,652 - com.infogen.hdfs.InfoGen_LZOOutputStream -6894 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/18/-0.4641635
[framework] 2015-12-18 15:53:21,339 - com.infogen.hdfs.InfoGen_LZOOutputStream -7581 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/19/-0.4641635
[framework] 2015-12-18 15:53:22,520 - com.infogen.hdfs.InfoGen_LZOOutputStream -8762 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/20/-0.4641635
[framework] 2015-12-18 15:53:23,475 - com.infogen.hdfs.InfoGen_LZOOutputStream -9717 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/21/-0.4641635
[framework] 2015-12-18 15:53:23,695 - com.infogen.hdfs.InfoGen_LZOOutputStream -9937 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/22/-0.4641635
[framework] 2015-12-18 15:53:23,990 - com.infogen.hdfs.InfoGen_LZOOutputStream -10232 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/23/-0.4641635
[framework] 2015-12-18 15:53:24,254 - com.infogen.hdfs.InfoGen_LZOOutputStream -10496 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/0/-0.4641635
[framework] 2015-12-18 15:53:24,497 - com.infogen.hdfs.InfoGen_LZOOutputStream -10739 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/1/-0.4641635
[framework] 2015-12-18 15:53:24,791 - com.infogen.hdfs.InfoGen_LZOOutputStream -11033 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/2/-0.4641635
[framework] 2015-12-18 15:53:25,206 - com.infogen.hdfs.InfoGen_LZOOutputStream -11448 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/3/-0.4641635
[framework] 2015-12-18 15:53:25,444 - com.infogen.hdfs.InfoGen_LZOOutputStream -11686 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/4/-0.4641635
[framework] 2015-12-18 15:53:25,748 - com.infogen.hdfs.InfoGen_LZOOutputStream -11990 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/6/-0.4641635
[framework] 2015-12-18 15:53:26,190 - com.infogen.hdfs.InfoGen_LZOOutputStream -12432 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/7/-0.4641635
[framework] 2015-12-18 15:53:29,351 - com.infogen.hdfs.InfoGen_LZOOutputStream -15593 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/8/-0.4641635
[framework] 2015-12-18 15:53:29,564 - com.infogen.hdfs.InfoGen_LZOOutputStream -15806 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/9/-0.4641635
[framework] 2015-12-18 15:53:29,794 - com.infogen.hdfs.InfoGen_LZOOutputStream -16036 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/10/-0.4641635
[framework] 2015-12-18 15:53:30,141 - com.infogen.hdfs.InfoGen_LZOOutputStream -16383 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/11/-0.4641635
[framework] 2015-12-18 15:53:30,343 - com.infogen.hdfs.InfoGen_LZOOutputStream -16585 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/12/-0.4641635
[framework] 2015-12-18 15:53:30,542 - com.infogen.hdfs.InfoGen_LZOOutputStream -16784 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/13/-0.4641635
[framework] 2015-12-18 15:53:30,713 - com.infogen.hdfs.InfoGen_LZOOutputStream -16955 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/14/-0.4641635
[framework] 2015-12-18 15:53:30,843 - com.infogen.hdfs.InfoGen_LZOOutputStream -17085 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/19/-0.4641635
[framework] 2015-12-18 15:53:31,554 - com.infogen.hdfs.InfoGen_LZOOutputStream -17796 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/18/-0.4641635
[framework] 2015-12-18 15:53:31,899 - com.infogen.hdfs.InfoGen_LZOOutputStream -18141 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/-0.4641635
[framework] 2015-12-18 15:53:32,116 - com.infogen.hdfs.InfoGen_LZOOutputStream -18358 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/21/-0.4641635
[framework] 2015-12-18 15:53:32,686 - com.infogen.hdfs.InfoGen_LZOOutputStream -18928 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/20/-0.4641635
[framework] 2015-12-18 15:53:32,964 - com.infogen.hdfs.InfoGen_LZOOutputStream -19206 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/23/-0.4641635
[framework] 2015-12-18 15:53:33,265 - com.infogen.hdfs.InfoGen_LZOOutputStream -19507 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/22/-0.4641635
[framework] 2015-12-18 15:53:33,607 - com.infogen.hdfs.InfoGen_LZOOutputStream -19849 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/1/-0.4641635
[framework] 2015-12-18 15:53:33,932 - com.infogen.hdfs.InfoGen_LZOOutputStream -20174 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/2/-0.4641635
[framework] 2015-12-18 15:53:34,232 - com.infogen.hdfs.InfoGen_LZOOutputStream -20474 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/0/-0.4641635
[framework] 2015-12-18 15:53:34,649 - com.infogen.hdfs.InfoGen_LZOOutputStream -20891 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/6/-0.4641635
[framework] 2015-12-18 15:53:35,245 - com.infogen.hdfs.InfoGen_LZOOutputStream -21487 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/3/-0.4641635
[framework] 2015-12-18 15:53:35,549 - com.infogen.hdfs.InfoGen_LZOOutputStream -21791 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/4/-0.4641635
[framework] 2015-12-18 15:53:35,851 - com.infogen.hdfs.InfoGen_LZOOutputStream -22093 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/9/-0.4641635
[framework] 2015-12-18 15:53:36,297 - com.infogen.hdfs.InfoGen_LZOOutputStream -22539 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/7/-0.4641635
[framework] 2015-12-18 15:53:36,600 - com.infogen.hdfs.InfoGen_LZOOutputStream -22842 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/8/-0.4641635
[framework] 2015-12-18 15:53:37,191 - com.infogen.hdfs.InfoGen_LZOOutputStream -23433 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/14/-0.4641635
[framework] 2015-12-18 15:53:37,422 - com.infogen.hdfs.InfoGen_LZOOutputStream -23664 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/12/-0.4641635
[framework] 2015-12-18 15:53:37,946 - com.infogen.hdfs.InfoGen_LZOOutputStream -24188 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/13/-0.4641635
[framework] 2015-12-18 15:53:38,724 - com.infogen.hdfs.InfoGen_LZOOutputStream -24966 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/10/-0.4641635
[framework] 2015-12-18 15:53:38,977 - com.infogen.hdfs.InfoGen_LZOOutputStream -25219 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/11/-0.4641635
[framework] 2015-12-18 15:53:39,172 - com.infogen.kafka.InfoGen_Consumer -25414 [main] ERROR com.infogen.kafka.InfoGen_Consumer  - #关闭流成功 : commit_offset-4641635 offset-4663209
[framework] 2015-12-18 15:53:39,192 - com.infogen.kafka.InfoGen_Consumer -25434 [main] ERROR com.infogen.kafka.InfoGen_Consumer  - #更新offset成功 : commit_offset-4663209 offset-4663209
[framework] 2015-12-18 15:53:41,014 - com.infogen.hdfs.InfoGen_LZOOutputStream -27256 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/14/-0.4663209
[framework] 2015-12-18 15:53:41,187 - com.infogen.hdfs.InfoGen_LZOOutputStream -27429 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/15/-0.4663209
[framework] 2015-12-18 15:53:41,339 - com.infogen.hdfs.InfoGen_LZOOutputStream -27581 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/16/-0.4663209
[framework] 2015-12-18 15:53:41,468 - com.infogen.hdfs.InfoGen_LZOOutputStream -27710 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/17/-0.4663209
[framework] 2015-12-18 15:53:41,613 - com.infogen.hdfs.InfoGen_LZOOutputStream -27855 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/18/-0.4663209
[framework] 2015-12-18 15:53:41,858 - com.infogen.hdfs.InfoGen_LZOOutputStream -28100 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/19/-0.4663209
[framework] 2015-12-18 15:53:42,388 - com.infogen.hdfs.InfoGen_LZOOutputStream -28630 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/20/-0.4663209
[framework] 2015-12-18 15:53:42,970 - com.infogen.hdfs.InfoGen_LZOOutputStream -29212 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/21/-0.4663209
[framework] 2015-12-18 15:53:43,403 - com.infogen.hdfs.InfoGen_LZOOutputStream -29645 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/22/-0.4663209
[framework] 2015-12-18 15:53:43,553 - com.infogen.hdfs.InfoGen_LZOOutputStream -29795 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/23/-0.4663209
[framework] 2015-12-18 15:53:43,711 - com.infogen.hdfs.InfoGen_LZOOutputStream -29953 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/0/-0.4663209
[framework] 2015-12-18 15:53:43,909 - com.infogen.hdfs.InfoGen_LZOOutputStream -30151 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/1/-0.4663209
[framework] 2015-12-18 15:53:44,111 - com.infogen.hdfs.InfoGen_LZOOutputStream -30353 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/3/-0.4663209
[framework] 2015-12-18 15:53:44,463 - com.infogen.hdfs.InfoGen_LZOOutputStream -30705 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/4/-0.4663209
[framework] 2015-12-18 15:53:44,614 - com.infogen.hdfs.InfoGen_LZOOutputStream -30856 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/6/-0.4663209
[framework] 2015-12-18 15:53:44,873 - com.infogen.hdfs.InfoGen_LZOOutputStream -31115 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/7/-0.4663209
[framework] 2015-12-18 16:24:35,763 - org.apache.hadoop.util.NativeCodeLoader -0    [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-18 16:24:37,694 - com.infogen.hdfs.InfoGen_LZOOutputStream -1931 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/test
[framework] 2015-12-18 16:24:37,915 - com.hadoop.compression.lzo.GPLNativeCodeLoader -2152 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-18 16:24:37,919 - com.hadoop.compression.lzo.LzoCodec -2156 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-18 16:24:37,921 - org.apache.hadoop.conf.Configuration.deprecation -2158 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-18 16:24:37,922 - org.apache.hadoop.io.compress.CodecPool -2159 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:24:41,227 - com.infogen.hdfs.InfoGen_LZOOutputStream -5464 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/test
[framework] 2015-12-18 16:26:20,586 - org.apache.hadoop.util.NativeCodeLoader -0    [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-18 16:26:21,507 - com.infogen.hdfs.InfoGen_LZOOutputStream -921  [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/test
[framework] 2015-12-18 16:26:21,729 - com.hadoop.compression.lzo.GPLNativeCodeLoader -1143 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-18 16:26:21,733 - com.hadoop.compression.lzo.LzoCodec -1147 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-18 16:26:21,736 - org.apache.hadoop.conf.Configuration.deprecation -1150 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-18 16:26:21,738 - org.apache.hadoop.io.compress.CodecPool -1152 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:27:13,419 - org.apache.hadoop.util.NativeCodeLoader -0    [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-18 16:27:14,665 - com.infogen.hdfs.InfoGen_LZOOutputStream -1246 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/test
[framework] 2015-12-18 16:27:14,895 - com.hadoop.compression.lzo.GPLNativeCodeLoader -1476 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-18 16:27:14,899 - com.hadoop.compression.lzo.LzoCodec -1480 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-18 16:27:14,901 - org.apache.hadoop.conf.Configuration.deprecation -1482 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-18 16:27:14,903 - org.apache.hadoop.io.compress.CodecPool -1484 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:28:19,154 - org.apache.hadoop.util.NativeCodeLoader -0    [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-18 16:28:20,079 - com.infogen.hdfs.InfoGen_LZOOutputStream -925  [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/test
[framework] 2015-12-18 16:28:20,341 - com.hadoop.compression.lzo.GPLNativeCodeLoader -1187 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-18 16:28:20,344 - com.hadoop.compression.lzo.LzoCodec -1190 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-18 16:28:20,349 - org.apache.hadoop.conf.Configuration.deprecation -1195 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-18 16:28:20,351 - org.apache.hadoop.io.compress.CodecPool -1197 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:29:15,146 - org.apache.hadoop.util.NativeCodeLoader -0    [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-18 16:29:16,305 - com.infogen.hdfs.InfoGen_LZOOutputStream -1159 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/test
[framework] 2015-12-18 16:29:16,515 - com.hadoop.compression.lzo.GPLNativeCodeLoader -1369 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-18 16:29:16,519 - com.hadoop.compression.lzo.LzoCodec -1373 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-18 16:29:16,522 - org.apache.hadoop.conf.Configuration.deprecation -1376 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-18 16:29:16,524 - org.apache.hadoop.io.compress.CodecPool -1378 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:30:51,942 - org.apache.hadoop.util.NativeCodeLoader -0    [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-18 16:30:54,303 - com.infogen.hdfs.InfoGen_LZOOutputStream -2361 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/test
[framework] 2015-12-18 16:30:54,488 - com.hadoop.compression.lzo.GPLNativeCodeLoader -2546 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-18 16:30:54,492 - com.hadoop.compression.lzo.LzoCodec -2550 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-18 16:30:54,496 - org.apache.hadoop.conf.Configuration.deprecation -2554 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-18 16:30:54,499 - org.apache.hadoop.io.compress.CodecPool -2557 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:31:17,667 - org.apache.hadoop.util.NativeCodeLoader -0    [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-18 16:31:18,649 - com.infogen.hdfs.InfoGen_LZOOutputStream -982  [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/test
[framework] 2015-12-18 16:31:18,835 - com.hadoop.compression.lzo.GPLNativeCodeLoader -1168 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-18 16:31:18,839 - com.hadoop.compression.lzo.LzoCodec -1172 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-18 16:31:18,842 - org.apache.hadoop.conf.Configuration.deprecation -1175 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-18 16:31:18,844 - org.apache.hadoop.io.compress.CodecPool -1177 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:33:25,519 - org.apache.hadoop.util.NativeCodeLoader -0    [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-18 16:33:26,520 - com.infogen.hdfs.InfoGen_LZOOutputStream -1001 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/test
[framework] 2015-12-18 16:33:26,721 - com.hadoop.compression.lzo.GPLNativeCodeLoader -1202 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-18 16:33:26,724 - com.hadoop.compression.lzo.LzoCodec -1205 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-18 16:33:26,726 - org.apache.hadoop.conf.Configuration.deprecation -1207 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-18 16:33:26,728 - org.apache.hadoop.io.compress.CodecPool -1209 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:33:55,802 - com.infogen.hdfs.InfoGen_LZOOutputStream -30283 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/test
[framework] 2015-12-18 16:35:05,106 - com.infogen.zookeeper.InfoGen_ZooKeeper -0    [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-18 16:35:05,154 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[framework] 2015-12-18 16:35:05,154 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:host.name=localhost
[framework] 2015-12-18 16:35:05,154 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_20
[framework] 2015-12-18 16:35:05,154 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
[framework] 2015-12-18 16:35:05,154 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/lib/jvm/java-8-sun/jre
[framework] 2015-12-18 16:35:05,154 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/home/juxinli/workspace/infogen_etl/target/classes:/home/juxinli/workspace/infogen_etl/lib/hadoop-lzo-0.4.20-SNAPSHOT.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-client/2.7.1/hadoop-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-common/2.7.1/hadoop-common-2.7.1.jar:/home/juxinli/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/juxinli/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/juxinli/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/juxinli/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/juxinli/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/juxinli/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/juxinli/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/juxinli/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/juxinli/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/juxinli/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/juxinli/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/juxinli/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/juxinli/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/juxinli/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/juxinli/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/juxinli/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/juxinli/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.1/hadoop-auth-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/home/juxinli/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/juxinli/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/juxinli/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.1/hadoop-hdfs-2.7.1.jar:/home/juxinli/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/juxinli/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/juxinli/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/juxinli/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/juxinli/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.1/hadoop-mapreduce-client-app-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.1/hadoop-mapreduce-client-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.1/hadoop-yarn-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.1/hadoop-yarn-server-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.1/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.1/hadoop-yarn-api-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.1/hadoop-mapreduce-client-core-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.1/hadoop-yarn-common-2.7.1.jar:/home/juxinli/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/juxinli/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/juxinli/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/juxinli/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.1/hadoop-mapreduce-client-jobclient-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.1/hadoop-annotations-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka_2.11/0.8.2.2/kafka_2.11-0.8.2.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/juxinli/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar:/home/juxinli/.m2/repository/org/scala-lang/scala-library/2.11.5/scala-library-2.11.5.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.2/kafka-clients-0.8.2.2.jar:/home/juxinli/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/juxinli/.m2/repository/net/jpountz/lz4/lz4/1.2.0/lz4-1.2.0.jar:/home/juxinli/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/juxinli/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/juxinli/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/juxinli/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar
[framework] 2015-12-18 16:35:05,155 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[framework] 2015-12-18 16:35:05,155 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp
[framework] 2015-12-18 16:35:05,155 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
[framework] 2015-12-18 16:35:05,156 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
[framework] 2015-12-18 16:35:05,156 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
[framework] 2015-12-18 16:35:05,156 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.2.0-21-generic
[framework] 2015-12-18 16:35:05,156 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.name=juxinli
[framework] 2015-12-18 16:35:05,156 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/juxinli
[framework] 2015-12-18 16:35:05,156 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/home/juxinli/workspace/infogen_etl
[framework] 2015-12-18 16:35:05,158 - org.apache.zookeeper.ZooKeeper -52   [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@5ae63ade
[framework] 2015-12-18 16:35:05,201 - com.infogen.zookeeper.InfoGen_ZooKeeper -95   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-18 16:35:05,204 - com.infogen.zookeeper.InfoGen_ZooKeeper -98   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers
[framework] 2015-12-18 16:35:05,206 - org.apache.zookeeper.ClientCnxn -100  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.98/172.16.8.98:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-18 16:35:05,280 - org.apache.zookeeper.ClientCnxn -174  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.98/172.16.8.98:2181, initiating session
[framework] 2015-12-18 16:35:05,541 - org.apache.zookeeper.ClientCnxn -435  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.98/172.16.8.98:2181, sessionid = 0x6250c64e42560797, negotiated timeout = 10000
[framework] 2015-12-18 16:35:05,544 - com.infogen.zookeeper.InfoGen_ZooKeeper -438  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-18 16:35:05,561 - com.infogen.zookeeper.InfoGen_ZooKeeper -455  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers
[framework] 2015-12-18 16:35:05,561 - com.infogen.zookeeper.InfoGen_ZooKeeper -455  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-18 16:35:05,580 - com.infogen.zookeeper.InfoGen_ZooKeeper -474  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-18 16:35:05,581 - com.infogen.zookeeper.InfoGen_ZooKeeper -475  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/infogen_etl
[framework] 2015-12-18 16:35:05,599 - com.infogen.zookeeper.InfoGen_ZooKeeper -493  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/infogen_etl
[framework] 2015-12-18 16:35:05,599 - com.infogen.zookeeper.InfoGen_ZooKeeper -493  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset
[framework] 2015-12-18 16:35:05,614 - com.infogen.zookeeper.InfoGen_ZooKeeper -508  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset
[framework] 2015-12-18 16:35:05,614 - com.infogen.zookeeper.InfoGen_ZooKeeper -508  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/infogen_etl/partition
[framework] 2015-12-18 16:35:05,627 - com.infogen.zookeeper.InfoGen_ZooKeeper -521  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/partition
[framework] 2015-12-18 16:35:05,628 - com.infogen.zookeeper.InfoGen_ZooKeeper -522  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/ids
[framework] 2015-12-18 16:35:05,650 - com.infogen.zookeeper.InfoGen_ZooKeeper -544  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/ids
[framework] 2015-12-18 16:35:05,651 - com.infogen.zookeeper.InfoGen_ZooKeeper -545  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/1
[framework] 2015-12-18 16:35:05,684 - com.infogen.zookeeper.InfoGen_ZooKeeper -578  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/1
[framework] 2015-12-18 16:35:05,685 - com.infogen.zookeeper.InfoGen_ZooKeeper -579  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/2
[framework] 2015-12-18 16:35:05,702 - com.infogen.zookeeper.InfoGen_ZooKeeper -596  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/2
[framework] 2015-12-18 16:35:05,704 - com.infogen.zookeeper.InfoGen_ZooKeeper -598  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/3
[framework] 2015-12-18 16:35:05,727 - com.infogen.zookeeper.InfoGen_ZooKeeper -621  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/3
[framework] 2015-12-18 16:35:05,727 - com.infogen.etl.InfoGen_Container -621  [main] INFO  com.infogen.etl.InfoGen_Container  - #broker为：172.16.8.97:10086,172.16.8.98:10086,172.16.8.99:10086
[framework] 2015-12-18 16:35:05,728 - com.infogen.zookeeper.InfoGen_ZooKeeper -622  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-18 16:35:05,746 - com.infogen.zookeeper.InfoGen_ZooKeeper -640  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-18 16:35:05,746 - com.infogen.zookeeper.InfoGen_ZooKeeper -640  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset/0
[framework] 2015-12-18 16:35:05,762 - com.infogen.zookeeper.InfoGen_ZooKeeper -656  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset/0
[framework] 2015-12-18 16:35:05,767 - com.infogen.zookeeper.InfoGen_ZooKeeper -661  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/infogen_etl/partition/0
[framework] 2015-12-18 16:35:05,786 - com.infogen.zookeeper.InfoGen_ZooKeeper -680  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/partition/0
[framework] 2015-12-18 16:35:05,789 - com.infogen.etl.InfoGen_Container -683  [main] INFO  com.infogen.etl.InfoGen_Container  - #获取partition成功:0
[framework] 2015-12-18 16:35:05,789 - com.infogen.etl.InfoGen_Container -683  [main] INFO  com.infogen.etl.InfoGen_Container  - #partition为：0
[framework] 2015-12-18 16:35:05,789 - com.infogen.zookeeper.InfoGen_ZooKeeper -683  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset/0
[framework] 2015-12-18 16:35:05,810 - com.infogen.zookeeper.InfoGen_ZooKeeper -704  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/infogen_consumers/infogen_topic_tracking/infogen_etl/offset/0
[framework] 2015-12-18 16:35:05,810 - com.infogen.etl.InfoGen_Container -704  [main] INFO  com.infogen.etl.InfoGen_Container  - #使用zookeeper 中 offset为:null
[framework] 2015-12-18 16:35:05,810 - com.infogen.etl.InfoGen_Container -704  [main] INFO  com.infogen.etl.InfoGen_Container  - #zookeeper_offset为：4663209
[framework] 2015-12-18 16:35:05,810 - com.infogen.zookeeper.InfoGen_ZooKeeper -704  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 关闭zookeeper
[framework] 2015-12-18 16:35:05,828 - org.apache.zookeeper.ZooKeeper -722  [main] INFO  org.apache.zookeeper.ZooKeeper  - Session: 0x6250c64e42560797 closed
[framework] 2015-12-18 16:35:05,828 - org.apache.zookeeper.ClientCnxn -722  [main-EventThread] INFO  org.apache.zookeeper.ClientCnxn  - EventThread shut down
[framework] 2015-12-18 16:35:05,828 - com.infogen.zookeeper.InfoGen_ZooKeeper -722  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 关闭zookeeper成功
[framework] 2015-12-18 16:35:05,828 - com.infogen.etl.InfoGen_Container -722  [main] INFO  com.infogen.etl.InfoGen_Container  - #执行ETL commit_offset为：4663209
[framework] 2015-12-18 16:35:05,833 - com.infogen.zookeeper.InfoGen_ZooKeeper -727  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-18 16:35:05,833 - org.apache.zookeeper.ZooKeeper -727  [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@23d2a7e8
[framework] 2015-12-18 16:35:05,834 - com.infogen.zookeeper.InfoGen_ZooKeeper -728  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-18 16:35:05,834 - org.apache.zookeeper.ClientCnxn -728  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.99/172.16.8.99:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-18 16:35:05,834 - com.infogen.kafka.InfoGen_Consumer -728  [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #获取指定Topic partition的元数据：topic-infogen_topic_tracking partition-0
[framework] 2015-12-18 16:35:05,847 - org.apache.zookeeper.ClientCnxn -741  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.99/172.16.8.99:2181, initiating session
[framework] 2015-12-18 16:35:05,861 - org.apache.zookeeper.ClientCnxn -755  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.99/172.16.8.99:2181, sessionid = 0x634f1aacb9811fe6, negotiated timeout = 10000
[framework] 2015-12-18 16:35:05,862 - com.infogen.zookeeper.InfoGen_ZooKeeper -756  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-18 16:35:06,394 - com.infogen.kafka.InfoGen_Consumer -1288 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #leaderBroker：172.16.8.98
[framework] 2015-12-18 16:35:06,394 - com.infogen.kafka.InfoGen_Consumer -1288 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #leaderPort：10086
[framework] 2015-12-18 16:35:06,395 - com.infogen.kafka.InfoGen_Consumer -1289 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #clientId：Client_infogen_topic_tracking_0_1450427706395
[framework] 2015-12-18 16:35:06,484 - com.infogen.kafka.InfoGen_Consumer -1378 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #offset：4663209:earliestOffset-4590888 latestOffset-4727767
[framework] 2015-12-18 16:35:06,484 - com.infogen.kafka.InfoGen_Consumer -1378 [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #开始ETL：单次获取字节数-2097152 最高重试fetch次数-5  最多未commit消息大小-67108864  最多未commit时间-300000
[framework] 2015-12-18 16:35:08,807 - org.apache.hadoop.util.NativeCodeLoader -3701 [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-18 16:35:10,884 - com.infogen.hdfs.InfoGen_LZOOutputStream -5778 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/14/-0.4663209
[framework] 2015-12-18 16:35:11,131 - com.hadoop.compression.lzo.GPLNativeCodeLoader -6025 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-18 16:35:11,136 - com.hadoop.compression.lzo.LzoCodec -6030 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-18 16:35:11,138 - org.apache.hadoop.conf.Configuration.deprecation -6032 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-18 16:35:11,140 - org.apache.hadoop.io.compress.CodecPool -6034 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:11,347 - com.infogen.hdfs.InfoGen_LZOOutputStream -6241 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/15/-0.4663209
[framework] 2015-12-18 16:35:11,462 - org.apache.hadoop.io.compress.CodecPool -6356 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:11,638 - com.infogen.hdfs.InfoGen_LZOOutputStream -6532 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/16/-0.4663209
[framework] 2015-12-18 16:35:11,815 - org.apache.hadoop.io.compress.CodecPool -6709 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:12,233 - com.infogen.hdfs.InfoGen_LZOOutputStream -7127 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/17/-0.4663209
[framework] 2015-12-18 16:35:12,324 - org.apache.hadoop.io.compress.CodecPool -7218 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:12,720 - com.infogen.hdfs.InfoGen_LZOOutputStream -7614 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/18/-0.4663209
[framework] 2015-12-18 16:35:12,814 - org.apache.hadoop.io.compress.CodecPool -7708 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:13,003 - com.infogen.hdfs.InfoGen_LZOOutputStream -7897 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/19/-0.4663209
[framework] 2015-12-18 16:35:13,102 - org.apache.hadoop.io.compress.CodecPool -7996 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:13,250 - com.infogen.hdfs.InfoGen_LZOOutputStream -8144 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/20/-0.4663209
[framework] 2015-12-18 16:35:13,344 - org.apache.hadoop.io.compress.CodecPool -8238 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:13,523 - com.infogen.hdfs.InfoGen_LZOOutputStream -8417 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/21/-0.4663209
[framework] 2015-12-18 16:35:13,624 - org.apache.hadoop.io.compress.CodecPool -8518 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:13,803 - com.infogen.hdfs.InfoGen_LZOOutputStream -8697 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/22/-0.4663209
[framework] 2015-12-18 16:35:13,890 - org.apache.hadoop.io.compress.CodecPool -8784 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:14,077 - com.infogen.hdfs.InfoGen_LZOOutputStream -8971 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/23/-0.4663209
[framework] 2015-12-18 16:35:14,157 - org.apache.hadoop.io.compress.CodecPool -9051 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:14,287 - com.infogen.hdfs.InfoGen_LZOOutputStream -9181 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/0/-0.4663209
[framework] 2015-12-18 16:35:14,382 - org.apache.hadoop.io.compress.CodecPool -9276 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:14,495 - com.infogen.hdfs.InfoGen_LZOOutputStream -9389 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/1/-0.4663209
[framework] 2015-12-18 16:35:14,590 - org.apache.hadoop.io.compress.CodecPool -9484 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:14,713 - com.infogen.hdfs.InfoGen_LZOOutputStream -9607 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/3/-0.4663209
[framework] 2015-12-18 16:35:14,798 - org.apache.hadoop.io.compress.CodecPool -9692 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:14,927 - com.infogen.hdfs.InfoGen_LZOOutputStream -9821 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/4/-0.4663209
[framework] 2015-12-18 16:35:15,259 - org.apache.hadoop.io.compress.CodecPool -10153 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:15,425 - com.infogen.hdfs.InfoGen_LZOOutputStream -10319 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/6/-0.4663209
[framework] 2015-12-18 16:35:15,599 - org.apache.hadoop.io.compress.CodecPool -10493 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:15,731 - com.infogen.hdfs.InfoGen_LZOOutputStream -10625 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/7/-0.4663209
[framework] 2015-12-18 16:35:15,866 - org.apache.hadoop.io.compress.CodecPool -10760 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:18,310 - com.infogen.hdfs.InfoGen_LZOOutputStream -13204 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/8/-0.4663209
[framework] 2015-12-18 16:35:18,432 - org.apache.hadoop.io.compress.CodecPool -13326 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:18,510 - com.infogen.hdfs.InfoGen_LZOOutputStream -13404 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/9/-0.4663209
[framework] 2015-12-18 16:35:18,597 - org.apache.hadoop.io.compress.CodecPool -13491 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:18,667 - com.infogen.hdfs.InfoGen_LZOOutputStream -13561 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/10/-0.4663209
[framework] 2015-12-18 16:35:18,845 - org.apache.hadoop.io.compress.CodecPool -13739 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:18,925 - com.infogen.hdfs.InfoGen_LZOOutputStream -13819 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/11/-0.4663209
[framework] 2015-12-18 16:35:19,106 - org.apache.hadoop.io.compress.CodecPool -14000 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:19,280 - com.infogen.hdfs.InfoGen_LZOOutputStream -14174 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/12/-0.4663209
[framework] 2015-12-18 16:35:19,675 - org.apache.hadoop.io.compress.CodecPool -14569 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:19,754 - com.infogen.hdfs.InfoGen_LZOOutputStream -14648 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/13/-0.4663209
[framework] 2015-12-18 16:35:19,867 - org.apache.hadoop.io.compress.CodecPool -14761 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:19,869 - com.infogen.hdfs.InfoGen_LZOOutputStream -14763 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/8/-0.4663209
[framework] 2015-12-18 16:35:20,372 - com.infogen.hdfs.InfoGen_LZOOutputStream -15266 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/9/-0.4663209
[framework] 2015-12-18 16:35:20,887 - com.infogen.hdfs.InfoGen_LZOOutputStream -15781 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/3/-0.4663209
[framework] 2015-12-18 16:35:21,337 - com.infogen.hdfs.InfoGen_LZOOutputStream -16231 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/0/-0.4663209
[framework] 2015-12-18 16:35:22,845 - com.infogen.hdfs.InfoGen_LZOOutputStream -17739 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/1/-0.4663209
[framework] 2015-12-18 16:35:23,295 - com.infogen.hdfs.InfoGen_LZOOutputStream -18189 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/6/-0.4663209
[framework] 2015-12-18 16:35:24,306 - com.infogen.hdfs.InfoGen_LZOOutputStream -19200 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/7/-0.4663209
[framework] 2015-12-18 16:35:26,053 - com.infogen.hdfs.InfoGen_LZOOutputStream -20947 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/4/-0.4663209
[framework] 2015-12-18 16:35:26,613 - com.infogen.hdfs.InfoGen_LZOOutputStream -21507 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/12/-0.4663209
[framework] 2015-12-18 16:35:28,120 - com.infogen.hdfs.InfoGen_LZOOutputStream -23014 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/13/-0.4663209
[framework] 2015-12-18 16:35:29,720 - com.infogen.hdfs.InfoGen_LZOOutputStream -24614 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/10/-0.4663209
[framework] 2015-12-18 16:35:30,198 - com.infogen.hdfs.InfoGen_LZOOutputStream -25092 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/11/-0.4663209
[framework] 2015-12-18 16:35:30,707 - com.infogen.hdfs.InfoGen_LZOOutputStream -25601 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/18/-0.4663209
[framework] 2015-12-18 16:35:31,358 - com.infogen.hdfs.InfoGen_LZOOutputStream -26252 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/19/-0.4663209
[framework] 2015-12-18 16:35:32,027 - com.infogen.hdfs.InfoGen_LZOOutputStream -26921 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/16/-0.4663209
[framework] 2015-12-18 16:35:32,484 - com.infogen.hdfs.InfoGen_LZOOutputStream -27378 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/17/-0.4663209
[framework] 2015-12-18 16:35:32,966 - com.infogen.hdfs.InfoGen_LZOOutputStream -27860 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/14/-0.4663209
[framework] 2015-12-18 16:35:33,760 - com.infogen.hdfs.InfoGen_LZOOutputStream -28654 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/15/-0.4663209
[framework] 2015-12-18 16:35:34,580 - com.infogen.hdfs.InfoGen_LZOOutputStream -29474 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/22/-0.4663209
[framework] 2015-12-18 16:35:35,317 - com.infogen.hdfs.InfoGen_LZOOutputStream -30211 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/23/-0.4663209
[framework] 2015-12-18 16:35:36,356 - com.infogen.hdfs.InfoGen_LZOOutputStream -31250 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/20/-0.4663209
[framework] 2015-12-18 16:35:36,791 - com.infogen.hdfs.InfoGen_LZOOutputStream -31685 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/21/-0.4663209
[framework] 2015-12-18 16:35:38,959 - com.infogen.kafka.InfoGen_Consumer -33853 [main] ERROR com.infogen.kafka.InfoGen_Consumer  - #关闭流成功 : commit_offset-4663209 offset-4684903
[framework] 2015-12-18 16:35:38,978 - com.infogen.kafka.InfoGen_Consumer -33872 [main] ERROR com.infogen.kafka.InfoGen_Consumer  - #更新offset成功 : commit_offset-4684903 offset-4684903
[framework] 2015-12-18 16:35:40,171 - com.infogen.hdfs.InfoGen_LZOOutputStream -35065 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/13/-0.4684903
[framework] 2015-12-18 16:35:40,310 - com.infogen.hdfs.InfoGen_LZOOutputStream -35204 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/14/-0.4684903
[framework] 2015-12-18 16:35:40,453 - com.infogen.hdfs.InfoGen_LZOOutputStream -35347 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/15/-0.4684903
[framework] 2015-12-18 16:35:40,603 - com.infogen.hdfs.InfoGen_LZOOutputStream -35497 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/16/-0.4684903
[framework] 2015-12-18 16:35:40,750 - com.infogen.hdfs.InfoGen_LZOOutputStream -35644 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/17/-0.4684903
[framework] 2015-12-18 16:35:40,933 - com.infogen.hdfs.InfoGen_LZOOutputStream -35827 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/18/-0.4684903
[framework] 2015-12-18 16:35:41,397 - com.infogen.hdfs.InfoGen_LZOOutputStream -36291 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/19/-0.4684903
[framework] 2015-12-18 16:35:41,581 - com.infogen.hdfs.InfoGen_LZOOutputStream -36475 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/20/-0.4684903
[framework] 2015-12-18 16:35:41,722 - com.infogen.hdfs.InfoGen_LZOOutputStream -36616 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/21/-0.4684903
[framework] 2015-12-18 16:35:41,897 - com.infogen.hdfs.InfoGen_LZOOutputStream -36791 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/22/-0.4684903
[framework] 2015-12-18 16:35:42,504 - com.infogen.hdfs.InfoGen_LZOOutputStream -37398 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/23/-0.4684903
[framework] 2015-12-18 16:35:42,780 - com.infogen.hdfs.InfoGen_LZOOutputStream -37674 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/0/-0.4684903
[framework] 2015-12-18 16:35:43,014 - com.infogen.hdfs.InfoGen_LZOOutputStream -37908 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/1/-0.4684903
[framework] 2015-12-18 16:35:43,185 - com.infogen.hdfs.InfoGen_LZOOutputStream -38079 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/2/-0.4684903
[framework] 2015-12-18 16:35:43,365 - com.infogen.hdfs.InfoGen_LZOOutputStream -38259 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/3/-0.4684903
[framework] 2015-12-18 16:35:43,736 - com.infogen.hdfs.InfoGen_LZOOutputStream -38630 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/4/-0.4684903
[framework] 2015-12-18 16:35:43,884 - com.infogen.hdfs.InfoGen_LZOOutputStream -38778 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/5/-0.4684903
[framework] 2015-12-18 16:35:44,102 - com.infogen.hdfs.InfoGen_LZOOutputStream -38996 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/6/-0.4684903
[framework] 2015-12-18 16:35:44,257 - com.infogen.hdfs.InfoGen_LZOOutputStream -39151 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/7/-0.4684903
[framework] 2015-12-18 16:35:44,416 - com.infogen.hdfs.InfoGen_LZOOutputStream -39310 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/8/-0.4684903
[framework] 2015-12-18 16:35:44,546 - com.infogen.hdfs.InfoGen_LZOOutputStream -39440 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/9/-0.4684903
[framework] 2015-12-18 16:35:44,706 - com.infogen.hdfs.InfoGen_LZOOutputStream -39600 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/10/-0.4684903
[framework] 2015-12-18 16:35:44,879 - com.infogen.hdfs.InfoGen_LZOOutputStream -39773 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/11/-0.4684903
[framework] 2015-12-18 16:35:45,132 - org.apache.hadoop.io.compress.CodecPool -40026 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:35:45,132 - com.infogen.hdfs.InfoGen_LZOOutputStream -40026 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/11/-0.4684903
[framework] 2015-12-18 16:35:45,677 - com.infogen.hdfs.InfoGen_LZOOutputStream -40571 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/10/-0.4684903
[framework] 2015-12-18 16:35:46,422 - com.infogen.hdfs.InfoGen_LZOOutputStream -41316 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/18/-0.4684903
[framework] 2015-12-18 16:35:47,933 - com.infogen.hdfs.InfoGen_LZOOutputStream -42827 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/19/-0.4684903
[framework] 2015-12-18 16:35:49,031 - com.infogen.hdfs.InfoGen_LZOOutputStream -43925 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/22/-0.4684903
[framework] 2015-12-18 16:35:49,469 - com.infogen.hdfs.InfoGen_LZOOutputStream -44363 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/23/-0.4684903
[framework] 2015-12-18 16:35:49,859 - com.infogen.hdfs.InfoGen_LZOOutputStream -44753 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/20/-0.4684903
[framework] 2015-12-18 16:35:50,596 - com.infogen.hdfs.InfoGen_LZOOutputStream -45490 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/21/-0.4684903
[framework] 2015-12-18 16:35:51,321 - com.infogen.hdfs.InfoGen_LZOOutputStream -46215 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/16/-0.4684903
[framework] 2015-12-18 16:35:51,782 - com.infogen.hdfs.InfoGen_LZOOutputStream -46676 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/17/-0.4684903
[framework] 2015-12-18 16:35:52,278 - com.infogen.hdfs.InfoGen_LZOOutputStream -47172 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/14/-0.4684903
[framework] 2015-12-18 16:35:52,887 - com.infogen.hdfs.InfoGen_LZOOutputStream -47781 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/15/-0.4684903
[framework] 2015-12-18 16:35:53,644 - com.infogen.hdfs.InfoGen_LZOOutputStream -48538 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/13/-0.4684903
[framework] 2015-12-18 16:35:54,022 - com.infogen.hdfs.InfoGen_LZOOutputStream -48916 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/7/-0.4684903
[framework] 2015-12-18 16:35:54,645 - com.infogen.hdfs.InfoGen_LZOOutputStream -49539 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/8/-0.4684903
[framework] 2015-12-18 16:35:54,988 - com.infogen.hdfs.InfoGen_LZOOutputStream -49882 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/5/-0.4684903
[framework] 2015-12-18 16:35:55,327 - com.infogen.hdfs.InfoGen_LZOOutputStream -50221 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/6/-0.4684903
[framework] 2015-12-18 16:35:55,786 - com.infogen.hdfs.InfoGen_LZOOutputStream -50680 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/9/-0.4684903
[framework] 2015-12-18 16:35:57,442 - com.infogen.hdfs.InfoGen_LZOOutputStream -52336 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/0/-0.4684903
[framework] 2015-12-18 16:35:57,859 - com.infogen.hdfs.InfoGen_LZOOutputStream -52753 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/3/-0.4684903
[framework] 2015-12-18 16:35:58,543 - com.infogen.hdfs.InfoGen_LZOOutputStream -53437 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/4/-0.4684903
[framework] 2015-12-18 16:35:58,926 - com.infogen.hdfs.InfoGen_LZOOutputStream -53820 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/1/-0.4684903
[framework] 2015-12-18 16:35:59,555 - com.infogen.hdfs.InfoGen_LZOOutputStream -54449 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/2/-0.4684903
[framework] 2015-12-18 16:36:01,200 - com.infogen.kafka.InfoGen_Consumer -56094 [main] ERROR com.infogen.kafka.InfoGen_Consumer  - #关闭流成功 : commit_offset-4684903 offset-4692146
[framework] 2015-12-18 16:36:01,215 - com.infogen.kafka.InfoGen_Consumer -56109 [main] ERROR com.infogen.kafka.InfoGen_Consumer  - #更新offset成功 : commit_offset-4692146 offset-4692146
[framework] 2015-12-18 16:36:01,344 - com.infogen.hdfs.InfoGen_LZOOutputStream -56238 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/11/-0.4692146
[framework] 2015-12-18 16:36:03,384 - com.infogen.hdfs.InfoGen_LZOOutputStream -58278 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/12/-0.4692146
[framework] 2015-12-18 16:36:05,729 - com.infogen.hdfs.InfoGen_LZOOutputStream -60623 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/13/-0.4692146
[framework] 2015-12-18 16:36:05,882 - com.infogen.hdfs.InfoGen_LZOOutputStream -60776 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/14/-0.4692146
[framework] 2015-12-18 16:36:06,052 - com.infogen.hdfs.InfoGen_LZOOutputStream -60946 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/15/-0.4692146
[framework] 2015-12-18 16:36:06,256 - com.infogen.hdfs.InfoGen_LZOOutputStream -61150 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/16/-0.4692146
[framework] 2015-12-18 16:36:06,493 - com.infogen.hdfs.InfoGen_LZOOutputStream -61387 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/17/-0.4692146
[framework] 2015-12-18 16:36:07,585 - com.infogen.hdfs.InfoGen_LZOOutputStream -62479 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/18/-0.4692146
[framework] 2015-12-18 16:36:07,998 - com.infogen.hdfs.InfoGen_LZOOutputStream -62892 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/19/-0.4692146
[framework] 2015-12-18 16:36:08,168 - com.infogen.hdfs.InfoGen_LZOOutputStream -63062 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/20/-0.4692146
[framework] 2015-12-18 16:36:08,329 - com.infogen.hdfs.InfoGen_LZOOutputStream -63223 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/21/-0.4692146
[framework] 2015-12-18 16:36:08,541 - com.infogen.hdfs.InfoGen_LZOOutputStream -63435 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/22/-0.4692146
[framework] 2015-12-18 16:36:08,698 - com.infogen.hdfs.InfoGen_LZOOutputStream -63592 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/23/-0.4692146
[framework] 2015-12-18 16:36:08,880 - com.infogen.hdfs.InfoGen_LZOOutputStream -63774 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/0/-0.4692146
[framework] 2015-12-18 16:36:09,031 - com.infogen.hdfs.InfoGen_LZOOutputStream -63925 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/1/-0.4692146
[framework] 2015-12-18 16:36:09,502 - com.infogen.hdfs.InfoGen_LZOOutputStream -64396 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/2/-0.4692146
[framework] 2015-12-18 16:36:09,646 - com.infogen.hdfs.InfoGen_LZOOutputStream -64540 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/3/-0.4692146
[framework] 2015-12-18 16:36:09,792 - com.infogen.hdfs.InfoGen_LZOOutputStream -64686 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/4/-0.4692146
[framework] 2015-12-18 16:36:10,188 - com.infogen.hdfs.InfoGen_LZOOutputStream -65082 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/5/-0.4692146
[framework] 2015-12-18 16:36:10,568 - com.infogen.hdfs.InfoGen_LZOOutputStream -65462 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/6/-0.4692146
[framework] 2015-12-18 16:36:10,709 - com.infogen.hdfs.InfoGen_LZOOutputStream -65603 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/7/-0.4692146
[framework] 2015-12-18 16:36:10,853 - com.infogen.hdfs.InfoGen_LZOOutputStream -65747 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/8/-0.4692146
[framework] 2015-12-18 16:36:10,976 - com.infogen.hdfs.InfoGen_LZOOutputStream -65870 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/9/-0.4692146
[framework] 2015-12-18 16:36:11,268 - com.infogen.hdfs.InfoGen_LZOOutputStream -66162 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/10/-0.4692146
[framework] 2015-12-18 16:36:11,343 - org.apache.hadoop.io.compress.CodecPool -66237 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:36:11,410 - com.infogen.hdfs.InfoGen_LZOOutputStream -66304 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/11/-0.4692146
[framework] 2015-12-18 16:36:11,487 - org.apache.hadoop.io.compress.CodecPool -66381 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:36:11,773 - com.infogen.hdfs.InfoGen_LZOOutputStream -66667 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/12/-0.4692146
[framework] 2015-12-18 16:36:11,840 - org.apache.hadoop.io.compress.CodecPool -66734 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:36:11,906 - com.infogen.hdfs.InfoGen_LZOOutputStream -66800 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/13/-0.4692146
[framework] 2015-12-18 16:36:11,974 - org.apache.hadoop.io.compress.CodecPool -66868 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:36:12,057 - com.infogen.hdfs.InfoGen_LZOOutputStream -66951 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/14/-0.4692146
[framework] 2015-12-18 16:36:12,123 - org.apache.hadoop.io.compress.CodecPool -67017 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:36:12,199 - com.infogen.hdfs.InfoGen_LZOOutputStream -67093 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/15/-0.4692146
[framework] 2015-12-18 16:36:12,284 - org.apache.hadoop.io.compress.CodecPool -67178 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-18 16:36:12,301 - com.infogen.hdfs.InfoGen_LZOOutputStream -67195 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/19/-0.4692146
[framework] 2015-12-18 16:36:13,598 - com.infogen.hdfs.InfoGen_LZOOutputStream -68492 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/18/-0.4692146
[framework] 2015-12-18 16:36:15,447 - com.infogen.hdfs.InfoGen_LZOOutputStream -70341 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/17/-0.4692146
[framework] 2015-12-18 16:36:16,693 - com.infogen.hdfs.InfoGen_LZOOutputStream -71587 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/16/-0.4692146
[framework] 2015-12-18 16:36:17,029 - com.infogen.hdfs.InfoGen_LZOOutputStream -71923 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/15/-0.4692146
[framework] 2015-12-18 16:36:17,496 - com.infogen.hdfs.InfoGen_LZOOutputStream -72390 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/14/-0.4692146
[framework] 2015-12-18 16:36:17,913 - com.infogen.hdfs.InfoGen_LZOOutputStream -72807 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/13/-0.4692146
[framework] 2015-12-18 16:36:18,744 - com.infogen.hdfs.InfoGen_LZOOutputStream -73638 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/12/-0.4692146
[framework] 2015-12-18 16:36:19,204 - com.infogen.hdfs.InfoGen_LZOOutputStream -74098 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/11/-0.4692146
[framework] 2015-12-18 16:36:19,546 - com.infogen.hdfs.InfoGen_LZOOutputStream -74440 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/15/-0.4692146
[framework] 2015-12-18 16:36:19,938 - com.infogen.hdfs.InfoGen_LZOOutputStream -74832 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/14/-0.4692146
[framework] 2015-12-18 16:36:20,512 - com.infogen.hdfs.InfoGen_LZOOutputStream -75406 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/13/-0.4692146
[framework] 2015-12-18 16:36:21,226 - com.infogen.hdfs.InfoGen_LZOOutputStream -76120 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/12/-0.4692146
[framework] 2015-12-18 16:36:27,502 - com.infogen.hdfs.InfoGen_LZOOutputStream -82396 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/11/-0.4692146
[framework] 2015-12-18 16:36:28,018 - com.infogen.hdfs.InfoGen_LZOOutputStream -82912 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/10/-0.4692146
[framework] 2015-12-18 16:36:28,451 - com.infogen.hdfs.InfoGen_LZOOutputStream -83345 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/4/-0.4692146
[framework] 2015-12-18 16:36:29,765 - com.infogen.hdfs.InfoGen_LZOOutputStream -84659 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/5/-0.4692146
[framework] 2015-12-18 16:36:30,552 - com.infogen.hdfs.InfoGen_LZOOutputStream -85446 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/2/-0.4692146
[framework] 2015-12-18 16:36:32,226 - com.infogen.hdfs.InfoGen_LZOOutputStream -87120 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/3/-0.4692146
[framework] 2015-12-18 16:36:33,162 - com.infogen.hdfs.InfoGen_LZOOutputStream -88056 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/8/-0.4692146
[framework] 2015-12-18 16:36:34,425 - com.infogen.hdfs.InfoGen_LZOOutputStream -89319 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/9/-0.4692146
[framework] 2015-12-18 16:36:35,025 - com.infogen.hdfs.InfoGen_LZOOutputStream -89919 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/6/-0.4692146
[framework] 2015-12-18 16:36:35,749 - com.infogen.hdfs.InfoGen_LZOOutputStream -90643 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/7/-0.4692146
[framework] 2015-12-18 16:36:36,389 - com.infogen.hdfs.InfoGen_LZOOutputStream -91283 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/0/-0.4692146
[framework] 2015-12-18 16:36:37,327 - com.infogen.hdfs.InfoGen_LZOOutputStream -92221 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/1/-0.4692146
[framework] 2015-12-18 16:36:37,813 - com.infogen.hdfs.InfoGen_LZOOutputStream -92707 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/23/-0.4692146
[framework] 2015-12-18 16:36:38,923 - com.infogen.hdfs.InfoGen_LZOOutputStream -93817 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/22/-0.4692146
[framework] 2015-12-18 16:36:39,448 - com.infogen.hdfs.InfoGen_LZOOutputStream -94342 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/21/-0.4692146
[framework] 2015-12-18 16:36:39,983 - com.infogen.hdfs.InfoGen_LZOOutputStream -94877 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-17/20/-0.4692146
[framework] 2015-12-18 16:36:40,407 - com.infogen.kafka.InfoGen_Consumer -95301 [main] ERROR com.infogen.kafka.InfoGen_Consumer  - #关闭流成功 : commit_offset-4692146 offset-4721128
[framework] 2015-12-18 16:36:40,423 - com.infogen.kafka.InfoGen_Consumer -95317 [main] ERROR com.infogen.kafka.InfoGen_Consumer  - #更新offset成功 : commit_offset-4721128 offset-4721128
[framework] 2015-12-18 16:36:43,375 - com.infogen.hdfs.InfoGen_LZOOutputStream -98269 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/15/-0.4721128
[framework] 2015-12-18 16:36:43,793 - com.infogen.hdfs.InfoGen_LZOOutputStream -98687 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-18/16/-0.4721128
