[framework] 2015-12-14 17:05:24,312 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -11453 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4494174-
[framework] 2015-12-14 17:05:24,328 - com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs -11469 [main] ERROR com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs  - #写入hdfs失败:
org.apache.hadoop.fs.FileAlreadyExistsException: /infogen/output/infogen_topic_tracking/1/4494174- for client 192.168.100.203 already exists
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2738)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2632)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2519)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:566)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:394)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:408)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1628)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1703)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1638)
	at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:448)
	at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:444)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:459)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:387)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:909)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:890)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:787)
	at com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream.<init>(InfoGen_Hdfs_LZOOutputStream.java:62)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs.handle(Kafka_To_Hdfs.java:48)
	at com.infogen.kafka.InfoGen_Consumer.run(InfoGen_Consumer.java:147)
	at com.infogen.kafka.InfoGen_Consumer.start(InfoGen_Consumer.java:57)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs.main(Kafka_To_Hdfs.java:121)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.fs.FileAlreadyExistsException): /infogen/output/infogen_topic_tracking/1/4494174- for client 192.168.100.203 already exists
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2738)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2632)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2519)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:566)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:394)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1476)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy11.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:296)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy12.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1623)
	... 15 more
[framework] 2015-12-14 17:05:25,397 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -12538 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4494174-
[framework] 2015-12-14 17:05:25,428 - com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs -12569 [main] ERROR com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs  - #写入hdfs失败:
org.apache.hadoop.fs.FileAlreadyExistsException: /infogen/output/infogen_topic_tracking/1/4494174- for client 192.168.100.203 already exists
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2738)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2632)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2519)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:566)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:394)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:408)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1628)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1703)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1638)
	at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:448)
	at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:444)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:459)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:387)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:909)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:890)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:787)
	at com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream.<init>(InfoGen_Hdfs_LZOOutputStream.java:62)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs.handle(Kafka_To_Hdfs.java:48)
	at com.infogen.kafka.InfoGen_Consumer.run(InfoGen_Consumer.java:147)
	at com.infogen.kafka.InfoGen_Consumer.start(InfoGen_Consumer.java:57)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs.main(Kafka_To_Hdfs.java:121)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.fs.FileAlreadyExistsException): /infogen/output/infogen_topic_tracking/1/4494174- for client 192.168.100.203 already exists
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2738)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2632)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2519)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:566)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:394)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1476)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy11.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:296)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy12.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1623)
	... 15 more
[framework] 2015-12-14 17:05:26,517 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -13658 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4494174-
[framework] 2015-12-14 17:05:26,544 - com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs -13685 [main] ERROR com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs  - #写入hdfs失败:
org.apache.hadoop.fs.FileAlreadyExistsException: /infogen/output/infogen_topic_tracking/1/4494174- for client 192.168.100.203 already exists
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2738)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2632)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2519)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:566)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:394)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:408)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1628)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1703)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1638)
	at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:448)
	at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:444)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:459)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:387)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:909)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:890)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:787)
	at com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream.<init>(InfoGen_Hdfs_LZOOutputStream.java:62)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs.handle(Kafka_To_Hdfs.java:48)
	at com.infogen.kafka.InfoGen_Consumer.run(InfoGen_Consumer.java:147)
	at com.infogen.kafka.InfoGen_Consumer.start(InfoGen_Consumer.java:57)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs.main(Kafka_To_Hdfs.java:121)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.fs.FileAlreadyExistsException): /infogen/output/infogen_topic_tracking/1/4494174- for client 192.168.100.203 already exists
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2738)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2632)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2519)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:566)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:394)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1476)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy11.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:296)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy12.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1623)
	... 15 more
[framework] 2015-12-14 17:05:26,604 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -13745 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4494174-
[framework] 2015-12-14 17:05:26,620 - com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs -13761 [main] ERROR com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs  - #写入hdfs失败:
org.apache.hadoop.fs.FileAlreadyExistsException: /infogen/output/infogen_topic_tracking/1/4494174- for client 192.168.100.203 already exists
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2738)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2632)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2519)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:566)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:394)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:408)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1628)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1703)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1638)
	at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:448)
	at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:444)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:459)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:387)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:909)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:890)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:787)
	at com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream.<init>(InfoGen_Hdfs_LZOOutputStream.java:62)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs.handle(Kafka_To_Hdfs.java:48)
	at com.infogen.kafka.InfoGen_Consumer.run(InfoGen_Consumer.java:147)
	at com.infogen.kafka.InfoGen_Consumer.start(InfoGen_Consumer.java:57)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs.main(Kafka_To_Hdfs.java:121)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.fs.FileAlreadyExistsException): /infogen/output/infogen_topic_tracking/1/4494174- for client 192.168.100.203 already exists
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2738)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2632)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2519)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:566)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:394)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1476)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy11.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:296)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy12.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1623)
	... 15 more
[framework] 2015-12-14 17:06:45,946 - com.infogen.zookeeper.InfoGen_ZooKeeper -0    [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-14 17:06:45,994 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[framework] 2015-12-14 17:06:45,994 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:host.name=localhost
[framework] 2015-12-14 17:06:45,995 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_20
[framework] 2015-12-14 17:06:45,995 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
[framework] 2015-12-14 17:06:45,995 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/lib/jvm/java-8-sun/jre
[framework] 2015-12-14 17:06:45,995 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/home/juxinli/workspace/infogen_etl/target/classes:/home/juxinli/workspace/infogen_etl/lib/hadoop-lzo-0.4.20-SNAPSHOT.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-client/2.7.1/hadoop-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-common/2.7.1/hadoop-common-2.7.1.jar:/home/juxinli/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/juxinli/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/juxinli/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/juxinli/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/juxinli/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/juxinli/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/juxinli/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/juxinli/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/juxinli/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/juxinli/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/juxinli/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/juxinli/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/juxinli/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/juxinli/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/juxinli/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/juxinli/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/juxinli/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.1/hadoop-auth-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/home/juxinli/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/juxinli/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/juxinli/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.1/hadoop-hdfs-2.7.1.jar:/home/juxinli/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/juxinli/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/juxinli/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/juxinli/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/juxinli/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.1/hadoop-mapreduce-client-app-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.1/hadoop-mapreduce-client-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.1/hadoop-yarn-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.1/hadoop-yarn-server-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.1/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.1/hadoop-yarn-api-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.1/hadoop-mapreduce-client-core-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.1/hadoop-yarn-common-2.7.1.jar:/home/juxinli/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/juxinli/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/juxinli/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/juxinli/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.1/hadoop-mapreduce-client-jobclient-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.1/hadoop-annotations-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka_2.11/0.8.2.2/kafka_2.11-0.8.2.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/juxinli/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar:/home/juxinli/.m2/repository/org/scala-lang/scala-library/2.11.5/scala-library-2.11.5.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.2/kafka-clients-0.8.2.2.jar:/home/juxinli/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/juxinli/.m2/repository/net/jpountz/lz4/lz4/1.2.0/lz4-1.2.0.jar:/home/juxinli/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/juxinli/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/juxinli/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/juxinli/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar
[framework] 2015-12-14 17:06:45,996 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[framework] 2015-12-14 17:06:45,996 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp
[framework] 2015-12-14 17:06:45,996 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
[framework] 2015-12-14 17:06:45,996 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
[framework] 2015-12-14 17:06:45,996 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
[framework] 2015-12-14 17:06:45,996 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.2.0-19-generic
[framework] 2015-12-14 17:06:45,997 - org.apache.zookeeper.ZooKeeper -51   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.name=juxinli
[framework] 2015-12-14 17:06:45,997 - org.apache.zookeeper.ZooKeeper -51   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/juxinli
[framework] 2015-12-14 17:06:45,997 - org.apache.zookeeper.ZooKeeper -51   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/home/juxinli/workspace/infogen_etl
[framework] 2015-12-14 17:06:45,998 - org.apache.zookeeper.ZooKeeper -52   [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@73846619
[framework] 2015-12-14 17:06:46,029 - com.infogen.zookeeper.InfoGen_ZooKeeper -83   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-14 17:06:46,029 - com.infogen.zookeeper.InfoGen_ZooKeeper -83   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/ids
[framework] 2015-12-14 17:06:46,037 - org.apache.zookeeper.ClientCnxn -91   [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.97/172.16.8.97:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-14 17:06:46,120 - org.apache.zookeeper.ClientCnxn -174  [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.97/172.16.8.97:2181, initiating session
[framework] 2015-12-14 17:06:46,141 - org.apache.zookeeper.ClientCnxn -195  [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.97/172.16.8.97:2181, sessionid = 0x614f1aad4d9c8033, negotiated timeout = 10000
[framework] 2015-12-14 17:06:46,144 - com.infogen.zookeeper.InfoGen_ZooKeeper -198  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-14 17:06:46,157 - com.infogen.zookeeper.InfoGen_ZooKeeper -211  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/ids
[framework] 2015-12-14 17:06:46,158 - com.infogen.zookeeper.InfoGen_ZooKeeper -212  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/1
[framework] 2015-12-14 17:06:46,176 - com.infogen.zookeeper.InfoGen_ZooKeeper -230  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/1
[framework] 2015-12-14 17:06:46,176 - com.infogen.zookeeper.InfoGen_ZooKeeper -230  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/2
[framework] 2015-12-14 17:06:46,190 - com.infogen.zookeeper.InfoGen_ZooKeeper -244  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/2
[framework] 2015-12-14 17:06:46,190 - com.infogen.zookeeper.InfoGen_ZooKeeper -244  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/3
[framework] 2015-12-14 17:06:46,204 - com.infogen.zookeeper.InfoGen_ZooKeeper -258  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/3
[framework] 2015-12-14 17:06:46,204 - com.infogen.zookeeper.InfoGen_ZooKeeper -258  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:06:46,230 - com.infogen.zookeeper.InfoGen_ZooKeeper -284  [main] ERROR com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据错误: 
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /infogen_consumers/infogen_topic_tracking/1
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1184)
	at com.infogen.zookeeper.InfoGen_ZooKeeper.get_data(InfoGen_ZooKeeper.java:155)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs.main(Kafka_To_Hdfs.java:110)
[framework] 2015-12-14 17:06:46,234 - com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs -288  [main] INFO  com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs  - #使用默认 offset为:0
[framework] 2015-12-14 17:06:46,925 - com.infogen.kafka.InfoGen_Consumer -979  [main] WARN  com.infogen.kafka.InfoGen_Consumer  - #offset不存在-从最早的offset开始获取:4494174
[framework] 2015-12-14 17:06:47,422 - org.apache.hadoop.util.NativeCodeLoader -1476 [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-14 17:06:48,413 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -2467 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4494174-
[framework] 2015-12-14 17:06:48,593 - com.hadoop.compression.lzo.GPLNativeCodeLoader -2647 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-14 17:06:48,599 - com.hadoop.compression.lzo.LzoCodec -2653 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-14 17:06:48,602 - org.apache.hadoop.conf.Configuration.deprecation -2656 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-14 17:06:48,603 - org.apache.hadoop.io.compress.CodecPool -2657 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 17:07:47,055 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -61109 [Thread-0] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4494174-
[framework] 2015-12-14 17:07:47,539 - com.infogen.zookeeper.InfoGen_ZooKeeper -61593 [Thread-0] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:07:47,558 - com.infogen.zookeeper.InfoGen_ZooKeeper -61612 [Thread-0] ERROR com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据失败: 
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /infogen_consumers/infogen_topic_tracking/1
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1270)
	at com.infogen.zookeeper.InfoGen_ZooKeeper.set_data(InfoGen_ZooKeeper.java:169)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs.lambda$0(Kafka_To_Hdfs.java:80)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs$$Lambda$2/2092769598.run(Unknown Source)
	at java.lang.Thread.run(Thread.java:745)
[framework] 2015-12-14 17:07:50,975 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -65029 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4675049-
[framework] 2015-12-14 17:11:45,532 - com.infogen.zookeeper.InfoGen_ZooKeeper -0    [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-14 17:11:45,574 - org.apache.zookeeper.ZooKeeper -42   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[framework] 2015-12-14 17:11:45,574 - org.apache.zookeeper.ZooKeeper -42   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:host.name=localhost
[framework] 2015-12-14 17:11:45,574 - org.apache.zookeeper.ZooKeeper -42   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_20
[framework] 2015-12-14 17:11:45,574 - org.apache.zookeeper.ZooKeeper -42   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
[framework] 2015-12-14 17:11:45,575 - org.apache.zookeeper.ZooKeeper -43   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/lib/jvm/java-8-sun/jre
[framework] 2015-12-14 17:11:45,575 - org.apache.zookeeper.ZooKeeper -43   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/home/juxinli/workspace/infogen_etl/target/classes:/home/juxinli/workspace/infogen_etl/lib/hadoop-lzo-0.4.20-SNAPSHOT.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-client/2.7.1/hadoop-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-common/2.7.1/hadoop-common-2.7.1.jar:/home/juxinli/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/juxinli/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/juxinli/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/juxinli/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/juxinli/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/juxinli/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/juxinli/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/juxinli/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/juxinli/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/juxinli/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/juxinli/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/juxinli/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/juxinli/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/juxinli/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/juxinli/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/juxinli/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/juxinli/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.1/hadoop-auth-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/home/juxinli/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/juxinli/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/juxinli/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.1/hadoop-hdfs-2.7.1.jar:/home/juxinli/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/juxinli/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/juxinli/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/juxinli/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/juxinli/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.1/hadoop-mapreduce-client-app-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.1/hadoop-mapreduce-client-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.1/hadoop-yarn-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.1/hadoop-yarn-server-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.1/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.1/hadoop-yarn-api-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.1/hadoop-mapreduce-client-core-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.1/hadoop-yarn-common-2.7.1.jar:/home/juxinli/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/juxinli/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/juxinli/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/juxinli/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.1/hadoop-mapreduce-client-jobclient-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.1/hadoop-annotations-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka_2.11/0.8.2.2/kafka_2.11-0.8.2.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/juxinli/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar:/home/juxinli/.m2/repository/org/scala-lang/scala-library/2.11.5/scala-library-2.11.5.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.2/kafka-clients-0.8.2.2.jar:/home/juxinli/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/juxinli/.m2/repository/net/jpountz/lz4/lz4/1.2.0/lz4-1.2.0.jar:/home/juxinli/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/juxinli/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/juxinli/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/juxinli/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar
[framework] 2015-12-14 17:11:45,577 - org.apache.zookeeper.ZooKeeper -45   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[framework] 2015-12-14 17:11:45,577 - org.apache.zookeeper.ZooKeeper -45   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp
[framework] 2015-12-14 17:11:45,577 - org.apache.zookeeper.ZooKeeper -45   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
[framework] 2015-12-14 17:11:45,577 - org.apache.zookeeper.ZooKeeper -45   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
[framework] 2015-12-14 17:11:45,577 - org.apache.zookeeper.ZooKeeper -45   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
[framework] 2015-12-14 17:11:45,578 - org.apache.zookeeper.ZooKeeper -46   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.2.0-19-generic
[framework] 2015-12-14 17:11:45,578 - org.apache.zookeeper.ZooKeeper -46   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.name=juxinli
[framework] 2015-12-14 17:11:45,578 - org.apache.zookeeper.ZooKeeper -46   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/juxinli
[framework] 2015-12-14 17:11:45,578 - org.apache.zookeeper.ZooKeeper -46   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/home/juxinli/workspace/infogen_etl
[framework] 2015-12-14 17:11:45,580 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@4bec1f0c
[framework] 2015-12-14 17:11:45,609 - com.infogen.zookeeper.InfoGen_ZooKeeper -77   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-14 17:11:45,610 - com.infogen.zookeeper.InfoGen_ZooKeeper -78   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/ids
[framework] 2015-12-14 17:11:45,617 - org.apache.zookeeper.ClientCnxn -85   [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.98/172.16.8.98:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-14 17:11:45,690 - org.apache.zookeeper.ClientCnxn -158  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.98/172.16.8.98:2181, initiating session
[framework] 2015-12-14 17:11:45,711 - org.apache.zookeeper.ClientCnxn -179  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.98/172.16.8.98:2181, sessionid = 0x6250c64e425606de, negotiated timeout = 10000
[framework] 2015-12-14 17:11:45,715 - com.infogen.zookeeper.InfoGen_ZooKeeper -183  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-14 17:11:45,730 - com.infogen.zookeeper.InfoGen_ZooKeeper -198  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/ids
[framework] 2015-12-14 17:11:45,730 - com.infogen.zookeeper.InfoGen_ZooKeeper -198  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/1
[framework] 2015-12-14 17:11:45,747 - com.infogen.zookeeper.InfoGen_ZooKeeper -215  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/1
[framework] 2015-12-14 17:11:45,747 - com.infogen.zookeeper.InfoGen_ZooKeeper -215  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/2
[framework] 2015-12-14 17:11:45,761 - com.infogen.zookeeper.InfoGen_ZooKeeper -229  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/2
[framework] 2015-12-14 17:11:45,762 - com.infogen.zookeeper.InfoGen_ZooKeeper -230  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/3
[framework] 2015-12-14 17:11:45,775 - com.infogen.zookeeper.InfoGen_ZooKeeper -243  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/3
[framework] 2015-12-14 17:11:45,775 - com.infogen.zookeeper.InfoGen_ZooKeeper -243  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:11:45,802 - com.infogen.zookeeper.InfoGen_ZooKeeper -270  [main] ERROR com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据错误: 
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /infogen_consumers/infogen_topic_tracking/1
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1184)
	at com.infogen.zookeeper.InfoGen_ZooKeeper.get_data(InfoGen_ZooKeeper.java:155)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs.main(Kafka_To_Hdfs.java:113)
[framework] 2015-12-14 17:11:45,811 - com.infogen.zookeeper.InfoGen_ZooKeeper -279  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:11:45,830 - com.infogen.zookeeper.InfoGen_ZooKeeper -298  [main] ERROR com.infogen.zookeeper.InfoGen_ZooKeeper  - 未知错误: 
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /infogen_consumers/infogen_topic_tracking/1
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at com.infogen.zookeeper.InfoGen_ZooKeeper.create(InfoGen_ZooKeeper.java:118)
	at com.infogen.zookeeper.InfoGen_ZooKeeper.create(InfoGen_ZooKeeper.java:127)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs.main(Kafka_To_Hdfs.java:118)
[framework] 2015-12-14 17:11:45,831 - com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs -299  [main] INFO  com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs  - #使用默认 offset为:0
[framework] 2015-12-14 17:11:46,580 - com.infogen.kafka.InfoGen_Consumer -1048 [main] WARN  com.infogen.kafka.InfoGen_Consumer  - #offset不存在-从最早的offset开始获取:4494174
[framework] 2015-12-14 17:11:47,116 - org.apache.hadoop.util.NativeCodeLoader -1584 [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-14 17:11:48,071 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -2539 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4494174-
[framework] 2015-12-14 17:11:48,260 - com.hadoop.compression.lzo.GPLNativeCodeLoader -2728 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-14 17:11:48,262 - com.hadoop.compression.lzo.LzoCodec -2730 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-14 17:11:48,264 - org.apache.hadoop.conf.Configuration.deprecation -2732 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-14 17:11:48,265 - org.apache.hadoop.io.compress.CodecPool -2733 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 17:12:46,751 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -61219 [Thread-0] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4494174-
[framework] 2015-12-14 17:12:47,247 - com.infogen.zookeeper.InfoGen_ZooKeeper -61715 [Thread-0] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:12:47,266 - com.infogen.zookeeper.InfoGen_ZooKeeper -61734 [Thread-0] ERROR com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据失败: 
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /infogen_consumers/infogen_topic_tracking/1
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1270)
	at com.infogen.zookeeper.InfoGen_ZooKeeper.set_data(InfoGen_ZooKeeper.java:169)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs.lambda$0(Kafka_To_Hdfs.java:81)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs$$Lambda$2/1131645570.run(Unknown Source)
	at java.lang.Thread.run(Thread.java:745)
[framework] 2015-12-14 17:19:59,134 - com.infogen.zookeeper.InfoGen_ZooKeeper -0    [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-14 17:19:59,181 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[framework] 2015-12-14 17:19:59,182 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:host.name=localhost
[framework] 2015-12-14 17:19:59,182 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_20
[framework] 2015-12-14 17:19:59,182 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
[framework] 2015-12-14 17:19:59,182 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/lib/jvm/java-8-sun/jre
[framework] 2015-12-14 17:19:59,182 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/home/juxinli/workspace/infogen_etl/target/classes:/home/juxinli/workspace/infogen_etl/lib/hadoop-lzo-0.4.20-SNAPSHOT.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-client/2.7.1/hadoop-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-common/2.7.1/hadoop-common-2.7.1.jar:/home/juxinli/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/juxinli/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/juxinli/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/juxinli/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/juxinli/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/juxinli/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/juxinli/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/juxinli/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/juxinli/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/juxinli/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/juxinli/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/juxinli/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/juxinli/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/juxinli/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/juxinli/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/juxinli/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/juxinli/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.1/hadoop-auth-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/home/juxinli/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/juxinli/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/juxinli/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.1/hadoop-hdfs-2.7.1.jar:/home/juxinli/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/juxinli/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/juxinli/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/juxinli/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/juxinli/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.1/hadoop-mapreduce-client-app-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.1/hadoop-mapreduce-client-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.1/hadoop-yarn-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.1/hadoop-yarn-server-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.1/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.1/hadoop-yarn-api-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.1/hadoop-mapreduce-client-core-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.1/hadoop-yarn-common-2.7.1.jar:/home/juxinli/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/juxinli/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/juxinli/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/juxinli/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.1/hadoop-mapreduce-client-jobclient-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.1/hadoop-annotations-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka_2.11/0.8.2.2/kafka_2.11-0.8.2.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/juxinli/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar:/home/juxinli/.m2/repository/org/scala-lang/scala-library/2.11.5/scala-library-2.11.5.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.2/kafka-clients-0.8.2.2.jar:/home/juxinli/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/juxinli/.m2/repository/net/jpountz/lz4/lz4/1.2.0/lz4-1.2.0.jar:/home/juxinli/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/juxinli/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/juxinli/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/juxinli/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar
[framework] 2015-12-14 17:19:59,183 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[framework] 2015-12-14 17:19:59,183 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp
[framework] 2015-12-14 17:19:59,183 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
[framework] 2015-12-14 17:19:59,183 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
[framework] 2015-12-14 17:19:59,183 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
[framework] 2015-12-14 17:19:59,183 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.2.0-19-generic
[framework] 2015-12-14 17:19:59,183 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.name=juxinli
[framework] 2015-12-14 17:19:59,184 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/juxinli
[framework] 2015-12-14 17:19:59,184 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/home/juxinli/workspace/infogen_etl
[framework] 2015-12-14 17:19:59,185 - org.apache.zookeeper.ZooKeeper -51   [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@4bec1f0c
[framework] 2015-12-14 17:19:59,218 - com.infogen.zookeeper.InfoGen_ZooKeeper -84   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-14 17:19:59,220 - com.infogen.zookeeper.InfoGen_ZooKeeper -86   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/ids
[framework] 2015-12-14 17:19:59,224 - org.apache.zookeeper.ClientCnxn -90   [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.97/172.16.8.97:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-14 17:19:59,308 - org.apache.zookeeper.ClientCnxn -174  [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.97/172.16.8.97:2181, initiating session
[framework] 2015-12-14 17:19:59,330 - org.apache.zookeeper.ClientCnxn -196  [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.97/172.16.8.97:2181, sessionid = 0x614f1aad4d9c8039, negotiated timeout = 10000
[framework] 2015-12-14 17:19:59,333 - com.infogen.zookeeper.InfoGen_ZooKeeper -199  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-14 17:19:59,348 - com.infogen.zookeeper.InfoGen_ZooKeeper -214  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/ids
[framework] 2015-12-14 17:19:59,348 - com.infogen.zookeeper.InfoGen_ZooKeeper -214  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/1
[framework] 2015-12-14 17:19:59,365 - com.infogen.zookeeper.InfoGen_ZooKeeper -231  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/1
[framework] 2015-12-14 17:19:59,366 - com.infogen.zookeeper.InfoGen_ZooKeeper -232  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/2
[framework] 2015-12-14 17:19:59,380 - com.infogen.zookeeper.InfoGen_ZooKeeper -246  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/2
[framework] 2015-12-14 17:19:59,381 - com.infogen.zookeeper.InfoGen_ZooKeeper -247  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/3
[framework] 2015-12-14 17:19:59,396 - com.infogen.zookeeper.InfoGen_ZooKeeper -262  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/3
[framework] 2015-12-14 17:19:59,396 - com.infogen.zookeeper.InfoGen_ZooKeeper -262  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:19:59,426 - com.infogen.zookeeper.InfoGen_ZooKeeper -292  [main] ERROR com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据错误: 
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /infogen_consumers/infogen_topic_tracking/1
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1184)
	at com.infogen.zookeeper.InfoGen_ZooKeeper.get_data(InfoGen_ZooKeeper.java:155)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs.main(Kafka_To_Hdfs.java:113)
[framework] 2015-12-14 17:19:59,432 - com.infogen.zookeeper.InfoGen_ZooKeeper -298  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers
[framework] 2015-12-14 17:19:59,450 - com.infogen.zookeeper.InfoGen_ZooKeeper -316  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers
[framework] 2015-12-14 17:19:59,454 - com.infogen.zookeeper.InfoGen_ZooKeeper -320  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers
[framework] 2015-12-14 17:19:59,472 - com.infogen.zookeeper.InfoGen_ZooKeeper -338  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers
[framework] 2015-12-14 17:19:59,473 - com.infogen.zookeeper.InfoGen_ZooKeeper -339  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-14 17:19:59,486 - com.infogen.zookeeper.InfoGen_ZooKeeper -352  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-14 17:19:59,486 - com.infogen.zookeeper.InfoGen_ZooKeeper -352  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-14 17:19:59,501 - com.infogen.zookeeper.InfoGen_ZooKeeper -367  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-14 17:19:59,502 - com.infogen.zookeeper.InfoGen_ZooKeeper -368  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:19:59,515 - com.infogen.zookeeper.InfoGen_ZooKeeper -381  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:19:59,516 - com.infogen.zookeeper.InfoGen_ZooKeeper -382  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:19:59,530 - com.infogen.zookeeper.InfoGen_ZooKeeper -396  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:19:59,531 - com.infogen.zookeeper.InfoGen_ZooKeeper -397  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:19:59,547 - com.infogen.zookeeper.InfoGen_ZooKeeper -413  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:19:59,547 - com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs -413  [main] INFO  com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs  - #使用默认 offset为:0
[framework] 2015-12-14 17:20:00,264 - com.infogen.kafka.InfoGen_Consumer -1130 [main] WARN  com.infogen.kafka.InfoGen_Consumer  - #offset不存在-从最早的offset开始获取:4494174
[framework] 2015-12-14 17:20:01,658 - org.apache.hadoop.util.NativeCodeLoader -2524 [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-14 17:20:02,601 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -3467 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4494174-
[framework] 2015-12-14 17:20:02,880 - com.hadoop.compression.lzo.GPLNativeCodeLoader -3746 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-14 17:20:02,885 - com.hadoop.compression.lzo.LzoCodec -3751 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-14 17:20:02,888 - org.apache.hadoop.conf.Configuration.deprecation -3754 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-14 17:20:02,891 - org.apache.hadoop.io.compress.CodecPool -3757 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 17:20:46,808 - com.infogen.zookeeper.InfoGen_ZooKeeper -0    [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-14 17:20:46,867 - org.apache.zookeeper.ZooKeeper -59   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[framework] 2015-12-14 17:20:46,867 - org.apache.zookeeper.ZooKeeper -59   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:host.name=localhost
[framework] 2015-12-14 17:20:46,867 - org.apache.zookeeper.ZooKeeper -59   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_20
[framework] 2015-12-14 17:20:46,867 - org.apache.zookeeper.ZooKeeper -59   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
[framework] 2015-12-14 17:20:46,868 - org.apache.zookeeper.ZooKeeper -60   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/lib/jvm/java-8-sun/jre
[framework] 2015-12-14 17:20:46,869 - org.apache.zookeeper.ZooKeeper -61   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/home/juxinli/workspace/infogen_etl/target/classes:/home/juxinli/workspace/infogen_etl/lib/hadoop-lzo-0.4.20-SNAPSHOT.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-client/2.7.1/hadoop-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-common/2.7.1/hadoop-common-2.7.1.jar:/home/juxinli/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/juxinli/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/juxinli/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/juxinli/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/juxinli/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/juxinli/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/juxinli/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/juxinli/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/juxinli/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/juxinli/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/juxinli/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/juxinli/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/juxinli/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/juxinli/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/juxinli/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/juxinli/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/juxinli/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.1/hadoop-auth-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/home/juxinli/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/juxinli/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/juxinli/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.1/hadoop-hdfs-2.7.1.jar:/home/juxinli/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/juxinli/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/juxinli/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/juxinli/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/juxinli/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.1/hadoop-mapreduce-client-app-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.1/hadoop-mapreduce-client-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.1/hadoop-yarn-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.1/hadoop-yarn-server-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.1/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.1/hadoop-yarn-api-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.1/hadoop-mapreduce-client-core-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.1/hadoop-yarn-common-2.7.1.jar:/home/juxinli/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/juxinli/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/juxinli/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/juxinli/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.1/hadoop-mapreduce-client-jobclient-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.1/hadoop-annotations-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka_2.11/0.8.2.2/kafka_2.11-0.8.2.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/juxinli/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar:/home/juxinli/.m2/repository/org/scala-lang/scala-library/2.11.5/scala-library-2.11.5.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.2/kafka-clients-0.8.2.2.jar:/home/juxinli/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/juxinli/.m2/repository/net/jpountz/lz4/lz4/1.2.0/lz4-1.2.0.jar:/home/juxinli/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/juxinli/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/juxinli/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/juxinli/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar
[framework] 2015-12-14 17:20:46,872 - org.apache.zookeeper.ZooKeeper -64   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[framework] 2015-12-14 17:20:46,872 - org.apache.zookeeper.ZooKeeper -64   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp
[framework] 2015-12-14 17:20:46,872 - org.apache.zookeeper.ZooKeeper -64   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
[framework] 2015-12-14 17:20:46,872 - org.apache.zookeeper.ZooKeeper -64   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
[framework] 2015-12-14 17:20:46,873 - org.apache.zookeeper.ZooKeeper -65   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
[framework] 2015-12-14 17:20:46,873 - org.apache.zookeeper.ZooKeeper -65   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.2.0-19-generic
[framework] 2015-12-14 17:20:46,873 - org.apache.zookeeper.ZooKeeper -65   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.name=juxinli
[framework] 2015-12-14 17:20:46,873 - org.apache.zookeeper.ZooKeeper -65   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/juxinli
[framework] 2015-12-14 17:20:46,873 - org.apache.zookeeper.ZooKeeper -65   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/home/juxinli/workspace/infogen_etl
[framework] 2015-12-14 17:20:46,875 - org.apache.zookeeper.ZooKeeper -67   [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@4bec1f0c
[framework] 2015-12-14 17:20:46,927 - com.infogen.zookeeper.InfoGen_ZooKeeper -119  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-14 17:20:46,929 - com.infogen.zookeeper.InfoGen_ZooKeeper -121  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/ids
[framework] 2015-12-14 17:20:46,938 - org.apache.zookeeper.ClientCnxn -130  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.98/172.16.8.98:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-14 17:20:47,031 - org.apache.zookeeper.ClientCnxn -223  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.98/172.16.8.98:2181, initiating session
[framework] 2015-12-14 17:20:47,063 - org.apache.zookeeper.ClientCnxn -255  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.98/172.16.8.98:2181, sessionid = 0x6250c64e425606df, negotiated timeout = 10000
[framework] 2015-12-14 17:20:47,066 - com.infogen.zookeeper.InfoGen_ZooKeeper -258  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-14 17:20:47,090 - com.infogen.zookeeper.InfoGen_ZooKeeper -282  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/ids
[framework] 2015-12-14 17:20:47,090 - com.infogen.zookeeper.InfoGen_ZooKeeper -282  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/1
[framework] 2015-12-14 17:20:47,110 - com.infogen.zookeeper.InfoGen_ZooKeeper -302  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/1
[framework] 2015-12-14 17:20:47,111 - com.infogen.zookeeper.InfoGen_ZooKeeper -303  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/2
[framework] 2015-12-14 17:20:47,128 - com.infogen.zookeeper.InfoGen_ZooKeeper -320  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/2
[framework] 2015-12-14 17:20:47,129 - com.infogen.zookeeper.InfoGen_ZooKeeper -321  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/3
[framework] 2015-12-14 17:20:47,147 - com.infogen.zookeeper.InfoGen_ZooKeeper -339  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/3
[framework] 2015-12-14 17:20:47,147 - com.infogen.zookeeper.InfoGen_ZooKeeper -339  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers
[framework] 2015-12-14 17:20:47,174 - com.infogen.zookeeper.InfoGen_ZooKeeper -366  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers
[framework] 2015-12-14 17:20:47,174 - com.infogen.zookeeper.InfoGen_ZooKeeper -366  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-14 17:20:47,197 - com.infogen.zookeeper.InfoGen_ZooKeeper -389  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-14 17:20:47,198 - com.infogen.zookeeper.InfoGen_ZooKeeper -390  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:20:47,219 - com.infogen.zookeeper.InfoGen_ZooKeeper -411  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:20:47,219 - com.infogen.zookeeper.InfoGen_ZooKeeper -411  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:20:47,238 - com.infogen.zookeeper.InfoGen_ZooKeeper -430  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:20:47,238 - com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs -430  [main] INFO  com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs  - #使用zookeeper 中 offset为:0
[framework] 2015-12-14 17:20:47,938 - com.infogen.kafka.InfoGen_Consumer -1130 [main] WARN  com.infogen.kafka.InfoGen_Consumer  - #offset不存在-从最早的offset开始获取:4494174
[framework] 2015-12-14 17:20:48,390 - org.apache.hadoop.util.NativeCodeLoader -1582 [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-14 17:20:49,484 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -2676 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4494174-
[framework] 2015-12-14 17:20:49,543 - com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs -2735 [main] ERROR com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs  - #写入hdfs失败:
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to create file [/infogen/output/infogen_topic_tracking/1/4494174-] for [DFSClient_NONMAPREDUCE_-1088967366_1] for client [192.168.100.203], because this file is already being created by [DFSClient_NONMAPREDUCE_759773558_1] on [192.168.100.203]
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:3035)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2737)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2632)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2519)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:566)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:394)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1476)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy11.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:296)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy12.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1623)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1703)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1638)
	at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:448)
	at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:444)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:459)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:387)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:909)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:890)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:787)
	at com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream.<init>(InfoGen_Hdfs_LZOOutputStream.java:62)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs.handle(Kafka_To_Hdfs.java:49)
	at com.infogen.kafka.InfoGen_Consumer.run(InfoGen_Consumer.java:147)
	at com.infogen.kafka.InfoGen_Consumer.start(InfoGen_Consumer.java:57)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs.main(Kafka_To_Hdfs.java:134)
[framework] 2015-12-14 17:20:50,700 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -3892 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4494174-
[framework] 2015-12-14 17:20:50,722 - com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs -3914 [main] ERROR com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs  - #写入hdfs失败:
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to create file [/infogen/output/infogen_topic_tracking/1/4494174-] for [DFSClient_NONMAPREDUCE_-1088967366_1] for client [192.168.100.203], because this file is already being created by [DFSClient_NONMAPREDUCE_759773558_1] on [192.168.100.203]
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:3035)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2737)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2632)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2519)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:566)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:394)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1476)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy11.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:296)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy12.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1623)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1703)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1638)
	at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:448)
	at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:444)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:459)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:387)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:909)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:890)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:787)
	at com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream.<init>(InfoGen_Hdfs_LZOOutputStream.java:62)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs.handle(Kafka_To_Hdfs.java:49)
	at com.infogen.kafka.InfoGen_Consumer.run(InfoGen_Consumer.java:147)
	at com.infogen.kafka.InfoGen_Consumer.start(InfoGen_Consumer.java:57)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs.main(Kafka_To_Hdfs.java:134)
[framework] 2015-12-14 17:20:51,809 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -5001 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4494174-
[framework] 2015-12-14 17:20:51,825 - com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs -5017 [main] ERROR com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs  - #写入hdfs失败:
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to create file [/infogen/output/infogen_topic_tracking/1/4494174-] for [DFSClient_NONMAPREDUCE_-1088967366_1] for client [192.168.100.203], because this file is already being created by [DFSClient_NONMAPREDUCE_759773558_1] on [192.168.100.203]
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:3035)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2737)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2632)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2519)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:566)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:394)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1476)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy11.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:296)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy12.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1623)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1703)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1638)
	at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:448)
	at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:444)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:459)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:387)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:909)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:890)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:787)
	at com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream.<init>(InfoGen_Hdfs_LZOOutputStream.java:62)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs.handle(Kafka_To_Hdfs.java:49)
	at com.infogen.kafka.InfoGen_Consumer.run(InfoGen_Consumer.java:147)
	at com.infogen.kafka.InfoGen_Consumer.start(InfoGen_Consumer.java:57)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs.main(Kafka_To_Hdfs.java:134)
[framework] 2015-12-14 17:20:52,960 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -6152 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4494174-
[framework] 2015-12-14 17:20:52,983 - com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs -6175 [main] ERROR com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs  - #写入hdfs失败:
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException): Failed to create file [/infogen/output/infogen_topic_tracking/1/4494174-] for [DFSClient_NONMAPREDUCE_-1088967366_1] for client [192.168.100.203], because this file is already being created by [DFSClient_NONMAPREDUCE_759773558_1] on [192.168.100.203]
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:3035)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2737)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2632)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2519)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:566)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:394)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1476)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy11.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:296)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy12.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1623)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1703)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1638)
	at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:448)
	at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:444)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:459)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:387)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:909)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:890)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:787)
	at com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream.<init>(InfoGen_Hdfs_LZOOutputStream.java:62)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs.handle(Kafka_To_Hdfs.java:49)
	at com.infogen.kafka.InfoGen_Consumer.run(InfoGen_Consumer.java:147)
	at com.infogen.kafka.InfoGen_Consumer.start(InfoGen_Consumer.java:57)
	at com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs.main(Kafka_To_Hdfs.java:134)
[framework] 2015-12-14 17:22:06,024 - com.infogen.zookeeper.InfoGen_ZooKeeper -0    [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-14 17:22:06,069 - org.apache.zookeeper.ZooKeeper -45   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[framework] 2015-12-14 17:22:06,069 - org.apache.zookeeper.ZooKeeper -45   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:host.name=localhost
[framework] 2015-12-14 17:22:06,069 - org.apache.zookeeper.ZooKeeper -45   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_20
[framework] 2015-12-14 17:22:06,069 - org.apache.zookeeper.ZooKeeper -45   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
[framework] 2015-12-14 17:22:06,069 - org.apache.zookeeper.ZooKeeper -45   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/lib/jvm/java-8-sun/jre
[framework] 2015-12-14 17:22:06,069 - org.apache.zookeeper.ZooKeeper -45   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/home/juxinli/workspace/infogen_etl/target/classes:/home/juxinli/workspace/infogen_etl/lib/hadoop-lzo-0.4.20-SNAPSHOT.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-client/2.7.1/hadoop-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-common/2.7.1/hadoop-common-2.7.1.jar:/home/juxinli/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/juxinli/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/juxinli/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/juxinli/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/juxinli/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/juxinli/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/juxinli/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/juxinli/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/juxinli/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/juxinli/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/juxinli/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/juxinli/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/juxinli/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/juxinli/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/juxinli/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/juxinli/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/juxinli/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.1/hadoop-auth-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/home/juxinli/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/juxinli/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/juxinli/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.1/hadoop-hdfs-2.7.1.jar:/home/juxinli/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/juxinli/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/juxinli/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/juxinli/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/juxinli/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.1/hadoop-mapreduce-client-app-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.1/hadoop-mapreduce-client-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.1/hadoop-yarn-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.1/hadoop-yarn-server-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.1/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.1/hadoop-yarn-api-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.1/hadoop-mapreduce-client-core-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.1/hadoop-yarn-common-2.7.1.jar:/home/juxinli/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/juxinli/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/juxinli/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/juxinli/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.1/hadoop-mapreduce-client-jobclient-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.1/hadoop-annotations-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka_2.11/0.8.2.2/kafka_2.11-0.8.2.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/juxinli/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar:/home/juxinli/.m2/repository/org/scala-lang/scala-library/2.11.5/scala-library-2.11.5.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.2/kafka-clients-0.8.2.2.jar:/home/juxinli/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/juxinli/.m2/repository/net/jpountz/lz4/lz4/1.2.0/lz4-1.2.0.jar:/home/juxinli/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/juxinli/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/juxinli/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/juxinli/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar
[framework] 2015-12-14 17:22:06,070 - org.apache.zookeeper.ZooKeeper -46   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[framework] 2015-12-14 17:22:06,071 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp
[framework] 2015-12-14 17:22:06,071 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
[framework] 2015-12-14 17:22:06,071 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
[framework] 2015-12-14 17:22:06,071 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
[framework] 2015-12-14 17:22:06,071 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.2.0-19-generic
[framework] 2015-12-14 17:22:06,071 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.name=juxinli
[framework] 2015-12-14 17:22:06,071 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/juxinli
[framework] 2015-12-14 17:22:06,072 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/home/juxinli/workspace/infogen_etl
[framework] 2015-12-14 17:22:06,073 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@4bec1f0c
[framework] 2015-12-14 17:22:06,108 - com.infogen.zookeeper.InfoGen_ZooKeeper -84   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-14 17:22:06,108 - com.infogen.zookeeper.InfoGen_ZooKeeper -84   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/ids
[framework] 2015-12-14 17:22:06,117 - org.apache.zookeeper.ClientCnxn -93   [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.97/172.16.8.97:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-14 17:22:06,189 - org.apache.zookeeper.ClientCnxn -165  [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.97/172.16.8.97:2181, initiating session
[framework] 2015-12-14 17:22:06,210 - org.apache.zookeeper.ClientCnxn -186  [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.97/172.16.8.97:2181, sessionid = 0x614f1aad4d9c803e, negotiated timeout = 10000
[framework] 2015-12-14 17:22:06,212 - com.infogen.zookeeper.InfoGen_ZooKeeper -188  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-14 17:22:06,226 - com.infogen.zookeeper.InfoGen_ZooKeeper -202  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/ids
[framework] 2015-12-14 17:22:06,226 - com.infogen.zookeeper.InfoGen_ZooKeeper -202  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/1
[framework] 2015-12-14 17:22:06,242 - com.infogen.zookeeper.InfoGen_ZooKeeper -218  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/1
[framework] 2015-12-14 17:22:06,242 - com.infogen.zookeeper.InfoGen_ZooKeeper -218  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/2
[framework] 2015-12-14 17:22:06,256 - com.infogen.zookeeper.InfoGen_ZooKeeper -232  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/2
[framework] 2015-12-14 17:22:06,256 - com.infogen.zookeeper.InfoGen_ZooKeeper -232  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/3
[framework] 2015-12-14 17:22:06,269 - com.infogen.zookeeper.InfoGen_ZooKeeper -245  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/3
[framework] 2015-12-14 17:22:06,270 - com.infogen.zookeeper.InfoGen_ZooKeeper -246  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers
[framework] 2015-12-14 17:22:06,285 - com.infogen.zookeeper.InfoGen_ZooKeeper -261  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers
[framework] 2015-12-14 17:22:06,285 - com.infogen.zookeeper.InfoGen_ZooKeeper -261  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-14 17:22:06,298 - com.infogen.zookeeper.InfoGen_ZooKeeper -274  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-14 17:22:06,299 - com.infogen.zookeeper.InfoGen_ZooKeeper -275  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:22:06,312 - com.infogen.zookeeper.InfoGen_ZooKeeper -288  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:22:06,312 - com.infogen.zookeeper.InfoGen_ZooKeeper -288  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:22:06,327 - com.infogen.zookeeper.InfoGen_ZooKeeper -303  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:22:06,328 - com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs -304  [main] INFO  com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs  - #使用zookeeper 中 offset为:0
[framework] 2015-12-14 17:22:07,069 - com.infogen.kafka.InfoGen_Consumer -1045 [main] WARN  com.infogen.kafka.InfoGen_Consumer  - #offset不存在-从最早的offset开始获取:4494174
[framework] 2015-12-14 17:22:07,548 - org.apache.hadoop.util.NativeCodeLoader -1524 [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-14 17:22:08,989 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -2965 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4494174-
[framework] 2015-12-14 17:22:09,192 - com.hadoop.compression.lzo.GPLNativeCodeLoader -3168 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-14 17:22:09,196 - com.hadoop.compression.lzo.LzoCodec -3172 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-14 17:22:09,199 - org.apache.hadoop.conf.Configuration.deprecation -3175 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-14 17:22:09,202 - org.apache.hadoop.io.compress.CodecPool -3178 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 17:23:07,191 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -61167 [Thread-0] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4494174-
[framework] 2015-12-14 17:23:07,597 - com.infogen.zookeeper.InfoGen_ZooKeeper -61573 [Thread-0] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:23:07,615 - com.infogen.zookeeper.InfoGen_ZooKeeper -61591 [Thread-0] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:23:40,856 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -94832 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4675184-
[framework] 2015-12-14 17:24:40,731 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -154707 [Thread-0] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4675184-
[framework] 2015-12-14 17:24:41,248 - com.infogen.zookeeper.InfoGen_ZooKeeper -155224 [Thread-0] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:24:41,264 - com.infogen.zookeeper.InfoGen_ZooKeeper -155240 [Thread-0] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:24:45,425 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -159401 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4675234-
[framework] 2015-12-14 17:25:45,328 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -219304 [Thread-0] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4675234-
[framework] 2015-12-14 17:25:45,839 - com.infogen.zookeeper.InfoGen_ZooKeeper -219815 [Thread-0] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:25:45,855 - com.infogen.zookeeper.InfoGen_ZooKeeper -219831 [Thread-0] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:25:47,767 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -221743 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4675270-
[framework] 2015-12-14 17:26:47,684 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -281660 [Thread-0] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4675270-
[framework] 2015-12-14 17:26:48,324 - com.infogen.zookeeper.InfoGen_ZooKeeper -282300 [Thread-0] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:26:48,340 - com.infogen.zookeeper.InfoGen_ZooKeeper -282316 [Thread-0] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:26:48,927 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -282903 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4675330-
[framework] 2015-12-14 17:27:48,857 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -342833 [Thread-0] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4675330-
[framework] 2015-12-14 17:27:49,487 - com.infogen.zookeeper.InfoGen_ZooKeeper -343463 [Thread-0] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:27:49,502 - com.infogen.zookeeper.InfoGen_ZooKeeper -343478 [Thread-0] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:27:50,391 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -344367 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4675389-
[framework] 2015-12-14 17:28:50,298 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -404274 [Thread-0] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4675389-
[framework] 2015-12-14 17:28:51,057 - com.infogen.zookeeper.InfoGen_ZooKeeper -405033 [Thread-0] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:28:51,075 - com.infogen.zookeeper.InfoGen_ZooKeeper -405051 [Thread-0] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:28:51,228 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -405204 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4675410-
[framework] 2015-12-14 17:29:51,164 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -465140 [Thread-0] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4675410-
[framework] 2015-12-14 17:29:51,620 - com.infogen.zookeeper.InfoGen_ZooKeeper -465596 [Thread-0] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:29:51,634 - com.infogen.zookeeper.InfoGen_ZooKeeper -465610 [Thread-0] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 17:29:52,540 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -466516 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/1/4675436-
[framework] 2015-12-14 17:52:42,616 - com.infogen.kafka.InfoGen_Consumer -0    [main] WARN  com.infogen.kafka.InfoGen_Consumer  - #offset不存在-从最早的offset开始获取:4360015
[framework] 2015-12-14 17:54:50,892 - com.infogen.kafka.InfoGen_Consumer -0    [main] WARN  com.infogen.kafka.InfoGen_Consumer  - #offset不存在-从最早的offset开始获取:4360015
[framework] 2015-12-14 19:29:18,827 - com.infogen.zookeeper.InfoGen_ZooKeeper -0    [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-14 19:29:18,874 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[framework] 2015-12-14 19:29:18,874 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:host.name=localhost
[framework] 2015-12-14 19:29:18,874 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_20
[framework] 2015-12-14 19:29:18,875 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
[framework] 2015-12-14 19:29:18,875 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/lib/jvm/java-8-sun/jre
[framework] 2015-12-14 19:29:18,875 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/home/juxinli/workspace/infogen_etl/target/classes:/home/juxinli/workspace/infogen_etl/lib/hadoop-lzo-0.4.20-SNAPSHOT.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-client/2.7.1/hadoop-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-common/2.7.1/hadoop-common-2.7.1.jar:/home/juxinli/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/juxinli/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/juxinli/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/juxinli/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/juxinli/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/juxinli/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/juxinli/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/juxinli/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/juxinli/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/juxinli/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/juxinli/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/juxinli/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/juxinli/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/juxinli/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/juxinli/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/juxinli/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/juxinli/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.1/hadoop-auth-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/home/juxinli/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/juxinli/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/juxinli/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.1/hadoop-hdfs-2.7.1.jar:/home/juxinli/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/juxinli/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/juxinli/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/juxinli/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/juxinli/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.1/hadoop-mapreduce-client-app-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.1/hadoop-mapreduce-client-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.1/hadoop-yarn-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.1/hadoop-yarn-server-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.1/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.1/hadoop-yarn-api-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.1/hadoop-mapreduce-client-core-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.1/hadoop-yarn-common-2.7.1.jar:/home/juxinli/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/juxinli/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/juxinli/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/juxinli/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.1/hadoop-mapreduce-client-jobclient-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.1/hadoop-annotations-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka_2.11/0.8.2.2/kafka_2.11-0.8.2.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/juxinli/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar:/home/juxinli/.m2/repository/org/scala-lang/scala-library/2.11.5/scala-library-2.11.5.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.2/kafka-clients-0.8.2.2.jar:/home/juxinli/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/juxinli/.m2/repository/net/jpountz/lz4/lz4/1.2.0/lz4-1.2.0.jar:/home/juxinli/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/juxinli/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/juxinli/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/juxinli/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar
[framework] 2015-12-14 19:29:18,876 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[framework] 2015-12-14 19:29:18,877 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp
[framework] 2015-12-14 19:29:18,877 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
[framework] 2015-12-14 19:29:18,877 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
[framework] 2015-12-14 19:29:18,877 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
[framework] 2015-12-14 19:29:18,877 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.2.0-19-generic
[framework] 2015-12-14 19:29:18,877 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.name=juxinli
[framework] 2015-12-14 19:29:18,877 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/juxinli
[framework] 2015-12-14 19:29:18,877 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/home/juxinli/workspace/infogen_etl
[framework] 2015-12-14 19:29:18,879 - org.apache.zookeeper.ZooKeeper -52   [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@4bec1f0c
[framework] 2015-12-14 19:29:18,915 - com.infogen.zookeeper.InfoGen_ZooKeeper -88   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-14 19:29:18,915 - com.infogen.zookeeper.InfoGen_ZooKeeper -88   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/ids
[framework] 2015-12-14 19:29:18,925 - org.apache.zookeeper.ClientCnxn -98   [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.99/172.16.8.99:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-14 19:29:19,007 - org.apache.zookeeper.ClientCnxn -180  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.99/172.16.8.99:2181, initiating session
[framework] 2015-12-14 19:29:19,033 - org.apache.zookeeper.ClientCnxn -206  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.99/172.16.8.99:2181, sessionid = 0x634f1aacb9811f53, negotiated timeout = 10000
[framework] 2015-12-14 19:29:19,037 - com.infogen.zookeeper.InfoGen_ZooKeeper -210  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-14 19:29:19,051 - com.infogen.zookeeper.InfoGen_ZooKeeper -224  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/ids
[framework] 2015-12-14 19:29:19,051 - com.infogen.zookeeper.InfoGen_ZooKeeper -224  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/1
[framework] 2015-12-14 19:29:19,069 - com.infogen.zookeeper.InfoGen_ZooKeeper -242  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/1
[framework] 2015-12-14 19:29:19,070 - com.infogen.zookeeper.InfoGen_ZooKeeper -243  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/2
[framework] 2015-12-14 19:29:19,083 - com.infogen.zookeeper.InfoGen_ZooKeeper -256  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/2
[framework] 2015-12-14 19:29:19,085 - com.infogen.zookeeper.InfoGen_ZooKeeper -258  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/3
[framework] 2015-12-14 19:29:19,099 - com.infogen.zookeeper.InfoGen_ZooKeeper -272  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/3
[framework] 2015-12-14 19:29:19,099 - com.infogen.zookeeper.InfoGen_ZooKeeper -272  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers
[framework] 2015-12-14 19:29:19,114 - com.infogen.zookeeper.InfoGen_ZooKeeper -287  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers
[framework] 2015-12-14 19:29:19,115 - com.infogen.zookeeper.InfoGen_ZooKeeper -288  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-14 19:29:19,128 - com.infogen.zookeeper.InfoGen_ZooKeeper -301  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-14 19:29:19,129 - com.infogen.zookeeper.InfoGen_ZooKeeper -302  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 19:29:19,142 - com.infogen.zookeeper.InfoGen_ZooKeeper -315  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 19:29:19,143 - com.infogen.zookeeper.InfoGen_ZooKeeper -316  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 19:29:19,156 - com.infogen.zookeeper.InfoGen_ZooKeeper -329  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/infogen_consumers/infogen_topic_tracking/1
[framework] 2015-12-14 19:29:19,156 - com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs -329  [main] INFO  com.infogen.etl.kafka_to_hdfs.Kafka_To_Hdfs  - #使用zookeeper 中 offset为:0
[framework] 2015-12-14 19:29:20,522 - org.apache.hadoop.util.NativeCodeLoader -1695 [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-14 19:29:21,626 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -2799 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/29/1.4675435-
[framework] 2015-12-14 19:29:21,834 - com.hadoop.compression.lzo.GPLNativeCodeLoader -3007 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-14 19:29:21,838 - com.hadoop.compression.lzo.LzoCodec -3011 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-14 19:29:21,840 - org.apache.hadoop.conf.Configuration.deprecation -3013 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-14 19:29:21,843 - org.apache.hadoop.io.compress.CodecPool -3016 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:21,940 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -3113 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/29/1.4675436-
[framework] 2015-12-14 19:29:22,020 - org.apache.hadoop.io.compress.CodecPool -3193 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:22,109 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -3282 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/29/1.4675437-
[framework] 2015-12-14 19:29:22,198 - org.apache.hadoop.io.compress.CodecPool -3371 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:22,298 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -3471 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/29/1.4675438-
[framework] 2015-12-14 19:29:22,411 - org.apache.hadoop.io.compress.CodecPool -3584 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:22,516 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -3689 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675439-
[framework] 2015-12-14 19:29:22,629 - org.apache.hadoop.io.compress.CodecPool -3802 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:22,710 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -3883 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675440-
[framework] 2015-12-14 19:29:22,802 - org.apache.hadoop.io.compress.CodecPool -3975 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:22,904 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -4077 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675441-
[framework] 2015-12-14 19:29:22,985 - org.apache.hadoop.io.compress.CodecPool -4158 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:23,087 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -4260 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675442-
[framework] 2015-12-14 19:29:23,177 - org.apache.hadoop.io.compress.CodecPool -4350 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:23,247 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -4420 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675443-
[framework] 2015-12-14 19:29:23,335 - org.apache.hadoop.io.compress.CodecPool -4508 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:23,401 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -4574 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675444-
[framework] 2015-12-14 19:29:23,486 - org.apache.hadoop.io.compress.CodecPool -4659 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:23,563 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -4736 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675445-
[framework] 2015-12-14 19:29:23,643 - org.apache.hadoop.io.compress.CodecPool -4816 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:23,702 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -4875 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675446-
[framework] 2015-12-14 19:29:23,897 - org.apache.hadoop.io.compress.CodecPool -5070 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:24,014 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -5187 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675447-
[framework] 2015-12-14 19:29:24,186 - org.apache.hadoop.io.compress.CodecPool -5359 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:24,250 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -5423 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675448-
[framework] 2015-12-14 19:29:24,377 - org.apache.hadoop.io.compress.CodecPool -5550 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:24,440 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -5613 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675449-
[framework] 2015-12-14 19:29:24,603 - org.apache.hadoop.io.compress.CodecPool -5776 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:24,664 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -5837 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675450-
[framework] 2015-12-14 19:29:24,760 - org.apache.hadoop.io.compress.CodecPool -5933 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:24,832 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -6005 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675451-
[framework] 2015-12-14 19:29:24,928 - org.apache.hadoop.io.compress.CodecPool -6101 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:24,992 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -6165 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675452-
[framework] 2015-12-14 19:29:25,095 - org.apache.hadoop.io.compress.CodecPool -6268 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:25,168 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -6341 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675453-
[framework] 2015-12-14 19:29:25,269 - org.apache.hadoop.io.compress.CodecPool -6442 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:25,360 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -6533 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675454-
[framework] 2015-12-14 19:29:25,460 - org.apache.hadoop.io.compress.CodecPool -6633 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:25,518 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -6691 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675455-
[framework] 2015-12-14 19:29:25,699 - org.apache.hadoop.io.compress.CodecPool -6872 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:25,771 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -6944 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675456-
[framework] 2015-12-14 19:29:25,860 - org.apache.hadoop.io.compress.CodecPool -7033 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:25,935 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -7108 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675457-
[framework] 2015-12-14 19:29:26,019 - org.apache.hadoop.io.compress.CodecPool -7192 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:26,082 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -7255 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675458-
[framework] 2015-12-14 19:29:26,169 - org.apache.hadoop.io.compress.CodecPool -7342 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:26,236 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -7409 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675459-
[framework] 2015-12-14 19:29:26,328 - org.apache.hadoop.io.compress.CodecPool -7501 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:26,389 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -7562 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675460-
[framework] 2015-12-14 19:29:26,492 - org.apache.hadoop.io.compress.CodecPool -7665 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:26,585 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -7758 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675461-
[framework] 2015-12-14 19:29:26,678 - org.apache.hadoop.io.compress.CodecPool -7851 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:26,739 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -7912 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675462-
[framework] 2015-12-14 19:29:26,828 - org.apache.hadoop.io.compress.CodecPool -8001 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:26,894 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -8067 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675463-
[framework] 2015-12-14 19:29:26,978 - org.apache.hadoop.io.compress.CodecPool -8151 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:27,042 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -8215 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675464-
[framework] 2015-12-14 19:29:27,135 - org.apache.hadoop.io.compress.CodecPool -8308 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:27,200 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -8373 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675465-
[framework] 2015-12-14 19:29:27,279 - org.apache.hadoop.io.compress.CodecPool -8452 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:27,337 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -8510 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675466-
[framework] 2015-12-14 19:29:27,419 - org.apache.hadoop.io.compress.CodecPool -8592 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:27,478 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -8651 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675467-
[framework] 2015-12-14 19:29:27,569 - org.apache.hadoop.io.compress.CodecPool -8742 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:27,635 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -8808 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675468-
[framework] 2015-12-14 19:29:27,727 - org.apache.hadoop.io.compress.CodecPool -8900 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:27,785 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -8958 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675469-
[framework] 2015-12-14 19:29:27,860 - org.apache.hadoop.io.compress.CodecPool -9033 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:27,925 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -9098 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675470-
[framework] 2015-12-14 19:29:28,010 - org.apache.hadoop.io.compress.CodecPool -9183 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:28,077 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -9250 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675471-
[framework] 2015-12-14 19:29:28,177 - org.apache.hadoop.io.compress.CodecPool -9350 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:28,247 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -9420 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675472-
[framework] 2015-12-14 19:29:28,327 - org.apache.hadoop.io.compress.CodecPool -9500 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:28,395 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -9568 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675473-
[framework] 2015-12-14 19:29:28,597 - org.apache.hadoop.io.compress.CodecPool -9770 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:28,661 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -9834 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675474-
[framework] 2015-12-14 19:29:28,794 - org.apache.hadoop.io.compress.CodecPool -9967 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:28,863 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -10036 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675475-
[framework] 2015-12-14 19:29:29,080 - org.apache.hadoop.io.compress.CodecPool -10253 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:29,156 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -10329 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675476-
[framework] 2015-12-14 19:29:29,257 - org.apache.hadoop.io.compress.CodecPool -10430 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:29,316 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -10489 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675477-
[framework] 2015-12-14 19:29:29,618 - org.apache.hadoop.io.compress.CodecPool -10791 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:29,683 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -10856 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675478-
[framework] 2015-12-14 19:29:29,876 - org.apache.hadoop.io.compress.CodecPool -11049 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:29,940 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -11113 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675479-
[framework] 2015-12-14 19:29:30,018 - org.apache.hadoop.io.compress.CodecPool -11191 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:30,085 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -11258 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675480-
[framework] 2015-12-14 19:29:30,168 - org.apache.hadoop.io.compress.CodecPool -11341 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:30,229 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -11402 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675481-
[framework] 2015-12-14 19:29:30,360 - org.apache.hadoop.io.compress.CodecPool -11533 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:30,425 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -11598 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675482-
[framework] 2015-12-14 19:29:30,501 - org.apache.hadoop.io.compress.CodecPool -11674 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:30,565 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -11738 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675483-
[framework] 2015-12-14 19:29:30,651 - org.apache.hadoop.io.compress.CodecPool -11824 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:30,721 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -11894 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675484-
[framework] 2015-12-14 19:29:30,810 - org.apache.hadoop.io.compress.CodecPool -11983 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:30,872 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -12045 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675485-
[framework] 2015-12-14 19:29:30,959 - org.apache.hadoop.io.compress.CodecPool -12132 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:31,018 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -12191 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675486-
[framework] 2015-12-14 19:29:31,109 - org.apache.hadoop.io.compress.CodecPool -12282 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:31,170 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -12343 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675487-
[framework] 2015-12-14 19:29:31,243 - org.apache.hadoop.io.compress.CodecPool -12416 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:31,331 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -12504 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675488-
[framework] 2015-12-14 19:29:31,426 - org.apache.hadoop.io.compress.CodecPool -12599 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:31,485 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -12658 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675489-
[framework] 2015-12-14 19:29:31,576 - org.apache.hadoop.io.compress.CodecPool -12749 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-14 19:29:31,634 - com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream -12807 [main] INFO  com.infogen.hdfs.InfoGen_Hdfs_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/30/1.4675490-
[framework] 2015-12-15 16:17:48,321 - com.infogen.zookeeper.InfoGen_ZooKeeper -0    [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-15 16:17:48,369 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[framework] 2015-12-15 16:17:48,370 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:host.name=localhost
[framework] 2015-12-15 16:17:48,371 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_20
[framework] 2015-12-15 16:17:48,371 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
[framework] 2015-12-15 16:17:48,371 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/lib/jvm/java-8-sun/jre
[framework] 2015-12-15 16:17:48,371 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/home/juxinli/workspace/infogen_etl/target/classes:/home/juxinli/workspace/infogen_etl/lib/hadoop-lzo-0.4.20-SNAPSHOT.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-client/2.7.1/hadoop-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-common/2.7.1/hadoop-common-2.7.1.jar:/home/juxinli/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/juxinli/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/juxinli/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/juxinli/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/juxinli/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/juxinli/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/juxinli/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/juxinli/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/juxinli/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/juxinli/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/juxinli/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/juxinli/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/juxinli/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/juxinli/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/juxinli/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/juxinli/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/juxinli/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.1/hadoop-auth-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/home/juxinli/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/juxinli/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/juxinli/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.1/hadoop-hdfs-2.7.1.jar:/home/juxinli/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/juxinli/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/juxinli/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/juxinli/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/juxinli/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.1/hadoop-mapreduce-client-app-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.1/hadoop-mapreduce-client-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.1/hadoop-yarn-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.1/hadoop-yarn-server-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.1/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.1/hadoop-yarn-api-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.1/hadoop-mapreduce-client-core-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.1/hadoop-yarn-common-2.7.1.jar:/home/juxinli/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/juxinli/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/juxinli/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/juxinli/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.1/hadoop-mapreduce-client-jobclient-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.1/hadoop-annotations-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka_2.11/0.8.2.2/kafka_2.11-0.8.2.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/juxinli/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar:/home/juxinli/.m2/repository/org/scala-lang/scala-library/2.11.5/scala-library-2.11.5.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.2/kafka-clients-0.8.2.2.jar:/home/juxinli/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/juxinli/.m2/repository/net/jpountz/lz4/lz4/1.2.0/lz4-1.2.0.jar:/home/juxinli/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/juxinli/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/juxinli/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/juxinli/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar
[framework] 2015-12-15 16:17:48,372 - org.apache.zookeeper.ZooKeeper -51   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[framework] 2015-12-15 16:17:48,372 - org.apache.zookeeper.ZooKeeper -51   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp
[framework] 2015-12-15 16:17:48,373 - org.apache.zookeeper.ZooKeeper -52   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
[framework] 2015-12-15 16:17:48,373 - org.apache.zookeeper.ZooKeeper -52   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
[framework] 2015-12-15 16:17:48,373 - org.apache.zookeeper.ZooKeeper -52   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
[framework] 2015-12-15 16:17:48,373 - org.apache.zookeeper.ZooKeeper -52   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.2.0-19-generic
[framework] 2015-12-15 16:17:48,373 - org.apache.zookeeper.ZooKeeper -52   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.name=juxinli
[framework] 2015-12-15 16:17:48,374 - org.apache.zookeeper.ZooKeeper -53   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/juxinli
[framework] 2015-12-15 16:17:48,374 - org.apache.zookeeper.ZooKeeper -53   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/home/juxinli/workspace/infogen_etl
[framework] 2015-12-15 16:17:48,376 - org.apache.zookeeper.ZooKeeper -55   [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@5c5a1b69
[framework] 2015-12-15 16:17:48,413 - com.infogen.zookeeper.InfoGen_ZooKeeper -92   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-15 16:17:48,415 - org.apache.zookeeper.ClientCnxn -94   [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.99/172.16.8.99:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-15 16:17:48,416 - com.infogen.zookeeper.InfoGen_ZooKeeper -95   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers
[framework] 2015-12-15 16:17:48,499 - org.apache.zookeeper.ClientCnxn -178  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.99/172.16.8.99:2181, initiating session
[framework] 2015-12-15 16:17:48,521 - org.apache.zookeeper.ClientCnxn -200  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.99/172.16.8.99:2181, sessionid = 0x634f1aacb9811f6d, negotiated timeout = 10000
[framework] 2015-12-15 16:17:48,525 - com.infogen.zookeeper.InfoGen_ZooKeeper -204  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-15 16:17:48,564 - com.infogen.zookeeper.InfoGen_ZooKeeper -243  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers
[framework] 2015-12-15 16:17:48,564 - com.infogen.zookeeper.InfoGen_ZooKeeper -243  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-15 16:17:48,581 - com.infogen.zookeeper.InfoGen_ZooKeeper -260  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-15 16:17:48,581 - com.infogen.zookeeper.InfoGen_ZooKeeper -260  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset
[framework] 2015-12-15 16:17:48,599 - com.infogen.zookeeper.InfoGen_ZooKeeper -278  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset
[framework] 2015-12-15 16:17:48,603 - com.infogen.zookeeper.InfoGen_ZooKeeper -282  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/offset
[framework] 2015-12-15 16:17:48,624 - com.infogen.zookeeper.InfoGen_ZooKeeper -303  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking/offset
[framework] 2015-12-15 16:17:48,624 - com.infogen.zookeeper.InfoGen_ZooKeeper -303  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-15 16:17:48,638 - com.infogen.zookeeper.InfoGen_ZooKeeper -317  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-15 16:17:48,638 - com.infogen.zookeeper.InfoGen_ZooKeeper -317  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-15 16:17:48,654 - com.infogen.zookeeper.InfoGen_ZooKeeper -333  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-15 16:17:48,654 - com.infogen.zookeeper.InfoGen_ZooKeeper -333  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-15 16:17:48,672 - com.infogen.zookeeper.InfoGen_ZooKeeper -351  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-15 16:17:48,673 - com.infogen.zookeeper.InfoGen_ZooKeeper -352  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-15 16:17:48,686 - com.infogen.zookeeper.InfoGen_ZooKeeper -365  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-15 16:17:48,686 - com.infogen.zookeeper.InfoGen_ZooKeeper -365  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-15 16:17:48,700 - com.infogen.zookeeper.InfoGen_ZooKeeper -379  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-15 16:17:48,700 - com.infogen.etl.InfoGen_Container -379  [main] INFO  com.infogen.etl.InfoGen_Container  - #创建partition成功:0
[framework] 2015-12-15 16:17:48,701 - com.infogen.zookeeper.InfoGen_ZooKeeper -380  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/partition/1
[framework] 2015-12-15 16:17:48,716 - com.infogen.zookeeper.InfoGen_ZooKeeper -395  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking/partition/1
[framework] 2015-12-15 16:17:48,717 - com.infogen.etl.InfoGen_Container -396  [main] INFO  com.infogen.etl.InfoGen_Container  - #创建partition成功:1
[framework] 2015-12-15 16:17:48,717 - com.infogen.zookeeper.InfoGen_ZooKeeper -396  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/partition/2
[framework] 2015-12-15 16:17:48,747 - com.infogen.zookeeper.InfoGen_ZooKeeper -426  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking/partition/2
[framework] 2015-12-15 16:17:48,747 - com.infogen.etl.InfoGen_Container -426  [main] INFO  com.infogen.etl.InfoGen_Container  - #创建partition成功:2
[framework] 2015-12-15 16:17:48,747 - com.infogen.zookeeper.InfoGen_ZooKeeper -426  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/ids
[framework] 2015-12-15 16:17:48,763 - com.infogen.zookeeper.InfoGen_ZooKeeper -442  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/ids
[framework] 2015-12-15 16:17:48,764 - com.infogen.zookeeper.InfoGen_ZooKeeper -443  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/1
[framework] 2015-12-15 16:17:48,784 - com.infogen.zookeeper.InfoGen_ZooKeeper -463  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/1
[framework] 2015-12-15 16:17:48,785 - com.infogen.zookeeper.InfoGen_ZooKeeper -464  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/2
[framework] 2015-12-15 16:17:48,799 - com.infogen.zookeeper.InfoGen_ZooKeeper -478  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/2
[framework] 2015-12-15 16:17:48,800 - com.infogen.zookeeper.InfoGen_ZooKeeper -479  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/3
[framework] 2015-12-15 16:17:48,813 - com.infogen.zookeeper.InfoGen_ZooKeeper -492  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/3
[framework] 2015-12-15 16:17:48,814 - com.infogen.zookeeper.InfoGen_ZooKeeper -493  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/offset/2
[framework] 2015-12-15 16:17:48,843 - com.infogen.zookeeper.InfoGen_ZooKeeper -522  [main] ERROR com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据错误: 
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /infogen_consumers/infogen_topic_tracking/offset/2
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1184)
	at com.infogen.zookeeper.InfoGen_ZooKeeper.get_data(InfoGen_ZooKeeper.java:170)
	at com.infogen.etl.InfoGen_Container.main(InfoGen_Container.java:94)
[framework] 2015-12-15 16:17:48,847 - com.infogen.zookeeper.InfoGen_ZooKeeper -526  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/2
[framework] 2015-12-15 16:17:48,863 - com.infogen.zookeeper.InfoGen_ZooKeeper -542  [main] ERROR com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据失败: 
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /infogen_consumers/infogen_topic_tracking/offset/2
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1270)
	at com.infogen.zookeeper.InfoGen_ZooKeeper.set_data(InfoGen_ZooKeeper.java:184)
	at com.infogen.etl.InfoGen_Container.main(InfoGen_Container.java:99)
[framework] 2015-12-15 16:17:48,864 - com.infogen.etl.InfoGen_Container -543  [main] INFO  com.infogen.etl.InfoGen_Container  - #使用默认 offset为:0
[framework] 2015-12-15 16:17:49,619 - com.infogen.kafka.InfoGen_Consumer -1298 [main] WARN  com.infogen.kafka.InfoGen_Consumer  - #offset不存在-从最早的offset开始获取:4360015
[framework] 2015-12-15 16:17:50,187 - org.apache.hadoop.util.NativeCodeLoader -1866 [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-15 16:17:51,284 - com.infogen.hdfs.InfoGen_LZOOutputStream -2963 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/2.4360015-
[framework] 2015-12-15 16:17:51,484 - com.hadoop.compression.lzo.GPLNativeCodeLoader -3163 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-15 16:17:51,488 - com.hadoop.compression.lzo.LzoCodec -3167 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-15 16:17:51,491 - org.apache.hadoop.conf.Configuration.deprecation -3170 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-15 16:17:51,494 - org.apache.hadoop.io.compress.CodecPool -3173 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:51,644 - com.infogen.hdfs.InfoGen_LZOOutputStream -3323 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-5/2.4360016-
[framework] 2015-12-15 16:17:51,781 - org.apache.hadoop.io.compress.CodecPool -3460 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:51,863 - com.infogen.hdfs.InfoGen_LZOOutputStream -3542 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360017-
[framework] 2015-12-15 16:17:51,940 - org.apache.hadoop.io.compress.CodecPool -3619 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:52,022 - com.infogen.hdfs.InfoGen_LZOOutputStream -3701 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360018-
[framework] 2015-12-15 16:17:52,102 - org.apache.hadoop.io.compress.CodecPool -3781 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:52,193 - com.infogen.hdfs.InfoGen_LZOOutputStream -3872 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360019-
[framework] 2015-12-15 16:17:52,327 - org.apache.hadoop.io.compress.CodecPool -4006 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:52,414 - com.infogen.hdfs.InfoGen_LZOOutputStream -4093 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/2.4360020-
[framework] 2015-12-15 16:17:52,481 - org.apache.hadoop.io.compress.CodecPool -4160 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:52,554 - com.infogen.hdfs.InfoGen_LZOOutputStream -4233 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/2.4360021-
[framework] 2015-12-15 16:17:52,621 - org.apache.hadoop.io.compress.CodecPool -4300 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:52,702 - com.infogen.hdfs.InfoGen_LZOOutputStream -4381 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/2.4360022-
[framework] 2015-12-15 16:17:52,777 - org.apache.hadoop.io.compress.CodecPool -4456 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:52,843 - com.infogen.hdfs.InfoGen_LZOOutputStream -4522 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/2.4360023-
[framework] 2015-12-15 16:17:52,910 - org.apache.hadoop.io.compress.CodecPool -4589 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:52,980 - com.infogen.hdfs.InfoGen_LZOOutputStream -4659 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/2.4360024-
[framework] 2015-12-15 16:17:53,143 - org.apache.hadoop.io.compress.CodecPool -4822 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:53,205 - com.infogen.hdfs.InfoGen_LZOOutputStream -4884 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/2.4360025-
[framework] 2015-12-15 16:17:53,273 - org.apache.hadoop.io.compress.CodecPool -4952 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:53,352 - com.infogen.hdfs.InfoGen_LZOOutputStream -5031 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360026-
[framework] 2015-12-15 16:17:53,418 - org.apache.hadoop.io.compress.CodecPool -5097 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:53,496 - com.infogen.hdfs.InfoGen_LZOOutputStream -5175 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360027-
[framework] 2015-12-15 16:17:53,568 - org.apache.hadoop.io.compress.CodecPool -5247 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:53,639 - com.infogen.hdfs.InfoGen_LZOOutputStream -5318 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360028-
[framework] 2015-12-15 16:17:53,716 - org.apache.hadoop.io.compress.CodecPool -5395 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:53,780 - com.infogen.hdfs.InfoGen_LZOOutputStream -5459 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360029-
[framework] 2015-12-15 16:17:53,845 - org.apache.hadoop.io.compress.CodecPool -5524 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:53,926 - com.infogen.hdfs.InfoGen_LZOOutputStream -5605 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360030-
[framework] 2015-12-15 16:17:53,986 - org.apache.hadoop.io.compress.CodecPool -5665 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:54,051 - com.infogen.hdfs.InfoGen_LZOOutputStream -5730 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360031-
[framework] 2015-12-15 16:17:54,119 - org.apache.hadoop.io.compress.CodecPool -5798 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:54,187 - com.infogen.hdfs.InfoGen_LZOOutputStream -5866 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360032-
[framework] 2015-12-15 16:17:54,268 - org.apache.hadoop.io.compress.CodecPool -5947 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:54,327 - com.infogen.hdfs.InfoGen_LZOOutputStream -6006 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360033-
[framework] 2015-12-15 16:17:54,401 - org.apache.hadoop.io.compress.CodecPool -6080 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:54,475 - com.infogen.hdfs.InfoGen_LZOOutputStream -6154 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360034-
[framework] 2015-12-15 16:17:54,551 - org.apache.hadoop.io.compress.CodecPool -6230 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:54,629 - com.infogen.hdfs.InfoGen_LZOOutputStream -6308 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360035-
[framework] 2015-12-15 16:17:54,702 - org.apache.hadoop.io.compress.CodecPool -6381 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:54,770 - com.infogen.hdfs.InfoGen_LZOOutputStream -6449 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360036-
[framework] 2015-12-15 16:17:55,065 - org.apache.hadoop.io.compress.CodecPool -6744 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:55,194 - com.infogen.hdfs.InfoGen_LZOOutputStream -6873 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360037-
[framework] 2015-12-15 16:17:55,265 - org.apache.hadoop.io.compress.CodecPool -6944 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:55,329 - com.infogen.hdfs.InfoGen_LZOOutputStream -7008 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360038-
[framework] 2015-12-15 16:17:55,408 - org.apache.hadoop.io.compress.CodecPool -7087 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:55,465 - com.infogen.hdfs.InfoGen_LZOOutputStream -7144 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360039-
[framework] 2015-12-15 16:17:55,535 - org.apache.hadoop.io.compress.CodecPool -7214 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:55,617 - com.infogen.hdfs.InfoGen_LZOOutputStream -7296 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360040-
[framework] 2015-12-15 16:17:55,927 - org.apache.hadoop.io.compress.CodecPool -7606 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:55,987 - com.infogen.hdfs.InfoGen_LZOOutputStream -7666 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360041-
[framework] 2015-12-15 16:17:56,164 - org.apache.hadoop.io.compress.CodecPool -7843 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:56,242 - com.infogen.hdfs.InfoGen_LZOOutputStream -7921 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360042-
[framework] 2015-12-15 16:17:56,318 - org.apache.hadoop.io.compress.CodecPool -7997 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:56,393 - com.infogen.hdfs.InfoGen_LZOOutputStream -8072 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360043-
[framework] 2015-12-15 16:17:56,559 - org.apache.hadoop.io.compress.CodecPool -8238 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:56,628 - com.infogen.hdfs.InfoGen_LZOOutputStream -8307 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360044-
[framework] 2015-12-15 16:17:56,703 - org.apache.hadoop.io.compress.CodecPool -8382 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:56,770 - com.infogen.hdfs.InfoGen_LZOOutputStream -8449 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360045-
[framework] 2015-12-15 16:17:56,848 - org.apache.hadoop.io.compress.CodecPool -8527 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:56,914 - com.infogen.hdfs.InfoGen_LZOOutputStream -8593 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360046-
[framework] 2015-12-15 16:17:56,985 - org.apache.hadoop.io.compress.CodecPool -8664 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:57,058 - com.infogen.hdfs.InfoGen_LZOOutputStream -8737 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360047-
[framework] 2015-12-15 16:17:57,150 - org.apache.hadoop.io.compress.CodecPool -8829 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:57,226 - com.infogen.hdfs.InfoGen_LZOOutputStream -8905 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360048-
[framework] 2015-12-15 16:17:57,306 - org.apache.hadoop.io.compress.CodecPool -8985 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:57,402 - com.infogen.hdfs.InfoGen_LZOOutputStream -9081 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360049-
[framework] 2015-12-15 16:17:57,475 - org.apache.hadoop.io.compress.CodecPool -9154 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:57,555 - com.infogen.hdfs.InfoGen_LZOOutputStream -9234 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360050-
[framework] 2015-12-15 16:17:57,625 - org.apache.hadoop.io.compress.CodecPool -9304 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:57,685 - com.infogen.hdfs.InfoGen_LZOOutputStream -9364 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360051-
[framework] 2015-12-15 16:17:57,764 - org.apache.hadoop.io.compress.CodecPool -9443 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:57,829 - com.infogen.hdfs.InfoGen_LZOOutputStream -9508 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360052-
[framework] 2015-12-15 16:17:57,917 - org.apache.hadoop.io.compress.CodecPool -9596 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:57,978 - com.infogen.hdfs.InfoGen_LZOOutputStream -9657 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360053-
[framework] 2015-12-15 16:17:58,062 - org.apache.hadoop.io.compress.CodecPool -9741 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:58,127 - com.infogen.hdfs.InfoGen_LZOOutputStream -9806 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360054-
[framework] 2015-12-15 16:17:58,224 - org.apache.hadoop.io.compress.CodecPool -9903 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:58,298 - com.infogen.hdfs.InfoGen_LZOOutputStream -9977 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360055-
[framework] 2015-12-15 16:17:58,383 - org.apache.hadoop.io.compress.CodecPool -10062 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:58,442 - com.infogen.hdfs.InfoGen_LZOOutputStream -10121 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-4/2.4360056-
[framework] 2015-12-15 16:17:58,517 - org.apache.hadoop.io.compress.CodecPool -10196 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:58,606 - com.infogen.hdfs.InfoGen_LZOOutputStream -10285 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360057-
[framework] 2015-12-15 16:17:58,675 - org.apache.hadoop.io.compress.CodecPool -10354 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:58,728 - com.infogen.hdfs.InfoGen_LZOOutputStream -10407 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360058-
[framework] 2015-12-15 16:17:58,840 - org.apache.hadoop.io.compress.CodecPool -10519 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:58,900 - com.infogen.hdfs.InfoGen_LZOOutputStream -10579 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360059-
[framework] 2015-12-15 16:17:58,972 - org.apache.hadoop.io.compress.CodecPool -10651 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:59,033 - com.infogen.hdfs.InfoGen_LZOOutputStream -10712 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360060-
[framework] 2015-12-15 16:17:59,114 - org.apache.hadoop.io.compress.CodecPool -10793 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:59,177 - com.infogen.hdfs.InfoGen_LZOOutputStream -10856 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360061-
[framework] 2015-12-15 16:17:59,265 - org.apache.hadoop.io.compress.CodecPool -10944 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:59,332 - com.infogen.hdfs.InfoGen_LZOOutputStream -11011 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360062-
[framework] 2015-12-15 16:17:59,405 - org.apache.hadoop.io.compress.CodecPool -11084 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:59,464 - com.infogen.hdfs.InfoGen_LZOOutputStream -11143 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360063-
[framework] 2015-12-15 16:17:59,538 - org.apache.hadoop.io.compress.CodecPool -11217 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:59,598 - com.infogen.hdfs.InfoGen_LZOOutputStream -11277 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360064-
[framework] 2015-12-15 16:17:59,759 - org.apache.hadoop.io.compress.CodecPool -11438 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:17:59,848 - com.infogen.hdfs.InfoGen_LZOOutputStream -11527 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360065-
[framework] 2015-12-15 16:18:00,155 - org.apache.hadoop.io.compress.CodecPool -11834 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:00,230 - com.infogen.hdfs.InfoGen_LZOOutputStream -11909 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360066-
[framework] 2015-12-15 16:18:00,303 - org.apache.hadoop.io.compress.CodecPool -11982 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:00,372 - com.infogen.hdfs.InfoGen_LZOOutputStream -12051 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360067-
[framework] 2015-12-15 16:18:00,449 - org.apache.hadoop.io.compress.CodecPool -12128 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:00,512 - com.infogen.hdfs.InfoGen_LZOOutputStream -12191 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360068-
[framework] 2015-12-15 16:18:00,587 - org.apache.hadoop.io.compress.CodecPool -12266 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:00,701 - com.infogen.hdfs.InfoGen_LZOOutputStream -12380 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360069-
[framework] 2015-12-15 16:18:00,771 - org.apache.hadoop.io.compress.CodecPool -12450 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:00,837 - com.infogen.hdfs.InfoGen_LZOOutputStream -12516 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360070-
[framework] 2015-12-15 16:18:01,133 - org.apache.hadoop.io.compress.CodecPool -12812 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:01,219 - com.infogen.hdfs.InfoGen_LZOOutputStream -12898 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360071-
[framework] 2015-12-15 16:18:01,300 - org.apache.hadoop.io.compress.CodecPool -12979 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:01,359 - com.infogen.hdfs.InfoGen_LZOOutputStream -13038 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360072-
[framework] 2015-12-15 16:18:01,421 - org.apache.hadoop.io.compress.CodecPool -13100 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:01,473 - com.infogen.hdfs.InfoGen_LZOOutputStream -13152 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360073-
[framework] 2015-12-15 16:18:01,582 - org.apache.hadoop.io.compress.CodecPool -13261 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:01,656 - com.infogen.hdfs.InfoGen_LZOOutputStream -13335 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360074-
[framework] 2015-12-15 16:18:01,740 - org.apache.hadoop.io.compress.CodecPool -13419 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:01,806 - com.infogen.hdfs.InfoGen_LZOOutputStream -13485 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360075-
[framework] 2015-12-15 16:18:01,890 - org.apache.hadoop.io.compress.CodecPool -13569 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:01,946 - com.infogen.hdfs.InfoGen_LZOOutputStream -13625 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360076-
[framework] 2015-12-15 16:18:02,029 - org.apache.hadoop.io.compress.CodecPool -13708 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:02,085 - com.infogen.hdfs.InfoGen_LZOOutputStream -13764 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360077-
[framework] 2015-12-15 16:18:02,241 - org.apache.hadoop.io.compress.CodecPool -13920 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:02,319 - com.infogen.hdfs.InfoGen_LZOOutputStream -13998 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360078-
[framework] 2015-12-15 16:18:02,580 - org.apache.hadoop.io.compress.CodecPool -14259 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:02,653 - com.infogen.hdfs.InfoGen_LZOOutputStream -14332 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360079-
[framework] 2015-12-15 16:18:02,840 - org.apache.hadoop.io.compress.CodecPool -14519 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:02,898 - com.infogen.hdfs.InfoGen_LZOOutputStream -14577 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360080-
[framework] 2015-12-15 16:18:02,987 - org.apache.hadoop.io.compress.CodecPool -14666 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:03,048 - com.infogen.hdfs.InfoGen_LZOOutputStream -14727 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/2.4360081-
[framework] 2015-12-15 16:18:03,116 - org.apache.hadoop.io.compress.CodecPool -14795 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:03,191 - com.infogen.hdfs.InfoGen_LZOOutputStream -14870 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360082-
[framework] 2015-12-15 16:18:03,263 - org.apache.hadoop.io.compress.CodecPool -14942 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:03,330 - com.infogen.hdfs.InfoGen_LZOOutputStream -15009 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360083-
[framework] 2015-12-15 16:18:03,429 - org.apache.hadoop.io.compress.CodecPool -15108 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:03,511 - com.infogen.hdfs.InfoGen_LZOOutputStream -15190 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360084-
[framework] 2015-12-15 16:18:03,580 - org.apache.hadoop.io.compress.CodecPool -15259 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:03,636 - com.infogen.hdfs.InfoGen_LZOOutputStream -15315 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360085-
[framework] 2015-12-15 16:18:03,699 - org.apache.hadoop.io.compress.CodecPool -15378 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:03,771 - com.infogen.hdfs.InfoGen_LZOOutputStream -15450 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360086-
[framework] 2015-12-15 16:18:03,838 - org.apache.hadoop.io.compress.CodecPool -15517 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:03,902 - com.infogen.hdfs.InfoGen_LZOOutputStream -15581 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360087-
[framework] 2015-12-15 16:18:03,995 - org.apache.hadoop.io.compress.CodecPool -15674 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:04,101 - com.infogen.hdfs.InfoGen_LZOOutputStream -15780 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360088-
[framework] 2015-12-15 16:18:04,171 - org.apache.hadoop.io.compress.CodecPool -15850 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:04,230 - com.infogen.hdfs.InfoGen_LZOOutputStream -15909 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360089-
[framework] 2015-12-15 16:18:04,298 - org.apache.hadoop.io.compress.CodecPool -15977 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:04,351 - com.infogen.hdfs.InfoGen_LZOOutputStream -16030 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360090-
[framework] 2015-12-15 16:18:04,508 - org.apache.hadoop.io.compress.CodecPool -16187 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:04,575 - com.infogen.hdfs.InfoGen_LZOOutputStream -16254 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360091-
[framework] 2015-12-15 16:18:04,641 - org.apache.hadoop.io.compress.CodecPool -16320 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:04,705 - com.infogen.hdfs.InfoGen_LZOOutputStream -16384 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360092-
[framework] 2015-12-15 16:18:04,881 - org.apache.hadoop.io.compress.CodecPool -16560 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:04,939 - com.infogen.hdfs.InfoGen_LZOOutputStream -16618 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360093-
[framework] 2015-12-15 16:18:05,008 - org.apache.hadoop.io.compress.CodecPool -16687 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:05,090 - com.infogen.hdfs.InfoGen_LZOOutputStream -16769 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360094-
[framework] 2015-12-15 16:18:05,187 - org.apache.hadoop.io.compress.CodecPool -16866 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:05,249 - com.infogen.hdfs.InfoGen_LZOOutputStream -16928 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360095-
[framework] 2015-12-15 16:18:05,335 - org.apache.hadoop.io.compress.CodecPool -17014 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:05,399 - com.infogen.hdfs.InfoGen_LZOOutputStream -17078 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360096-
[framework] 2015-12-15 16:18:05,488 - org.apache.hadoop.io.compress.CodecPool -17167 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:05,548 - com.infogen.hdfs.InfoGen_LZOOutputStream -17227 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360097-
[framework] 2015-12-15 16:18:05,619 - org.apache.hadoop.io.compress.CodecPool -17298 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:05,673 - com.infogen.hdfs.InfoGen_LZOOutputStream -17352 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360098-
[framework] 2015-12-15 16:18:05,748 - org.apache.hadoop.io.compress.CodecPool -17427 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:05,826 - com.infogen.hdfs.InfoGen_LZOOutputStream -17505 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360099-
[framework] 2015-12-15 16:18:05,904 - org.apache.hadoop.io.compress.CodecPool -17583 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:05,965 - com.infogen.hdfs.InfoGen_LZOOutputStream -17644 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360100-
[framework] 2015-12-15 16:18:06,028 - org.apache.hadoop.io.compress.CodecPool -17707 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:06,091 - com.infogen.hdfs.InfoGen_LZOOutputStream -17770 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360101-
[framework] 2015-12-15 16:18:06,286 - org.apache.hadoop.io.compress.CodecPool -17965 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:06,345 - com.infogen.hdfs.InfoGen_LZOOutputStream -18024 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360102-
[framework] 2015-12-15 16:18:06,412 - org.apache.hadoop.io.compress.CodecPool -18091 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:06,465 - com.infogen.hdfs.InfoGen_LZOOutputStream -18144 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360103-
[framework] 2015-12-15 16:18:06,575 - org.apache.hadoop.io.compress.CodecPool -18254 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:06,636 - com.infogen.hdfs.InfoGen_LZOOutputStream -18315 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360104-
[framework] 2015-12-15 16:18:06,723 - org.apache.hadoop.io.compress.CodecPool -18402 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:06,779 - com.infogen.hdfs.InfoGen_LZOOutputStream -18458 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360105-
[framework] 2015-12-15 16:18:06,856 - org.apache.hadoop.io.compress.CodecPool -18535 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:06,935 - com.infogen.hdfs.InfoGen_LZOOutputStream -18614 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360106-
[framework] 2015-12-15 16:18:07,101 - org.apache.hadoop.io.compress.CodecPool -18780 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:07,214 - com.infogen.hdfs.InfoGen_LZOOutputStream -18893 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360107-
[framework] 2015-12-15 16:18:07,436 - org.apache.hadoop.io.compress.CodecPool -19115 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:07,518 - com.infogen.hdfs.InfoGen_LZOOutputStream -19197 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360108-
[framework] 2015-12-15 16:18:07,711 - org.apache.hadoop.io.compress.CodecPool -19390 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:07,777 - com.infogen.hdfs.InfoGen_LZOOutputStream -19456 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360109-
[framework] 2015-12-15 16:18:07,947 - org.apache.hadoop.io.compress.CodecPool -19626 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:08,007 - com.infogen.hdfs.InfoGen_LZOOutputStream -19686 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360110-
[framework] 2015-12-15 16:18:08,072 - org.apache.hadoop.io.compress.CodecPool -19751 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:08,141 - com.infogen.hdfs.InfoGen_LZOOutputStream -19820 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360111-
[framework] 2015-12-15 16:18:08,217 - org.apache.hadoop.io.compress.CodecPool -19896 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:08,301 - com.infogen.hdfs.InfoGen_LZOOutputStream -19980 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360112-
[framework] 2015-12-15 16:18:08,494 - org.apache.hadoop.io.compress.CodecPool -20173 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:08,554 - com.infogen.hdfs.InfoGen_LZOOutputStream -20233 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360113-
[framework] 2015-12-15 16:18:08,714 - org.apache.hadoop.io.compress.CodecPool -20393 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:08,790 - com.infogen.hdfs.InfoGen_LZOOutputStream -20469 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360114-
[framework] 2015-12-15 16:18:09,097 - org.apache.hadoop.io.compress.CodecPool -20776 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:09,193 - com.infogen.hdfs.InfoGen_LZOOutputStream -20872 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360115-
[framework] 2015-12-15 16:18:09,379 - org.apache.hadoop.io.compress.CodecPool -21058 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:09,444 - com.infogen.hdfs.InfoGen_LZOOutputStream -21123 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360116-
[framework] 2015-12-15 16:18:09,514 - org.apache.hadoop.io.compress.CodecPool -21193 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:09,569 - com.infogen.hdfs.InfoGen_LZOOutputStream -21248 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360117-
[framework] 2015-12-15 16:18:09,758 - org.apache.hadoop.io.compress.CodecPool -21437 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:09,817 - com.infogen.hdfs.InfoGen_LZOOutputStream -21496 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360118-
[framework] 2015-12-15 16:18:09,888 - org.apache.hadoop.io.compress.CodecPool -21567 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:09,950 - com.infogen.hdfs.InfoGen_LZOOutputStream -21629 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360119-
[framework] 2015-12-15 16:18:10,022 - org.apache.hadoop.io.compress.CodecPool -21701 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:10,084 - com.infogen.hdfs.InfoGen_LZOOutputStream -21763 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360120-
[framework] 2015-12-15 16:18:10,155 - org.apache.hadoop.io.compress.CodecPool -21834 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:10,212 - com.infogen.hdfs.InfoGen_LZOOutputStream -21891 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360121-
[framework] 2015-12-15 16:18:10,427 - org.apache.hadoop.io.compress.CodecPool -22106 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:10,485 - com.infogen.hdfs.InfoGen_LZOOutputStream -22164 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360122-
[framework] 2015-12-15 16:18:10,663 - org.apache.hadoop.io.compress.CodecPool -22342 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:10,717 - com.infogen.hdfs.InfoGen_LZOOutputStream -22396 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360123-
[framework] 2015-12-15 16:18:10,893 - org.apache.hadoop.io.compress.CodecPool -22572 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:10,950 - com.infogen.hdfs.InfoGen_LZOOutputStream -22629 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360124-
[framework] 2015-12-15 16:18:11,022 - org.apache.hadoop.io.compress.CodecPool -22701 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:11,080 - com.infogen.hdfs.InfoGen_LZOOutputStream -22759 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360125-
[framework] 2015-12-15 16:18:11,339 - org.apache.hadoop.io.compress.CodecPool -23018 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:11,410 - com.infogen.hdfs.InfoGen_LZOOutputStream -23089 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360126-
[framework] 2015-12-15 16:18:11,597 - org.apache.hadoop.io.compress.CodecPool -23276 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:11,658 - com.infogen.hdfs.InfoGen_LZOOutputStream -23337 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360127-
[framework] 2015-12-15 16:18:11,722 - org.apache.hadoop.io.compress.CodecPool -23401 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:11,784 - com.infogen.hdfs.InfoGen_LZOOutputStream -23463 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360128-
[framework] 2015-12-15 16:18:12,004 - org.apache.hadoop.io.compress.CodecPool -23683 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:12,062 - com.infogen.hdfs.InfoGen_LZOOutputStream -23741 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-7/2.4360129-
[framework] 2015-12-15 16:18:12,205 - org.apache.hadoop.io.compress.CodecPool -23884 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:12,278 - com.infogen.hdfs.InfoGen_LZOOutputStream -23957 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-8/2.4360130-
[framework] 2015-12-15 16:18:12,533 - org.apache.hadoop.io.compress.CodecPool -24212 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:12,589 - com.infogen.hdfs.InfoGen_LZOOutputStream -24268 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-8/2.4360131-
[framework] 2015-12-15 16:18:12,663 - org.apache.hadoop.io.compress.CodecPool -24342 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:12,718 - com.infogen.hdfs.InfoGen_LZOOutputStream -24397 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-10/2.4360132-
[framework] 2015-12-15 16:18:12,888 - org.apache.hadoop.io.compress.CodecPool -24567 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:12,945 - com.infogen.hdfs.InfoGen_LZOOutputStream -24624 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-8/2.4360133-
[framework] 2015-12-15 16:18:13,034 - org.apache.hadoop.io.compress.CodecPool -24713 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:13,100 - com.infogen.hdfs.InfoGen_LZOOutputStream -24779 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-8/2.4360134-
[framework] 2015-12-15 16:18:13,207 - org.apache.hadoop.io.compress.CodecPool -24886 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:13,417 - com.infogen.hdfs.InfoGen_LZOOutputStream -25096 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-8/2.4360135-
[framework] 2015-12-15 16:18:13,594 - org.apache.hadoop.io.compress.CodecPool -25273 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:13,649 - com.infogen.hdfs.InfoGen_LZOOutputStream -25328 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-8/2.4360136-
[framework] 2015-12-15 16:18:13,740 - org.apache.hadoop.io.compress.CodecPool -25419 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:13,795 - com.infogen.hdfs.InfoGen_LZOOutputStream -25474 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-8/2.4360137-
[framework] 2015-12-15 16:18:13,910 - org.apache.hadoop.io.compress.CodecPool -25589 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:13,977 - com.infogen.hdfs.InfoGen_LZOOutputStream -25656 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-8/2.4360138-
[framework] 2015-12-15 16:18:14,046 - org.apache.hadoop.io.compress.CodecPool -25725 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:14,107 - com.infogen.hdfs.InfoGen_LZOOutputStream -25786 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-8/2.4360139-
[framework] 2015-12-15 16:18:14,295 - org.apache.hadoop.io.compress.CodecPool -25974 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:14,367 - com.infogen.hdfs.InfoGen_LZOOutputStream -26046 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-8/2.4360140-
[framework] 2015-12-15 16:18:14,572 - org.apache.hadoop.io.compress.CodecPool -26251 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:14,636 - com.infogen.hdfs.InfoGen_LZOOutputStream -26315 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-8/2.4360141-
[framework] 2015-12-15 16:18:14,723 - org.apache.hadoop.io.compress.CodecPool -26402 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:14,789 - com.infogen.hdfs.InfoGen_LZOOutputStream -26468 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-8/2.4360142-
[framework] 2015-12-15 16:18:14,996 - org.apache.hadoop.io.compress.CodecPool -26675 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:15,053 - com.infogen.hdfs.InfoGen_LZOOutputStream -26732 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-8/2.4360143-
[framework] 2015-12-15 16:18:15,226 - org.apache.hadoop.io.compress.CodecPool -26905 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:15,284 - com.infogen.hdfs.InfoGen_LZOOutputStream -26963 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-8/2.4360144-
[framework] 2015-12-15 16:18:15,476 - org.apache.hadoop.io.compress.CodecPool -27155 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:15,554 - com.infogen.hdfs.InfoGen_LZOOutputStream -27233 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-8/2.4360145-
[framework] 2015-12-15 16:18:15,971 - org.apache.hadoop.io.compress.CodecPool -27650 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:16,043 - com.infogen.hdfs.InfoGen_LZOOutputStream -27722 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-8/2.4360146-
[framework] 2015-12-15 16:18:16,242 - org.apache.hadoop.io.compress.CodecPool -27921 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:16,310 - com.infogen.hdfs.InfoGen_LZOOutputStream -27989 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-8/2.4360147-
[framework] 2015-12-15 16:18:16,385 - org.apache.hadoop.io.compress.CodecPool -28064 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:16,440 - com.infogen.hdfs.InfoGen_LZOOutputStream -28119 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-8/2.4360148-
[framework] 2015-12-15 16:18:16,612 - org.apache.hadoop.io.compress.CodecPool -28291 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:16,668 - com.infogen.hdfs.InfoGen_LZOOutputStream -28347 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-8/2.4360149-
[framework] 2015-12-15 16:18:16,767 - org.apache.hadoop.io.compress.CodecPool -28446 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:16,828 - com.infogen.hdfs.InfoGen_LZOOutputStream -28507 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-8/2.4360150-
[framework] 2015-12-15 16:18:16,900 - org.apache.hadoop.io.compress.CodecPool -28579 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:16,951 - com.infogen.hdfs.InfoGen_LZOOutputStream -28630 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-8/2.4360151-
[framework] 2015-12-15 16:18:17,017 - org.apache.hadoop.io.compress.CodecPool -28696 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:17,525 - com.infogen.hdfs.InfoGen_LZOOutputStream -29204 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-8/2.4360152-
[framework] 2015-12-15 16:18:17,735 - org.apache.hadoop.io.compress.CodecPool -29414 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:17,817 - com.infogen.hdfs.InfoGen_LZOOutputStream -29496 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-12/2.4360153-
[framework] 2015-12-15 16:18:17,984 - org.apache.hadoop.io.compress.CodecPool -29663 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:18,035 - com.infogen.hdfs.InfoGen_LZOOutputStream -29714 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-12/2.4360154-
[framework] 2015-12-15 16:18:18,206 - org.apache.hadoop.io.compress.CodecPool -29885 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:18,287 - com.infogen.hdfs.InfoGen_LZOOutputStream -29966 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-12/2.4360155-
[framework] 2015-12-15 16:18:18,384 - org.apache.hadoop.io.compress.CodecPool -30063 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:18,687 - com.infogen.hdfs.InfoGen_LZOOutputStream -30366 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-12/2.4360156-
[framework] 2015-12-15 16:18:18,794 - org.apache.hadoop.io.compress.CodecPool -30473 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:18,897 - com.infogen.hdfs.InfoGen_LZOOutputStream -30576 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-12/2.4360157-
[framework] 2015-12-15 16:18:19,028 - org.apache.hadoop.io.compress.CodecPool -30707 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:19,086 - com.infogen.hdfs.InfoGen_LZOOutputStream -30765 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-12/2.4360158-
[framework] 2015-12-15 16:18:19,251 - org.apache.hadoop.io.compress.CodecPool -30930 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:19,331 - com.infogen.hdfs.InfoGen_LZOOutputStream -31010 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-12/2.4360159-
[framework] 2015-12-15 16:18:19,518 - org.apache.hadoop.io.compress.CodecPool -31197 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:19,578 - com.infogen.hdfs.InfoGen_LZOOutputStream -31257 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-10/2.4360160-
[framework] 2015-12-15 16:18:19,693 - org.apache.hadoop.io.compress.CodecPool -31372 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:20,016 - com.infogen.hdfs.InfoGen_LZOOutputStream -31695 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-13/2.4360161-
[framework] 2015-12-15 16:18:20,130 - org.apache.hadoop.io.compress.CodecPool -31809 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:20,194 - com.infogen.hdfs.InfoGen_LZOOutputStream -31873 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-17/2.4360162-
[framework] 2015-12-15 16:18:20,350 - org.apache.hadoop.io.compress.CodecPool -32029 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:20,407 - com.infogen.hdfs.InfoGen_LZOOutputStream -32086 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-17/2.4360163-
[framework] 2015-12-15 16:18:20,575 - org.apache.hadoop.io.compress.CodecPool -32254 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:20,665 - com.infogen.hdfs.InfoGen_LZOOutputStream -32344 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-17/2.4360164-
[framework] 2015-12-15 16:18:20,770 - org.apache.hadoop.io.compress.CodecPool -32449 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:20,898 - com.infogen.hdfs.InfoGen_LZOOutputStream -32577 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-17/2.4360165-
[framework] 2015-12-15 16:18:21,016 - org.apache.hadoop.io.compress.CodecPool -32695 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:21,301 - com.infogen.hdfs.InfoGen_LZOOutputStream -32980 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-18/2.4360166-
[framework] 2015-12-15 16:18:21,417 - org.apache.hadoop.io.compress.CodecPool -33096 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:21,505 - com.infogen.hdfs.InfoGen_LZOOutputStream -33184 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-18/2.4360167-
[framework] 2015-12-15 16:18:21,687 - org.apache.hadoop.io.compress.CodecPool -33366 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:21,744 - com.infogen.hdfs.InfoGen_LZOOutputStream -33423 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-16/2.4360168-
[framework] 2015-12-15 16:18:21,874 - org.apache.hadoop.io.compress.CodecPool -33553 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:21,984 - com.infogen.hdfs.InfoGen_LZOOutputStream -33663 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-18/2.4360169-
[framework] 2015-12-15 16:18:22,076 - org.apache.hadoop.io.compress.CodecPool -33755 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:22,140 - com.infogen.hdfs.InfoGen_LZOOutputStream -33819 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-18/2.4360170-
[framework] 2015-12-15 16:18:22,232 - org.apache.hadoop.io.compress.CodecPool -33911 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:22,284 - com.infogen.hdfs.InfoGen_LZOOutputStream -33963 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-18/2.4360171-
[framework] 2015-12-15 16:18:22,391 - org.apache.hadoop.io.compress.CodecPool -34070 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:22,452 - com.infogen.hdfs.InfoGen_LZOOutputStream -34131 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-18/2.4360172-
[framework] 2015-12-15 16:18:22,579 - org.apache.hadoop.io.compress.CodecPool -34258 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:22,655 - com.infogen.hdfs.InfoGen_LZOOutputStream -34334 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-18/2.4360173-
[framework] 2015-12-15 16:18:22,758 - org.apache.hadoop.io.compress.CodecPool -34437 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:22,814 - com.infogen.hdfs.InfoGen_LZOOutputStream -34493 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-18/2.4360174-
[framework] 2015-12-15 16:18:22,924 - org.apache.hadoop.io.compress.CodecPool -34603 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:22,980 - com.infogen.hdfs.InfoGen_LZOOutputStream -34659 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-18/2.4360175-
[framework] 2015-12-15 16:18:23,069 - org.apache.hadoop.io.compress.CodecPool -34748 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:23,129 - com.infogen.hdfs.InfoGen_LZOOutputStream -34808 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-18/2.4360176-
[framework] 2015-12-15 16:18:23,241 - org.apache.hadoop.io.compress.CodecPool -34920 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:23,298 - com.infogen.hdfs.InfoGen_LZOOutputStream -34977 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-18/2.4360177-
[framework] 2015-12-15 16:18:23,391 - org.apache.hadoop.io.compress.CodecPool -35070 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:23,446 - com.infogen.hdfs.InfoGen_LZOOutputStream -35125 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-18/2.4360178-
[framework] 2015-12-15 16:18:23,650 - org.apache.hadoop.io.compress.CodecPool -35329 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:23,722 - com.infogen.hdfs.InfoGen_LZOOutputStream -35401 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-18/2.4360179-
[framework] 2015-12-15 16:18:51,519 - com.infogen.zookeeper.InfoGen_ZooKeeper -0    [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-15 16:18:51,565 - org.apache.zookeeper.ZooKeeper -46   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[framework] 2015-12-15 16:18:51,565 - org.apache.zookeeper.ZooKeeper -46   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:host.name=localhost
[framework] 2015-12-15 16:18:51,566 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_20
[framework] 2015-12-15 16:18:51,566 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
[framework] 2015-12-15 16:18:51,566 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/lib/jvm/java-8-sun/jre
[framework] 2015-12-15 16:18:51,566 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/home/juxinli/workspace/infogen_etl/target/classes:/home/juxinli/workspace/infogen_etl/lib/hadoop-lzo-0.4.20-SNAPSHOT.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-client/2.7.1/hadoop-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-common/2.7.1/hadoop-common-2.7.1.jar:/home/juxinli/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/juxinli/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/juxinli/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/juxinli/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/juxinli/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/juxinli/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/juxinli/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/juxinli/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/juxinli/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/juxinli/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/juxinli/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/juxinli/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/juxinli/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/juxinli/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/juxinli/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/juxinli/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/juxinli/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.1/hadoop-auth-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/home/juxinli/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/juxinli/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/juxinli/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.1/hadoop-hdfs-2.7.1.jar:/home/juxinli/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/juxinli/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/juxinli/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/juxinli/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/juxinli/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.1/hadoop-mapreduce-client-app-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.1/hadoop-mapreduce-client-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.1/hadoop-yarn-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.1/hadoop-yarn-server-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.1/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.1/hadoop-yarn-api-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.1/hadoop-mapreduce-client-core-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.1/hadoop-yarn-common-2.7.1.jar:/home/juxinli/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/juxinli/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/juxinli/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/juxinli/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.1/hadoop-mapreduce-client-jobclient-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.1/hadoop-annotations-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka_2.11/0.8.2.2/kafka_2.11-0.8.2.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/juxinli/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar:/home/juxinli/.m2/repository/org/scala-lang/scala-library/2.11.5/scala-library-2.11.5.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.2/kafka-clients-0.8.2.2.jar:/home/juxinli/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/juxinli/.m2/repository/net/jpountz/lz4/lz4/1.2.0/lz4-1.2.0.jar:/home/juxinli/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/juxinli/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/juxinli/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/juxinli/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar
[framework] 2015-12-15 16:18:51,567 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[framework] 2015-12-15 16:18:51,567 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp
[framework] 2015-12-15 16:18:51,567 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
[framework] 2015-12-15 16:18:51,567 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
[framework] 2015-12-15 16:18:51,568 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
[framework] 2015-12-15 16:18:51,568 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.2.0-19-generic
[framework] 2015-12-15 16:18:51,568 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.name=juxinli
[framework] 2015-12-15 16:18:51,568 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/juxinli
[framework] 2015-12-15 16:18:51,568 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/home/juxinli/workspace/infogen_etl
[framework] 2015-12-15 16:18:51,570 - org.apache.zookeeper.ZooKeeper -51   [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@5c5a1b69
[framework] 2015-12-15 16:18:51,604 - com.infogen.zookeeper.InfoGen_ZooKeeper -85   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-15 16:18:51,606 - com.infogen.zookeeper.InfoGen_ZooKeeper -87   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers
[framework] 2015-12-15 16:18:51,615 - org.apache.zookeeper.ClientCnxn -96   [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.97/172.16.8.97:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-15 16:18:51,720 - org.apache.zookeeper.ClientCnxn -201  [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.97/172.16.8.97:2181, initiating session
[framework] 2015-12-15 16:18:51,745 - org.apache.zookeeper.ClientCnxn -226  [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.97/172.16.8.97:2181, sessionid = 0x614f1aad4d9c80bb, negotiated timeout = 10000
[framework] 2015-12-15 16:18:51,748 - com.infogen.zookeeper.InfoGen_ZooKeeper -229  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-15 16:18:51,763 - com.infogen.zookeeper.InfoGen_ZooKeeper -244  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers
[framework] 2015-12-15 16:18:51,764 - com.infogen.zookeeper.InfoGen_ZooKeeper -245  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-15 16:18:51,778 - com.infogen.zookeeper.InfoGen_ZooKeeper -259  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-15 16:18:51,778 - com.infogen.zookeeper.InfoGen_ZooKeeper -259  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset
[framework] 2015-12-15 16:18:51,792 - com.infogen.zookeeper.InfoGen_ZooKeeper -273  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset
[framework] 2015-12-15 16:18:51,793 - com.infogen.zookeeper.InfoGen_ZooKeeper -274  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-15 16:18:51,806 - com.infogen.zookeeper.InfoGen_ZooKeeper -287  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-15 16:18:51,806 - com.infogen.zookeeper.InfoGen_ZooKeeper -287  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-15 16:18:51,825 - com.infogen.zookeeper.InfoGen_ZooKeeper -306  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-15 16:18:51,825 - com.infogen.zookeeper.InfoGen_ZooKeeper -306  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 删除节点:/infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-15 16:18:51,859 - com.infogen.zookeeper.InfoGen_ZooKeeper -340  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 删除节点成功:/infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-15 16:18:51,859 - com.infogen.zookeeper.InfoGen_ZooKeeper -340  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 删除节点:/infogen_consumers/infogen_topic_tracking/partition/1
[framework] 2015-12-15 16:18:51,881 - com.infogen.zookeeper.InfoGen_ZooKeeper -362  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 删除节点成功:/infogen_consumers/infogen_topic_tracking/partition/1
[framework] 2015-12-15 16:18:51,881 - com.infogen.zookeeper.InfoGen_ZooKeeper -362  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 删除节点:/infogen_consumers/infogen_topic_tracking/partition/2
[framework] 2015-12-15 16:18:51,896 - com.infogen.zookeeper.InfoGen_ZooKeeper -377  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 删除节点成功:/infogen_consumers/infogen_topic_tracking/partition/2
[framework] 2015-12-15 16:18:51,896 - com.infogen.zookeeper.InfoGen_ZooKeeper -377  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-15 16:18:51,911 - com.infogen.zookeeper.InfoGen_ZooKeeper -392  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-15 16:18:51,914 - com.infogen.zookeeper.InfoGen_ZooKeeper -395  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-15 16:18:51,934 - com.infogen.zookeeper.InfoGen_ZooKeeper -415  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-15 16:18:51,937 - com.infogen.etl.InfoGen_Container -418  [main] INFO  com.infogen.etl.InfoGen_Container  - #创建partition成功:0
[framework] 2015-12-15 16:18:51,937 - com.infogen.zookeeper.InfoGen_ZooKeeper -418  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/ids
[framework] 2015-12-15 16:18:51,950 - com.infogen.zookeeper.InfoGen_ZooKeeper -431  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/ids
[framework] 2015-12-15 16:18:51,950 - com.infogen.zookeeper.InfoGen_ZooKeeper -431  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/1
[framework] 2015-12-15 16:18:51,965 - com.infogen.zookeeper.InfoGen_ZooKeeper -446  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/1
[framework] 2015-12-15 16:18:51,966 - com.infogen.zookeeper.InfoGen_ZooKeeper -447  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/2
[framework] 2015-12-15 16:18:51,985 - com.infogen.zookeeper.InfoGen_ZooKeeper -466  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/2
[framework] 2015-12-15 16:18:51,986 - com.infogen.zookeeper.InfoGen_ZooKeeper -467  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/3
[framework] 2015-12-15 16:18:52,000 - com.infogen.zookeeper.InfoGen_ZooKeeper -481  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/3
[framework] 2015-12-15 16:18:52,000 - com.infogen.zookeeper.InfoGen_ZooKeeper -481  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/offset/0
[framework] 2015-12-15 16:18:52,030 - com.infogen.zookeeper.InfoGen_ZooKeeper -511  [main] ERROR com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据错误: 
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /infogen_consumers/infogen_topic_tracking/offset/0
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1184)
	at com.infogen.zookeeper.InfoGen_ZooKeeper.get_data(InfoGen_ZooKeeper.java:170)
	at com.infogen.etl.InfoGen_Container.main(InfoGen_Container.java:95)
[framework] 2015-12-15 16:18:52,035 - com.infogen.zookeeper.InfoGen_ZooKeeper -516  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/0
[framework] 2015-12-15 16:18:52,051 - com.infogen.zookeeper.InfoGen_ZooKeeper -532  [main] ERROR com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据失败: 
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /infogen_consumers/infogen_topic_tracking/offset/0
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1270)
	at com.infogen.zookeeper.InfoGen_ZooKeeper.set_data(InfoGen_ZooKeeper.java:184)
	at com.infogen.etl.InfoGen_Container.main(InfoGen_Container.java:100)
[framework] 2015-12-15 16:18:52,051 - com.infogen.etl.InfoGen_Container -532  [main] INFO  com.infogen.etl.InfoGen_Container  - #使用默认 offset为:0
[framework] 2015-12-15 16:18:52,886 - com.infogen.kafka.InfoGen_Consumer -1367 [main] WARN  com.infogen.kafka.InfoGen_Consumer  - #offset不存在-从最早的offset开始获取:4464428
[framework] 2015-12-15 16:18:53,392 - org.apache.hadoop.util.NativeCodeLoader -1873 [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-15 16:18:54,516 - com.infogen.hdfs.InfoGen_LZOOutputStream -2997 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/0.4464428-
[framework] 2015-12-15 16:18:54,723 - com.hadoop.compression.lzo.GPLNativeCodeLoader -3204 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-15 16:18:54,726 - com.hadoop.compression.lzo.LzoCodec -3207 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-15 16:18:54,728 - org.apache.hadoop.conf.Configuration.deprecation -3209 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-15 16:18:54,730 - org.apache.hadoop.io.compress.CodecPool -3211 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:54,837 - com.infogen.hdfs.InfoGen_LZOOutputStream -3318 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-6/0.4464429-
[framework] 2015-12-15 16:18:54,940 - org.apache.hadoop.io.compress.CodecPool -3421 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:55,045 - com.infogen.hdfs.InfoGen_LZOOutputStream -3526 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/0.4464430-
[framework] 2015-12-15 16:18:55,264 - org.apache.hadoop.io.compress.CodecPool -3745 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:55,357 - com.infogen.hdfs.InfoGen_LZOOutputStream -3838 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/0.4464431-
[framework] 2015-12-15 16:18:55,474 - org.apache.hadoop.io.compress.CodecPool -3955 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:55,547 - com.infogen.hdfs.InfoGen_LZOOutputStream -4028 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/0.4464432-
[framework] 2015-12-15 16:18:55,767 - org.apache.hadoop.io.compress.CodecPool -4248 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:55,880 - com.infogen.hdfs.InfoGen_LZOOutputStream -4361 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/0.4464433-
[framework] 2015-12-15 16:18:55,962 - org.apache.hadoop.io.compress.CodecPool -4443 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:56,034 - com.infogen.hdfs.InfoGen_LZOOutputStream -4515 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/0.4464434-
[framework] 2015-12-15 16:18:56,200 - org.apache.hadoop.io.compress.CodecPool -4681 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:56,299 - com.infogen.hdfs.InfoGen_LZOOutputStream -4780 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/0.4464435-
[framework] 2015-12-15 16:18:56,473 - org.apache.hadoop.io.compress.CodecPool -4954 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:56,554 - com.infogen.hdfs.InfoGen_LZOOutputStream -5035 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/0.4464436-
[framework] 2015-12-15 16:18:56,712 - org.apache.hadoop.io.compress.CodecPool -5193 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:56,782 - com.infogen.hdfs.InfoGen_LZOOutputStream -5263 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/0.4464437-
[framework] 2015-12-15 16:18:56,870 - org.apache.hadoop.io.compress.CodecPool -5351 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:56,931 - com.infogen.hdfs.InfoGen_LZOOutputStream -5412 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/0.4464438-
[framework] 2015-12-15 16:18:57,096 - org.apache.hadoop.io.compress.CodecPool -5577 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:57,181 - com.infogen.hdfs.InfoGen_LZOOutputStream -5662 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/0.4464439-
[framework] 2015-12-15 16:18:57,339 - org.apache.hadoop.io.compress.CodecPool -5820 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:57,402 - com.infogen.hdfs.InfoGen_LZOOutputStream -5883 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/0.4464440-
[framework] 2015-12-15 16:18:57,476 - org.apache.hadoop.io.compress.CodecPool -5957 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:57,539 - com.infogen.hdfs.InfoGen_LZOOutputStream -6020 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/0.4464441-
[framework] 2015-12-15 16:18:57,611 - org.apache.hadoop.io.compress.CodecPool -6092 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:57,670 - com.infogen.hdfs.InfoGen_LZOOutputStream -6151 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/0.4464442-
[framework] 2015-12-15 16:18:57,737 - org.apache.hadoop.io.compress.CodecPool -6218 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:57,817 - com.infogen.hdfs.InfoGen_LZOOutputStream -6298 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/0.4464443-
[framework] 2015-12-15 16:18:57,886 - org.apache.hadoop.io.compress.CodecPool -6367 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-15 16:18:57,959 - com.infogen.hdfs.InfoGen_LZOOutputStream -6440 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11-3/0.4464444-
[framework] 2015-12-15 16:18:58,028 - org.apache.hadoop.io.compress.CodecPool -6509 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:27:44,279 - com.infogen.zookeeper.InfoGen_ZooKeeper -0    [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-16 12:27:44,355 - org.apache.zookeeper.ZooKeeper -76   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[framework] 2015-12-16 12:27:44,355 - org.apache.zookeeper.ZooKeeper -76   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:host.name=localhost
[framework] 2015-12-16 12:27:44,356 - org.apache.zookeeper.ZooKeeper -77   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_20
[framework] 2015-12-16 12:27:44,356 - org.apache.zookeeper.ZooKeeper -77   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
[framework] 2015-12-16 12:27:44,356 - org.apache.zookeeper.ZooKeeper -77   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/lib/jvm/java-8-sun/jre
[framework] 2015-12-16 12:27:44,356 - org.apache.zookeeper.ZooKeeper -77   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/home/juxinli/workspace/infogen_etl/target/classes:/home/juxinli/workspace/infogen_etl/lib/hadoop-lzo-0.4.20-SNAPSHOT.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-client/2.7.1/hadoop-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-common/2.7.1/hadoop-common-2.7.1.jar:/home/juxinli/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/juxinli/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/juxinli/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/juxinli/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/juxinli/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/juxinli/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/juxinli/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/juxinli/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/juxinli/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/juxinli/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/juxinli/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/juxinli/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/juxinli/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/juxinli/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/juxinli/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/juxinli/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/juxinli/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.1/hadoop-auth-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/home/juxinli/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/juxinli/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/juxinli/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.1/hadoop-hdfs-2.7.1.jar:/home/juxinli/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/juxinli/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/juxinli/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/juxinli/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/juxinli/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.1/hadoop-mapreduce-client-app-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.1/hadoop-mapreduce-client-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.1/hadoop-yarn-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.1/hadoop-yarn-server-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.1/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.1/hadoop-yarn-api-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.1/hadoop-mapreduce-client-core-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.1/hadoop-yarn-common-2.7.1.jar:/home/juxinli/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/juxinli/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/juxinli/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/juxinli/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.1/hadoop-mapreduce-client-jobclient-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.1/hadoop-annotations-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka_2.11/0.8.2.2/kafka_2.11-0.8.2.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/juxinli/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar:/home/juxinli/.m2/repository/org/scala-lang/scala-library/2.11.5/scala-library-2.11.5.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.2/kafka-clients-0.8.2.2.jar:/home/juxinli/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/juxinli/.m2/repository/net/jpountz/lz4/lz4/1.2.0/lz4-1.2.0.jar:/home/juxinli/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/juxinli/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/juxinli/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/juxinli/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar
[framework] 2015-12-16 12:27:44,356 - org.apache.zookeeper.ZooKeeper -77   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[framework] 2015-12-16 12:27:44,357 - org.apache.zookeeper.ZooKeeper -78   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp
[framework] 2015-12-16 12:27:44,357 - org.apache.zookeeper.ZooKeeper -78   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
[framework] 2015-12-16 12:27:44,357 - org.apache.zookeeper.ZooKeeper -78   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
[framework] 2015-12-16 12:27:44,357 - org.apache.zookeeper.ZooKeeper -78   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
[framework] 2015-12-16 12:27:44,357 - org.apache.zookeeper.ZooKeeper -78   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.2.0-19-generic
[framework] 2015-12-16 12:27:44,357 - org.apache.zookeeper.ZooKeeper -78   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.name=juxinli
[framework] 2015-12-16 12:27:44,357 - org.apache.zookeeper.ZooKeeper -78   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/juxinli
[framework] 2015-12-16 12:27:44,358 - org.apache.zookeeper.ZooKeeper -79   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/home/juxinli/workspace/infogen_etl
[framework] 2015-12-16 12:27:44,359 - org.apache.zookeeper.ZooKeeper -80   [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@43814d18
[framework] 2015-12-16 12:27:44,429 - com.infogen.zookeeper.InfoGen_ZooKeeper -150  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-16 12:27:44,432 - com.infogen.zookeeper.InfoGen_ZooKeeper -153  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers
[framework] 2015-12-16 12:27:44,456 - org.apache.zookeeper.ClientCnxn -177  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.99/172.16.8.99:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-16 12:27:44,555 - org.apache.zookeeper.ClientCnxn -276  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.99/172.16.8.99:2181, initiating session
[framework] 2015-12-16 12:27:44,581 - org.apache.zookeeper.ClientCnxn -302  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.99/172.16.8.99:2181, sessionid = 0x634f1aacb9811f8c, negotiated timeout = 10000
[framework] 2015-12-16 12:27:44,589 - com.infogen.zookeeper.InfoGen_ZooKeeper -310  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-16 12:27:44,609 - com.infogen.zookeeper.InfoGen_ZooKeeper -330  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers
[framework] 2015-12-16 12:27:44,609 - com.infogen.zookeeper.InfoGen_ZooKeeper -330  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-16 12:27:44,623 - com.infogen.zookeeper.InfoGen_ZooKeeper -344  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-16 12:27:44,623 - com.infogen.zookeeper.InfoGen_ZooKeeper -344  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset
[framework] 2015-12-16 12:27:44,636 - com.infogen.zookeeper.InfoGen_ZooKeeper -357  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset
[framework] 2015-12-16 12:27:44,637 - com.infogen.zookeeper.InfoGen_ZooKeeper -358  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-16 12:27:44,653 - com.infogen.zookeeper.InfoGen_ZooKeeper -374  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-16 12:27:44,655 - com.infogen.zookeeper.InfoGen_ZooKeeper -376  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-16 12:27:44,670 - com.infogen.zookeeper.InfoGen_ZooKeeper -391  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-16 12:27:44,672 - com.infogen.zookeeper.InfoGen_ZooKeeper -393  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-16 12:27:44,702 - com.infogen.zookeeper.InfoGen_ZooKeeper -423  [main] WARN  com.infogen.zookeeper.InfoGen_ZooKeeper  - 节点已经存在: /infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-16 12:27:44,703 - com.infogen.zookeeper.InfoGen_ZooKeeper -424  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-16 12:27:44,717 - com.infogen.zookeeper.InfoGen_ZooKeeper -438  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/partition/1
[framework] 2015-12-16 12:27:44,732 - com.infogen.zookeeper.InfoGen_ZooKeeper -453  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking/partition/1
[framework] 2015-12-16 12:27:44,733 - com.infogen.etl.InfoGen_Container -454  [main] INFO  com.infogen.etl.InfoGen_Container  - #创建partition成功:1
[framework] 2015-12-16 12:27:44,741 - com.infogen.zookeeper.InfoGen_ZooKeeper -462  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/ids
[framework] 2015-12-16 12:27:44,755 - com.infogen.zookeeper.InfoGen_ZooKeeper -476  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/ids
[framework] 2015-12-16 12:27:44,755 - com.infogen.zookeeper.InfoGen_ZooKeeper -476  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/1
[framework] 2015-12-16 12:27:44,769 - com.infogen.zookeeper.InfoGen_ZooKeeper -490  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/1
[framework] 2015-12-16 12:27:44,769 - com.infogen.zookeeper.InfoGen_ZooKeeper -490  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/2
[framework] 2015-12-16 12:27:44,793 - com.infogen.zookeeper.InfoGen_ZooKeeper -514  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/2
[framework] 2015-12-16 12:27:44,793 - com.infogen.zookeeper.InfoGen_ZooKeeper -514  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/3
[framework] 2015-12-16 12:27:44,812 - com.infogen.zookeeper.InfoGen_ZooKeeper -533  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/3
[framework] 2015-12-16 12:27:44,813 - com.infogen.zookeeper.InfoGen_ZooKeeper -534  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:27:44,837 - com.infogen.zookeeper.InfoGen_ZooKeeper -558  [main] ERROR com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据错误: 
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /infogen_consumers/infogen_topic_tracking/offset/1
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1184)
	at com.infogen.zookeeper.InfoGen_ZooKeeper.get_data(InfoGen_ZooKeeper.java:150)
	at com.infogen.kafka.InfoGen_Consumer.<init>(InfoGen_Consumer.java:68)
	at com.infogen.etl.InfoGen_Container.main(InfoGen_Container.java:77)
[framework] 2015-12-16 12:27:44,847 - com.infogen.zookeeper.InfoGen_ZooKeeper -568  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:27:44,867 - com.infogen.zookeeper.InfoGen_ZooKeeper -588  [main] ERROR com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据失败: 
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /infogen_consumers/infogen_topic_tracking/offset/1
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1270)
	at com.infogen.zookeeper.InfoGen_ZooKeeper.set_data(InfoGen_ZooKeeper.java:164)
	at com.infogen.kafka.InfoGen_Consumer.<init>(InfoGen_Consumer.java:73)
	at com.infogen.etl.InfoGen_Container.main(InfoGen_Container.java:77)
[framework] 2015-12-16 12:27:44,868 - com.infogen.kafka.InfoGen_Consumer -589  [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #使用默认 offset为:0
[framework] 2015-12-16 12:27:46,552 - com.infogen.kafka.InfoGen_Consumer -2273 [main] WARN  com.infogen.kafka.InfoGen_Consumer  - #offset不存在-从最早的offset开始获取:4494174
[framework] 2015-12-16 12:27:48,685 - org.apache.hadoop.util.NativeCodeLoader -4406 [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-16 12:27:50,625 - com.infogen.hdfs.InfoGen_LZOOutputStream -6346 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-47/1.4494174-
[framework] 2015-12-16 12:27:50,903 - com.hadoop.compression.lzo.GPLNativeCodeLoader -6624 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-16 12:27:50,907 - com.hadoop.compression.lzo.LzoCodec -6628 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-16 12:27:50,909 - org.apache.hadoop.conf.Configuration.deprecation -6630 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-16 12:27:50,911 - org.apache.hadoop.io.compress.CodecPool -6632 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:27:51,033 - com.infogen.hdfs.InfoGen_LZOOutputStream -6754 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-47/1.4494175-
[framework] 2015-12-16 12:27:51,110 - org.apache.hadoop.io.compress.CodecPool -6831 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:27:51,196 - com.infogen.hdfs.InfoGen_LZOOutputStream -6917 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-47/1.4494176-
[framework] 2015-12-16 12:27:51,278 - org.apache.hadoop.io.compress.CodecPool -6999 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:27:51,405 - com.infogen.hdfs.InfoGen_LZOOutputStream -7126 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-47/1.4494177-
[framework] 2015-12-16 12:27:51,493 - org.apache.hadoop.io.compress.CodecPool -7214 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:27:51,563 - com.infogen.hdfs.InfoGen_LZOOutputStream -7284 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-47/1.4494178-
[framework] 2015-12-16 12:27:51,727 - org.apache.hadoop.io.compress.CodecPool -7448 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:27:51,806 - com.infogen.hdfs.InfoGen_LZOOutputStream -7527 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-48/1.4494179-
[framework] 2015-12-16 12:27:51,986 - org.apache.hadoop.io.compress.CodecPool -7707 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:27:52,077 - com.infogen.hdfs.InfoGen_LZOOutputStream -7798 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-48/1.4494180-
[framework] 2015-12-16 12:27:52,150 - org.apache.hadoop.io.compress.CodecPool -7871 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:27:52,254 - com.infogen.hdfs.InfoGen_LZOOutputStream -7975 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-48/1.4494181-
[framework] 2015-12-16 12:27:52,357 - org.apache.hadoop.io.compress.CodecPool -8078 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:27:52,476 - com.infogen.hdfs.InfoGen_LZOOutputStream -8197 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-48/1.4494182-
[framework] 2015-12-16 12:27:52,575 - org.apache.hadoop.io.compress.CodecPool -8296 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:32:10,902 - com.infogen.zookeeper.InfoGen_ZooKeeper -0    [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-16 12:32:10,938 - org.apache.zookeeper.ZooKeeper -36   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[framework] 2015-12-16 12:32:10,938 - org.apache.zookeeper.ZooKeeper -36   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:host.name=localhost
[framework] 2015-12-16 12:32:10,938 - org.apache.zookeeper.ZooKeeper -36   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_20
[framework] 2015-12-16 12:32:10,939 - org.apache.zookeeper.ZooKeeper -37   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
[framework] 2015-12-16 12:32:10,939 - org.apache.zookeeper.ZooKeeper -37   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/lib/jvm/java-8-sun/jre
[framework] 2015-12-16 12:32:10,939 - org.apache.zookeeper.ZooKeeper -37   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/home/juxinli/workspace/infogen_etl/target/classes:/home/juxinli/workspace/infogen_etl/lib/hadoop-lzo-0.4.20-SNAPSHOT.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-client/2.7.1/hadoop-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-common/2.7.1/hadoop-common-2.7.1.jar:/home/juxinli/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/juxinli/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/juxinli/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/juxinli/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/juxinli/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/juxinli/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/juxinli/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/juxinli/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/juxinli/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/juxinli/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/juxinli/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/juxinli/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/juxinli/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/juxinli/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/juxinli/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/juxinli/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/juxinli/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.1/hadoop-auth-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/home/juxinli/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/juxinli/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/juxinli/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.1/hadoop-hdfs-2.7.1.jar:/home/juxinli/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/juxinli/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/juxinli/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/juxinli/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/juxinli/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.1/hadoop-mapreduce-client-app-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.1/hadoop-mapreduce-client-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.1/hadoop-yarn-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.1/hadoop-yarn-server-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.1/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.1/hadoop-yarn-api-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.1/hadoop-mapreduce-client-core-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.1/hadoop-yarn-common-2.7.1.jar:/home/juxinli/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/juxinli/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/juxinli/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/juxinli/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.1/hadoop-mapreduce-client-jobclient-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.1/hadoop-annotations-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka_2.11/0.8.2.2/kafka_2.11-0.8.2.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/juxinli/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar:/home/juxinli/.m2/repository/org/scala-lang/scala-library/2.11.5/scala-library-2.11.5.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.2/kafka-clients-0.8.2.2.jar:/home/juxinli/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/juxinli/.m2/repository/net/jpountz/lz4/lz4/1.2.0/lz4-1.2.0.jar:/home/juxinli/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/juxinli/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/juxinli/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/juxinli/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar
[framework] 2015-12-16 12:32:10,940 - org.apache.zookeeper.ZooKeeper -38   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[framework] 2015-12-16 12:32:10,940 - org.apache.zookeeper.ZooKeeper -38   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp
[framework] 2015-12-16 12:32:10,940 - org.apache.zookeeper.ZooKeeper -38   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
[framework] 2015-12-16 12:32:10,940 - org.apache.zookeeper.ZooKeeper -38   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
[framework] 2015-12-16 12:32:10,940 - org.apache.zookeeper.ZooKeeper -38   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
[framework] 2015-12-16 12:32:10,940 - org.apache.zookeeper.ZooKeeper -38   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.2.0-19-generic
[framework] 2015-12-16 12:32:10,941 - org.apache.zookeeper.ZooKeeper -39   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.name=juxinli
[framework] 2015-12-16 12:32:10,941 - org.apache.zookeeper.ZooKeeper -39   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/juxinli
[framework] 2015-12-16 12:32:10,941 - org.apache.zookeeper.ZooKeeper -39   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/home/juxinli/workspace/infogen_etl
[framework] 2015-12-16 12:32:10,942 - org.apache.zookeeper.ZooKeeper -40   [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@43814d18
[framework] 2015-12-16 12:32:10,974 - com.infogen.zookeeper.InfoGen_ZooKeeper -72   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-16 12:32:10,976 - com.infogen.zookeeper.InfoGen_ZooKeeper -74   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers
[framework] 2015-12-16 12:32:10,982 - org.apache.zookeeper.ClientCnxn -80   [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.98/172.16.8.98:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-16 12:32:11,067 - org.apache.zookeeper.ClientCnxn -165  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.98/172.16.8.98:2181, initiating session
[framework] 2015-12-16 12:32:11,088 - org.apache.zookeeper.ClientCnxn -186  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.98/172.16.8.98:2181, sessionid = 0x6250c64e4256072a, negotiated timeout = 10000
[framework] 2015-12-16 12:32:11,091 - com.infogen.zookeeper.InfoGen_ZooKeeper -189  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-16 12:32:11,106 - com.infogen.zookeeper.InfoGen_ZooKeeper -204  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers
[framework] 2015-12-16 12:32:11,106 - com.infogen.zookeeper.InfoGen_ZooKeeper -204  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-16 12:32:11,120 - com.infogen.zookeeper.InfoGen_ZooKeeper -218  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-16 12:32:11,120 - com.infogen.zookeeper.InfoGen_ZooKeeper -218  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset
[framework] 2015-12-16 12:32:11,134 - com.infogen.zookeeper.InfoGen_ZooKeeper -232  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset
[framework] 2015-12-16 12:32:11,135 - com.infogen.zookeeper.InfoGen_ZooKeeper -233  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-16 12:32:11,149 - com.infogen.zookeeper.InfoGen_ZooKeeper -247  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-16 12:32:11,151 - com.infogen.zookeeper.InfoGen_ZooKeeper -249  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-16 12:32:11,169 - com.infogen.zookeeper.InfoGen_ZooKeeper -267  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-16 12:32:11,169 - com.infogen.zookeeper.InfoGen_ZooKeeper -267  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset/0
[framework] 2015-12-16 12:32:11,187 - com.infogen.zookeeper.InfoGen_ZooKeeper -285  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset/0
[framework] 2015-12-16 12:32:11,190 - com.infogen.zookeeper.InfoGen_ZooKeeper -288  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/offset/0
[framework] 2015-12-16 12:32:11,211 - com.infogen.zookeeper.InfoGen_ZooKeeper -309  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking/offset/0
[framework] 2015-12-16 12:32:11,211 - com.infogen.zookeeper.InfoGen_ZooKeeper -309  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-16 12:32:11,239 - com.infogen.zookeeper.InfoGen_ZooKeeper -337  [main] WARN  com.infogen.zookeeper.InfoGen_ZooKeeper  - 节点已经存在: /infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-16 12:32:11,239 - com.infogen.zookeeper.InfoGen_ZooKeeper -337  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-16 12:32:11,257 - com.infogen.zookeeper.InfoGen_ZooKeeper -355  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:32:11,270 - com.infogen.zookeeper.InfoGen_ZooKeeper -368  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:32:11,270 - com.infogen.zookeeper.InfoGen_ZooKeeper -368  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:32:11,287 - com.infogen.zookeeper.InfoGen_ZooKeeper -385  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:32:11,287 - com.infogen.zookeeper.InfoGen_ZooKeeper -385  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/partition/1
[framework] 2015-12-16 12:32:11,303 - com.infogen.zookeeper.InfoGen_ZooKeeper -401  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking/partition/1
[framework] 2015-12-16 12:32:11,304 - com.infogen.etl.InfoGen_Container -402  [main] INFO  com.infogen.etl.InfoGen_Container  - #创建partition成功:1
[framework] 2015-12-16 12:32:11,313 - com.infogen.zookeeper.InfoGen_ZooKeeper -411  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/ids
[framework] 2015-12-16 12:32:11,333 - com.infogen.zookeeper.InfoGen_ZooKeeper -431  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/ids
[framework] 2015-12-16 12:32:11,333 - com.infogen.zookeeper.InfoGen_ZooKeeper -431  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/1
[framework] 2015-12-16 12:32:11,347 - com.infogen.zookeeper.InfoGen_ZooKeeper -445  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/1
[framework] 2015-12-16 12:32:11,348 - com.infogen.zookeeper.InfoGen_ZooKeeper -446  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/2
[framework] 2015-12-16 12:32:11,362 - com.infogen.zookeeper.InfoGen_ZooKeeper -460  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/2
[framework] 2015-12-16 12:32:11,362 - com.infogen.zookeeper.InfoGen_ZooKeeper -460  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/3
[framework] 2015-12-16 12:32:11,379 - com.infogen.zookeeper.InfoGen_ZooKeeper -477  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/3
[framework] 2015-12-16 12:32:11,379 - com.infogen.zookeeper.InfoGen_ZooKeeper -477  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:32:11,393 - com.infogen.zookeeper.InfoGen_ZooKeeper -491  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:32:11,412 - com.infogen.zookeeper.InfoGen_ZooKeeper -510  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:32:11,413 - com.infogen.kafka.InfoGen_Consumer -511  [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #使用默认 offset为:0
[framework] 2015-12-16 12:32:12,110 - com.infogen.kafka.InfoGen_Consumer -1208 [main] WARN  com.infogen.kafka.InfoGen_Consumer  - #offset不存在-从最早的offset开始获取:4494174
[framework] 2015-12-16 12:32:13,724 - org.apache.hadoop.util.NativeCodeLoader -2822 [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-16 12:32:14,780 - com.infogen.hdfs.InfoGen_LZOOutputStream -3878 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-47/1.4494174-
[framework] 2015-12-16 12:32:15,215 - com.hadoop.compression.lzo.GPLNativeCodeLoader -4313 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-16 12:32:15,219 - com.hadoop.compression.lzo.LzoCodec -4317 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-16 12:32:15,221 - org.apache.hadoop.conf.Configuration.deprecation -4319 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-16 12:32:15,224 - org.apache.hadoop.io.compress.CodecPool -4322 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:32:15,389 - com.infogen.hdfs.InfoGen_LZOOutputStream -4487 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-47/1.4494175-
[framework] 2015-12-16 12:32:15,486 - org.apache.hadoop.io.compress.CodecPool -4584 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:32:15,641 - com.infogen.hdfs.InfoGen_LZOOutputStream -4739 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-47/1.4494176-
[framework] 2015-12-16 12:32:15,734 - org.apache.hadoop.io.compress.CodecPool -4832 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:32:15,873 - com.infogen.hdfs.InfoGen_LZOOutputStream -4971 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-47/1.4494177-
[framework] 2015-12-16 12:32:16,198 - org.apache.hadoop.io.compress.CodecPool -5296 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:32:16,458 - com.infogen.hdfs.InfoGen_LZOOutputStream -5556 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-47/1.4494178-
[framework] 2015-12-16 12:32:16,533 - org.apache.hadoop.io.compress.CodecPool -5631 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:32:16,680 - com.infogen.hdfs.InfoGen_LZOOutputStream -5778 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-48/1.4494179-
[framework] 2015-12-16 12:32:16,863 - org.apache.hadoop.io.compress.CodecPool -5961 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:32:16,981 - com.infogen.hdfs.InfoGen_LZOOutputStream -6079 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-48/1.4494180-
[framework] 2015-12-16 12:32:17,066 - org.apache.hadoop.io.compress.CodecPool -6164 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:32:17,172 - com.infogen.hdfs.InfoGen_LZOOutputStream -6270 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-48/1.4494181-
[framework] 2015-12-16 12:32:17,364 - org.apache.hadoop.io.compress.CodecPool -6462 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:42:30,865 - com.infogen.zookeeper.InfoGen_ZooKeeper -1    [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-16 12:42:30,911 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[framework] 2015-12-16 12:42:30,911 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:host.name=localhost
[framework] 2015-12-16 12:42:30,911 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_20
[framework] 2015-12-16 12:42:30,912 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
[framework] 2015-12-16 12:42:30,912 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/lib/jvm/java-8-sun/jre
[framework] 2015-12-16 12:42:30,912 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/home/juxinli/workspace/infogen_etl/target/classes:/home/juxinli/workspace/infogen_etl/lib/hadoop-lzo-0.4.20-SNAPSHOT.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-client/2.7.1/hadoop-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-common/2.7.1/hadoop-common-2.7.1.jar:/home/juxinli/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/juxinli/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/juxinli/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/juxinli/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/juxinli/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/juxinli/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/juxinli/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/juxinli/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/juxinli/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/juxinli/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/juxinli/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/juxinli/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/juxinli/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/juxinli/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/juxinli/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/juxinli/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/juxinli/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.1/hadoop-auth-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/home/juxinli/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/juxinli/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/juxinli/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.1/hadoop-hdfs-2.7.1.jar:/home/juxinli/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/juxinli/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/juxinli/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/juxinli/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/juxinli/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.1/hadoop-mapreduce-client-app-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.1/hadoop-mapreduce-client-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.1/hadoop-yarn-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.1/hadoop-yarn-server-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.1/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.1/hadoop-yarn-api-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.1/hadoop-mapreduce-client-core-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.1/hadoop-yarn-common-2.7.1.jar:/home/juxinli/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/juxinli/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/juxinli/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/juxinli/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.1/hadoop-mapreduce-client-jobclient-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.1/hadoop-annotations-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka_2.11/0.8.2.2/kafka_2.11-0.8.2.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/juxinli/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar:/home/juxinli/.m2/repository/org/scala-lang/scala-library/2.11.5/scala-library-2.11.5.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.2/kafka-clients-0.8.2.2.jar:/home/juxinli/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/juxinli/.m2/repository/net/jpountz/lz4/lz4/1.2.0/lz4-1.2.0.jar:/home/juxinli/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/juxinli/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/juxinli/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/juxinli/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar
[framework] 2015-12-16 12:42:30,913 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[framework] 2015-12-16 12:42:30,913 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp
[framework] 2015-12-16 12:42:30,913 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
[framework] 2015-12-16 12:42:30,913 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
[framework] 2015-12-16 12:42:30,913 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
[framework] 2015-12-16 12:42:30,913 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.2.0-19-generic
[framework] 2015-12-16 12:42:30,913 - org.apache.zookeeper.ZooKeeper -49   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.name=juxinli
[framework] 2015-12-16 12:42:30,914 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/juxinli
[framework] 2015-12-16 12:42:30,914 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/home/juxinli/workspace/infogen_etl
[framework] 2015-12-16 12:42:30,915 - org.apache.zookeeper.ZooKeeper -51   [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@43814d18
[framework] 2015-12-16 12:42:30,953 - com.infogen.zookeeper.InfoGen_ZooKeeper -89   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-16 12:42:30,955 - com.infogen.zookeeper.InfoGen_ZooKeeper -91   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers
[framework] 2015-12-16 12:42:30,965 - org.apache.zookeeper.ClientCnxn -101  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.98/172.16.8.98:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-16 12:42:31,061 - org.apache.zookeeper.ClientCnxn -197  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.98/172.16.8.98:2181, initiating session
[framework] 2015-12-16 12:42:31,089 - org.apache.zookeeper.ClientCnxn -225  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.98/172.16.8.98:2181, sessionid = 0x6250c64e4256072b, negotiated timeout = 10000
[framework] 2015-12-16 12:42:31,093 - com.infogen.zookeeper.InfoGen_ZooKeeper -229  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-16 12:42:31,108 - com.infogen.zookeeper.InfoGen_ZooKeeper -244  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers
[framework] 2015-12-16 12:42:31,108 - com.infogen.zookeeper.InfoGen_ZooKeeper -244  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-16 12:42:31,123 - com.infogen.zookeeper.InfoGen_ZooKeeper -259  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-16 12:42:31,123 - com.infogen.zookeeper.InfoGen_ZooKeeper -259  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset
[framework] 2015-12-16 12:42:31,156 - com.infogen.zookeeper.InfoGen_ZooKeeper -292  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset
[framework] 2015-12-16 12:42:31,157 - com.infogen.zookeeper.InfoGen_ZooKeeper -293  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-16 12:42:31,174 - com.infogen.zookeeper.InfoGen_ZooKeeper -310  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-16 12:42:31,176 - com.infogen.zookeeper.InfoGen_ZooKeeper -312  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-16 12:42:31,195 - com.infogen.zookeeper.InfoGen_ZooKeeper -331  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-16 12:42:31,195 - com.infogen.zookeeper.InfoGen_ZooKeeper -331  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset/0
[framework] 2015-12-16 12:42:31,210 - com.infogen.zookeeper.InfoGen_ZooKeeper -346  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset/0
[framework] 2015-12-16 12:42:31,215 - com.infogen.zookeeper.InfoGen_ZooKeeper -351  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-16 12:42:31,251 - com.infogen.zookeeper.InfoGen_ZooKeeper -387  [main] WARN  com.infogen.zookeeper.InfoGen_ZooKeeper  - 节点已经存在: /infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-16 12:42:31,252 - com.infogen.zookeeper.InfoGen_ZooKeeper -388  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-16 12:42:31,267 - com.infogen.zookeeper.InfoGen_ZooKeeper -403  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:42:31,282 - com.infogen.zookeeper.InfoGen_ZooKeeper -418  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:42:31,283 - com.infogen.zookeeper.InfoGen_ZooKeeper -419  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/partition/1
[framework] 2015-12-16 12:42:31,318 - com.infogen.zookeeper.InfoGen_ZooKeeper -454  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking/partition/1
[framework] 2015-12-16 12:42:31,319 - com.infogen.etl.InfoGen_Container -455  [main] INFO  com.infogen.etl.InfoGen_Container  - #创建partition成功:1
[framework] 2015-12-16 12:42:31,344 - com.infogen.zookeeper.InfoGen_ZooKeeper -480  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/ids
[framework] 2015-12-16 12:42:31,364 - com.infogen.zookeeper.InfoGen_ZooKeeper -500  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/ids
[framework] 2015-12-16 12:42:31,365 - com.infogen.zookeeper.InfoGen_ZooKeeper -501  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/1
[framework] 2015-12-16 12:42:31,383 - com.infogen.zookeeper.InfoGen_ZooKeeper -519  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/1
[framework] 2015-12-16 12:42:31,384 - com.infogen.zookeeper.InfoGen_ZooKeeper -520  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/2
[framework] 2015-12-16 12:42:31,408 - com.infogen.zookeeper.InfoGen_ZooKeeper -544  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/2
[framework] 2015-12-16 12:42:31,409 - com.infogen.zookeeper.InfoGen_ZooKeeper -545  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/3
[framework] 2015-12-16 12:42:31,432 - com.infogen.zookeeper.InfoGen_ZooKeeper -568  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/3
[framework] 2015-12-16 12:42:31,433 - com.infogen.zookeeper.InfoGen_ZooKeeper -569  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:42:31,453 - com.infogen.zookeeper.InfoGen_ZooKeeper -589  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:42:31,453 - com.infogen.kafka.InfoGen_Consumer -589  [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #使用zookeeper 中 offset为:0
[framework] 2015-12-16 12:42:33,209 - com.infogen.kafka.InfoGen_Consumer -2345 [main] WARN  com.infogen.kafka.InfoGen_Consumer  - #offset不存在-从最早的offset开始获取:4494174
[framework] 2015-12-16 12:47:13,466 - com.infogen.zookeeper.InfoGen_ZooKeeper -0    [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-16 12:47:13,505 - org.apache.zookeeper.ZooKeeper -39   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[framework] 2015-12-16 12:47:13,505 - org.apache.zookeeper.ZooKeeper -39   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:host.name=localhost
[framework] 2015-12-16 12:47:13,505 - org.apache.zookeeper.ZooKeeper -39   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_20
[framework] 2015-12-16 12:47:13,505 - org.apache.zookeeper.ZooKeeper -39   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
[framework] 2015-12-16 12:47:13,506 - org.apache.zookeeper.ZooKeeper -40   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/lib/jvm/java-8-sun/jre
[framework] 2015-12-16 12:47:13,506 - org.apache.zookeeper.ZooKeeper -40   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/home/juxinli/workspace/infogen_etl/target/classes:/home/juxinli/workspace/infogen_etl/lib/hadoop-lzo-0.4.20-SNAPSHOT.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-client/2.7.1/hadoop-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-common/2.7.1/hadoop-common-2.7.1.jar:/home/juxinli/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/juxinli/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/juxinli/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/juxinli/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/juxinli/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/juxinli/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/juxinli/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/juxinli/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/juxinli/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/juxinli/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/juxinli/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/juxinli/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/juxinli/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/juxinli/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/juxinli/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/juxinli/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/juxinli/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.1/hadoop-auth-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/home/juxinli/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/juxinli/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/juxinli/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.1/hadoop-hdfs-2.7.1.jar:/home/juxinli/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/juxinli/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/juxinli/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/juxinli/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/juxinli/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.1/hadoop-mapreduce-client-app-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.1/hadoop-mapreduce-client-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.1/hadoop-yarn-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.1/hadoop-yarn-server-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.1/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.1/hadoop-yarn-api-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.1/hadoop-mapreduce-client-core-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.1/hadoop-yarn-common-2.7.1.jar:/home/juxinli/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/juxinli/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/juxinli/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/juxinli/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.1/hadoop-mapreduce-client-jobclient-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.1/hadoop-annotations-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka_2.11/0.8.2.2/kafka_2.11-0.8.2.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/juxinli/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar:/home/juxinli/.m2/repository/org/scala-lang/scala-library/2.11.5/scala-library-2.11.5.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.2/kafka-clients-0.8.2.2.jar:/home/juxinli/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/juxinli/.m2/repository/net/jpountz/lz4/lz4/1.2.0/lz4-1.2.0.jar:/home/juxinli/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/juxinli/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/juxinli/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/juxinli/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar
[framework] 2015-12-16 12:47:13,506 - org.apache.zookeeper.ZooKeeper -40   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[framework] 2015-12-16 12:47:13,506 - org.apache.zookeeper.ZooKeeper -40   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp
[framework] 2015-12-16 12:47:13,507 - org.apache.zookeeper.ZooKeeper -41   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
[framework] 2015-12-16 12:47:13,507 - org.apache.zookeeper.ZooKeeper -41   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
[framework] 2015-12-16 12:47:13,507 - org.apache.zookeeper.ZooKeeper -41   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
[framework] 2015-12-16 12:47:13,507 - org.apache.zookeeper.ZooKeeper -41   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.2.0-19-generic
[framework] 2015-12-16 12:47:13,507 - org.apache.zookeeper.ZooKeeper -41   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.name=juxinli
[framework] 2015-12-16 12:47:13,507 - org.apache.zookeeper.ZooKeeper -41   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/juxinli
[framework] 2015-12-16 12:47:13,507 - org.apache.zookeeper.ZooKeeper -41   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/home/juxinli/workspace/infogen_etl
[framework] 2015-12-16 12:47:13,508 - org.apache.zookeeper.ZooKeeper -42   [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@43814d18
[framework] 2015-12-16 12:47:13,531 - com.infogen.zookeeper.InfoGen_ZooKeeper -65   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-16 12:47:13,534 - com.infogen.zookeeper.InfoGen_ZooKeeper -68   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers
[framework] 2015-12-16 12:47:13,537 - org.apache.zookeeper.ClientCnxn -71   [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.99/172.16.8.99:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-16 12:47:13,632 - org.apache.zookeeper.ClientCnxn -166  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.99/172.16.8.99:2181, initiating session
[framework] 2015-12-16 12:47:13,654 - org.apache.zookeeper.ClientCnxn -188  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.99/172.16.8.99:2181, sessionid = 0x634f1aacb9811f8d, negotiated timeout = 10000
[framework] 2015-12-16 12:47:13,656 - com.infogen.zookeeper.InfoGen_ZooKeeper -190  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-16 12:47:13,672 - com.infogen.zookeeper.InfoGen_ZooKeeper -206  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers
[framework] 2015-12-16 12:47:13,672 - com.infogen.zookeeper.InfoGen_ZooKeeper -206  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-16 12:47:13,685 - com.infogen.zookeeper.InfoGen_ZooKeeper -219  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-16 12:47:13,686 - com.infogen.zookeeper.InfoGen_ZooKeeper -220  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset
[framework] 2015-12-16 12:47:13,699 - com.infogen.zookeeper.InfoGen_ZooKeeper -233  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset
[framework] 2015-12-16 12:47:13,699 - com.infogen.zookeeper.InfoGen_ZooKeeper -233  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-16 12:47:13,714 - com.infogen.zookeeper.InfoGen_ZooKeeper -248  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-16 12:47:13,715 - com.infogen.zookeeper.InfoGen_ZooKeeper -249  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-16 12:47:13,732 - com.infogen.zookeeper.InfoGen_ZooKeeper -266  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-16 12:47:13,732 - com.infogen.zookeeper.InfoGen_ZooKeeper -266  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset/0
[framework] 2015-12-16 12:47:13,752 - com.infogen.zookeeper.InfoGen_ZooKeeper -286  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset/0
[framework] 2015-12-16 12:47:13,756 - com.infogen.zookeeper.InfoGen_ZooKeeper -290  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-16 12:47:13,788 - com.infogen.zookeeper.InfoGen_ZooKeeper -322  [main] WARN  com.infogen.zookeeper.InfoGen_ZooKeeper  - 节点已经存在: /infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-16 12:47:13,789 - com.infogen.zookeeper.InfoGen_ZooKeeper -323  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-16 12:47:13,805 - com.infogen.zookeeper.InfoGen_ZooKeeper -339  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:47:13,818 - com.infogen.zookeeper.InfoGen_ZooKeeper -352  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:47:13,819 - com.infogen.zookeeper.InfoGen_ZooKeeper -353  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/partition/1
[framework] 2015-12-16 12:47:13,833 - com.infogen.zookeeper.InfoGen_ZooKeeper -367  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking/partition/1
[framework] 2015-12-16 12:47:13,834 - com.infogen.etl.InfoGen_Container -368  [main] INFO  com.infogen.etl.InfoGen_Container  - #创建partition成功:1
[framework] 2015-12-16 12:47:13,848 - com.infogen.zookeeper.InfoGen_ZooKeeper -382  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/ids
[framework] 2015-12-16 12:47:13,861 - com.infogen.zookeeper.InfoGen_ZooKeeper -395  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/ids
[framework] 2015-12-16 12:47:13,861 - com.infogen.zookeeper.InfoGen_ZooKeeper -395  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/1
[framework] 2015-12-16 12:47:13,875 - com.infogen.zookeeper.InfoGen_ZooKeeper -409  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/1
[framework] 2015-12-16 12:47:13,875 - com.infogen.zookeeper.InfoGen_ZooKeeper -409  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/2
[framework] 2015-12-16 12:47:13,894 - com.infogen.zookeeper.InfoGen_ZooKeeper -428  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/2
[framework] 2015-12-16 12:47:13,894 - com.infogen.zookeeper.InfoGen_ZooKeeper -428  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/3
[framework] 2015-12-16 12:47:13,907 - com.infogen.zookeeper.InfoGen_ZooKeeper -441  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/3
[framework] 2015-12-16 12:47:13,908 - com.infogen.zookeeper.InfoGen_ZooKeeper -442  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:47:13,921 - com.infogen.zookeeper.InfoGen_ZooKeeper -455  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:47:13,921 - com.infogen.kafka.InfoGen_Consumer -455  [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #使用zookeeper 中 offset为:0
[framework] 2015-12-16 12:47:14,788 - com.infogen.kafka.InfoGen_Consumer -1322 [main] WARN  com.infogen.kafka.InfoGen_Consumer  - #offset不存在-从最早的offset开始获取:4494174
[framework] 2015-12-16 12:47:15,365 - org.apache.hadoop.util.NativeCodeLoader -1899 [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-16 12:47:16,545 - com.infogen.hdfs.InfoGen_LZOOutputStream -3079 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-47/1.4494174-
[framework] 2015-12-16 12:47:16,724 - com.hadoop.compression.lzo.GPLNativeCodeLoader -3258 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-16 12:47:16,726 - com.hadoop.compression.lzo.LzoCodec -3260 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-16 12:47:16,729 - org.apache.hadoop.conf.Configuration.deprecation -3263 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-16 12:47:16,732 - org.apache.hadoop.io.compress.CodecPool -3266 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:16,915 - com.infogen.hdfs.InfoGen_LZOOutputStream -3449 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-48/1.4494179-
[framework] 2015-12-16 12:47:17,005 - org.apache.hadoop.io.compress.CodecPool -3539 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:17,151 - com.infogen.hdfs.InfoGen_LZOOutputStream -3685 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-50/1.4494198-
[framework] 2015-12-16 12:47:17,247 - org.apache.hadoop.io.compress.CodecPool -3781 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:17,330 - com.infogen.hdfs.InfoGen_LZOOutputStream -3864 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-49/1.4494205-
[framework] 2015-12-16 12:47:17,407 - org.apache.hadoop.io.compress.CodecPool -3941 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:17,484 - com.infogen.hdfs.InfoGen_LZOOutputStream -4018 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-51/1.4494206-
[framework] 2015-12-16 12:47:17,563 - org.apache.hadoop.io.compress.CodecPool -4097 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:17,646 - com.infogen.hdfs.InfoGen_LZOOutputStream -4180 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-52/1.4494237-
[framework] 2015-12-16 12:47:17,723 - org.apache.hadoop.io.compress.CodecPool -4257 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:17,813 - com.infogen.hdfs.InfoGen_LZOOutputStream -4347 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-53/1.4494253-
[framework] 2015-12-16 12:47:17,906 - org.apache.hadoop.io.compress.CodecPool -4440 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:17,971 - com.infogen.hdfs.InfoGen_LZOOutputStream -4505 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-55/1.4494279-
[framework] 2015-12-16 12:47:18,079 - org.apache.hadoop.io.compress.CodecPool -4613 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:18,153 - com.infogen.hdfs.InfoGen_LZOOutputStream -4687 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-56/1.4494281-
[framework] 2015-12-16 12:47:18,229 - org.apache.hadoop.io.compress.CodecPool -4763 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:18,305 - com.infogen.hdfs.InfoGen_LZOOutputStream -4839 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-57/1.4494290-
[framework] 2015-12-16 12:47:18,389 - org.apache.hadoop.io.compress.CodecPool -4923 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:18,463 - com.infogen.hdfs.InfoGen_LZOOutputStream -4997 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-58/1.4494337-
[framework] 2015-12-16 12:47:18,647 - org.apache.hadoop.io.compress.CodecPool -5181 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:18,721 - com.infogen.hdfs.InfoGen_LZOOutputStream -5255 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/10-1/1.4494404-
[framework] 2015-12-16 12:47:18,807 - org.apache.hadoop.io.compress.CodecPool -5341 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:18,877 - com.infogen.hdfs.InfoGen_LZOOutputStream -5411 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-59/1.4494411-
[framework] 2015-12-16 12:47:19,189 - org.apache.hadoop.io.compress.CodecPool -5723 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:19,274 - com.infogen.hdfs.InfoGen_LZOOutputStream -5808 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/10-3/1.4494417-
[framework] 2015-12-16 12:47:19,354 - org.apache.hadoop.io.compress.CodecPool -5888 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:19,430 - com.infogen.hdfs.InfoGen_LZOOutputStream -5964 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/10-4/1.4494459-
[framework] 2015-12-16 12:47:19,529 - org.apache.hadoop.io.compress.CodecPool -6063 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:19,592 - com.infogen.hdfs.InfoGen_LZOOutputStream -6126 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/10-2/1.4494462-
[framework] 2015-12-16 12:47:19,671 - org.apache.hadoop.io.compress.CodecPool -6205 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:19,742 - com.infogen.hdfs.InfoGen_LZOOutputStream -6276 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/10-5/1.4494494-
[framework] 2015-12-16 12:47:19,931 - org.apache.hadoop.io.compress.CodecPool -6465 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:20,090 - com.infogen.hdfs.InfoGen_LZOOutputStream -6624 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/10-6/1.4494518-
[framework] 2015-12-16 12:47:20,247 - org.apache.hadoop.io.compress.CodecPool -6781 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:20,320 - com.infogen.hdfs.InfoGen_LZOOutputStream -6854 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/10-7/1.4494562-
[framework] 2015-12-16 12:47:20,514 - org.apache.hadoop.io.compress.CodecPool -7048 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:20,592 - com.infogen.hdfs.InfoGen_LZOOutputStream -7126 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/10-8/1.4494642-
[framework] 2015-12-16 12:47:20,673 - org.apache.hadoop.io.compress.CodecPool -7207 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:20,761 - com.infogen.hdfs.InfoGen_LZOOutputStream -7295 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/10-10/1.4494726-
[framework] 2015-12-16 12:47:20,847 - org.apache.hadoop.io.compress.CodecPool -7381 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:20,927 - com.infogen.hdfs.InfoGen_LZOOutputStream -7461 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/10-11/1.4494760-
[framework] 2015-12-16 12:47:20,996 - org.apache.hadoop.io.compress.CodecPool -7530 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:21,062 - com.infogen.hdfs.InfoGen_LZOOutputStream -7596 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/10-9/1.4494763-
[framework] 2015-12-16 12:47:21,148 - org.apache.hadoop.io.compress.CodecPool -7682 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:21,216 - com.infogen.hdfs.InfoGen_LZOOutputStream -7750 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/10-13/1.4494854-
[framework] 2015-12-16 12:47:21,305 - org.apache.hadoop.io.compress.CodecPool -7839 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:21,507 - com.infogen.hdfs.InfoGen_LZOOutputStream -8041 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/10-16/1.4494863-
[framework] 2015-12-16 12:47:21,597 - org.apache.hadoop.io.compress.CodecPool -8131 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:21,660 - com.infogen.hdfs.InfoGen_LZOOutputStream -8194 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/10-14/1.4494867-
[framework] 2015-12-16 12:47:21,746 - org.apache.hadoop.io.compress.CodecPool -8280 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:21,816 - com.infogen.hdfs.InfoGen_LZOOutputStream -8350 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/10-18/1.4494878-
[framework] 2015-12-16 12:47:21,920 - org.apache.hadoop.io.compress.CodecPool -8454 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:47:50,709 - com.infogen.zookeeper.InfoGen_ZooKeeper -0    [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-16 12:47:50,770 - org.apache.zookeeper.ZooKeeper -61   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[framework] 2015-12-16 12:47:50,771 - org.apache.zookeeper.ZooKeeper -62   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:host.name=localhost
[framework] 2015-12-16 12:47:50,771 - org.apache.zookeeper.ZooKeeper -62   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_20
[framework] 2015-12-16 12:47:50,771 - org.apache.zookeeper.ZooKeeper -62   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
[framework] 2015-12-16 12:47:50,771 - org.apache.zookeeper.ZooKeeper -62   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/lib/jvm/java-8-sun/jre
[framework] 2015-12-16 12:47:50,772 - org.apache.zookeeper.ZooKeeper -63   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/home/juxinli/workspace/infogen_etl/target/classes:/home/juxinli/workspace/infogen_etl/lib/hadoop-lzo-0.4.20-SNAPSHOT.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-client/2.7.1/hadoop-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-common/2.7.1/hadoop-common-2.7.1.jar:/home/juxinli/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/juxinli/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/juxinli/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/juxinli/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/juxinli/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/juxinli/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/juxinli/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/juxinli/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/juxinli/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/juxinli/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/juxinli/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/juxinli/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/juxinli/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/juxinli/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/juxinli/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/juxinli/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/juxinli/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.1/hadoop-auth-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/home/juxinli/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/juxinli/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/juxinli/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.1/hadoop-hdfs-2.7.1.jar:/home/juxinli/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/juxinli/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/juxinli/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/juxinli/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/juxinli/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.1/hadoop-mapreduce-client-app-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.1/hadoop-mapreduce-client-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.1/hadoop-yarn-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.1/hadoop-yarn-server-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.1/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.1/hadoop-yarn-api-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.1/hadoop-mapreduce-client-core-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.1/hadoop-yarn-common-2.7.1.jar:/home/juxinli/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/juxinli/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/juxinli/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/juxinli/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.1/hadoop-mapreduce-client-jobclient-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.1/hadoop-annotations-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka_2.11/0.8.2.2/kafka_2.11-0.8.2.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/juxinli/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar:/home/juxinli/.m2/repository/org/scala-lang/scala-library/2.11.5/scala-library-2.11.5.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.2/kafka-clients-0.8.2.2.jar:/home/juxinli/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/juxinli/.m2/repository/net/jpountz/lz4/lz4/1.2.0/lz4-1.2.0.jar:/home/juxinli/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/juxinli/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/juxinli/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/juxinli/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar
[framework] 2015-12-16 12:47:50,773 - org.apache.zookeeper.ZooKeeper -64   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[framework] 2015-12-16 12:47:50,773 - org.apache.zookeeper.ZooKeeper -64   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp
[framework] 2015-12-16 12:47:50,774 - org.apache.zookeeper.ZooKeeper -65   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
[framework] 2015-12-16 12:47:50,774 - org.apache.zookeeper.ZooKeeper -65   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
[framework] 2015-12-16 12:47:50,774 - org.apache.zookeeper.ZooKeeper -65   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
[framework] 2015-12-16 12:47:50,775 - org.apache.zookeeper.ZooKeeper -66   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.2.0-19-generic
[framework] 2015-12-16 12:47:50,776 - org.apache.zookeeper.ZooKeeper -67   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.name=juxinli
[framework] 2015-12-16 12:47:50,776 - org.apache.zookeeper.ZooKeeper -67   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/juxinli
[framework] 2015-12-16 12:47:50,776 - org.apache.zookeeper.ZooKeeper -67   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/home/juxinli/workspace/infogen_etl
[framework] 2015-12-16 12:47:50,778 - org.apache.zookeeper.ZooKeeper -69   [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@43814d18
[framework] 2015-12-16 12:47:50,840 - org.apache.zookeeper.ClientCnxn -131  [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.97/172.16.8.97:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-16 12:47:50,841 - com.infogen.zookeeper.InfoGen_ZooKeeper -132  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-16 12:47:50,843 - com.infogen.zookeeper.InfoGen_ZooKeeper -134  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers
[framework] 2015-12-16 12:47:50,960 - org.apache.zookeeper.ClientCnxn -251  [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.97/172.16.8.97:2181, initiating session
[framework] 2015-12-16 12:47:50,984 - org.apache.zookeeper.ClientCnxn -275  [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.97/172.16.8.97:2181, sessionid = 0x614f1aad4d9c8133, negotiated timeout = 10000
[framework] 2015-12-16 12:47:50,988 - com.infogen.zookeeper.InfoGen_ZooKeeper -279  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-16 12:47:51,021 - com.infogen.zookeeper.InfoGen_ZooKeeper -312  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers
[framework] 2015-12-16 12:47:51,021 - com.infogen.zookeeper.InfoGen_ZooKeeper -312  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-16 12:47:51,034 - com.infogen.zookeeper.InfoGen_ZooKeeper -325  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-16 12:47:51,034 - com.infogen.zookeeper.InfoGen_ZooKeeper -325  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset
[framework] 2015-12-16 12:47:51,050 - com.infogen.zookeeper.InfoGen_ZooKeeper -341  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset
[framework] 2015-12-16 12:47:51,050 - com.infogen.zookeeper.InfoGen_ZooKeeper -341  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-16 12:47:51,064 - com.infogen.zookeeper.InfoGen_ZooKeeper -355  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-16 12:47:51,066 - com.infogen.zookeeper.InfoGen_ZooKeeper -357  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-16 12:47:51,100 - com.infogen.zookeeper.InfoGen_ZooKeeper -391  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-16 12:47:51,100 - com.infogen.zookeeper.InfoGen_ZooKeeper -391  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset/0
[framework] 2015-12-16 12:47:51,114 - com.infogen.zookeeper.InfoGen_ZooKeeper -405  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset/0
[framework] 2015-12-16 12:47:51,120 - com.infogen.zookeeper.InfoGen_ZooKeeper -411  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-16 12:47:51,184 - com.infogen.zookeeper.InfoGen_ZooKeeper -475  [main] WARN  com.infogen.zookeeper.InfoGen_ZooKeeper  - 节点已经存在: /infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-16 12:47:51,184 - com.infogen.zookeeper.InfoGen_ZooKeeper -475  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-16 12:47:51,202 - com.infogen.zookeeper.InfoGen_ZooKeeper -493  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:47:51,216 - com.infogen.zookeeper.InfoGen_ZooKeeper -507  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:47:51,216 - com.infogen.zookeeper.InfoGen_ZooKeeper -507  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/partition/1
[framework] 2015-12-16 12:47:51,232 - com.infogen.zookeeper.InfoGen_ZooKeeper -523  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking/partition/1
[framework] 2015-12-16 12:47:51,233 - com.infogen.etl.InfoGen_Container -524  [main] INFO  com.infogen.etl.InfoGen_Container  - #创建partition成功:1
[framework] 2015-12-16 12:47:51,250 - com.infogen.zookeeper.InfoGen_ZooKeeper -541  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/ids
[framework] 2015-12-16 12:47:51,264 - com.infogen.zookeeper.InfoGen_ZooKeeper -555  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/ids
[framework] 2015-12-16 12:47:51,265 - com.infogen.zookeeper.InfoGen_ZooKeeper -556  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/1
[framework] 2015-12-16 12:47:51,279 - com.infogen.zookeeper.InfoGen_ZooKeeper -570  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/1
[framework] 2015-12-16 12:47:51,280 - com.infogen.zookeeper.InfoGen_ZooKeeper -571  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/2
[framework] 2015-12-16 12:47:51,299 - com.infogen.zookeeper.InfoGen_ZooKeeper -590  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/2
[framework] 2015-12-16 12:47:51,300 - com.infogen.zookeeper.InfoGen_ZooKeeper -591  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/3
[framework] 2015-12-16 12:47:51,313 - com.infogen.zookeeper.InfoGen_ZooKeeper -604  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/3
[framework] 2015-12-16 12:47:51,314 - com.infogen.zookeeper.InfoGen_ZooKeeper -605  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:47:51,328 - com.infogen.zookeeper.InfoGen_ZooKeeper -619  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:47:51,328 - com.infogen.kafka.InfoGen_Consumer -619  [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #使用zookeeper 中 offset为:0
[framework] 2015-12-16 12:47:53,468 - com.infogen.kafka.InfoGen_Consumer -2759 [main] WARN  com.infogen.kafka.InfoGen_Consumer  - #offset不存在-从最早的offset开始获取:4494174
[framework] 2015-12-16 12:48:45,794 - org.apache.hadoop.util.NativeCodeLoader -55085 [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-16 12:48:49,522 - com.infogen.hdfs.InfoGen_LZOOutputStream -58813 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-47/1.4494174-
[framework] 2015-12-16 12:48:50,045 - com.hadoop.compression.lzo.GPLNativeCodeLoader -59336 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-16 12:48:50,052 - com.hadoop.compression.lzo.LzoCodec -59343 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-16 12:48:50,057 - org.apache.hadoop.conf.Configuration.deprecation -59348 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-16 12:48:50,062 - org.apache.hadoop.io.compress.CodecPool -59353 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:49:44,652 - com.infogen.hdfs.InfoGen_LZOOutputStream -113943 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-47/1.4494174-
[framework] 2015-12-16 12:50:07,035 - com.infogen.hdfs.InfoGen_LZOOutputStream -136326 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-47/1.4494176-
[framework] 2015-12-16 12:50:26,200 - com.infogen.hdfs.InfoGen_LZOOutputStream -155491 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-48/1.4494179-
[framework] 2015-12-16 12:50:26,369 - org.apache.hadoop.io.compress.CodecPool -155660 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:51:01,767 - com.infogen.hdfs.InfoGen_LZOOutputStream -191058 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-50/1.4494198-
[framework] 2015-12-16 12:51:01,901 - org.apache.hadoop.io.compress.CodecPool -191192 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:51:06,720 - com.infogen.hdfs.InfoGen_LZOOutputStream -196011 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9-47/1.4494176-
[framework] 2015-12-16 12:51:54,762 - com.infogen.zookeeper.InfoGen_ZooKeeper -0    [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-16 12:51:54,814 - org.apache.zookeeper.ZooKeeper -52   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[framework] 2015-12-16 12:51:54,814 - org.apache.zookeeper.ZooKeeper -52   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:host.name=localhost
[framework] 2015-12-16 12:51:54,815 - org.apache.zookeeper.ZooKeeper -53   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_20
[framework] 2015-12-16 12:51:54,815 - org.apache.zookeeper.ZooKeeper -53   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
[framework] 2015-12-16 12:51:54,818 - org.apache.zookeeper.ZooKeeper -56   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/lib/jvm/java-8-sun/jre
[framework] 2015-12-16 12:51:54,818 - org.apache.zookeeper.ZooKeeper -56   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/home/juxinli/workspace/infogen_etl/target/classes:/home/juxinli/workspace/infogen_etl/lib/hadoop-lzo-0.4.20-SNAPSHOT.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-client/2.7.1/hadoop-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-common/2.7.1/hadoop-common-2.7.1.jar:/home/juxinli/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/juxinli/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/juxinli/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/juxinli/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/juxinli/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/juxinli/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/juxinli/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/juxinli/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/juxinli/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/juxinli/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/juxinli/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/juxinli/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/juxinli/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/juxinli/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/juxinli/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/juxinli/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/juxinli/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.1/hadoop-auth-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/home/juxinli/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/juxinli/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/juxinli/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.1/hadoop-hdfs-2.7.1.jar:/home/juxinli/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/juxinli/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/juxinli/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/juxinli/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/juxinli/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.1/hadoop-mapreduce-client-app-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.1/hadoop-mapreduce-client-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.1/hadoop-yarn-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.1/hadoop-yarn-server-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.1/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.1/hadoop-yarn-api-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.1/hadoop-mapreduce-client-core-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.1/hadoop-yarn-common-2.7.1.jar:/home/juxinli/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/juxinli/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/juxinli/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/juxinli/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.1/hadoop-mapreduce-client-jobclient-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.1/hadoop-annotations-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka_2.11/0.8.2.2/kafka_2.11-0.8.2.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/juxinli/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar:/home/juxinli/.m2/repository/org/scala-lang/scala-library/2.11.5/scala-library-2.11.5.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.2/kafka-clients-0.8.2.2.jar:/home/juxinli/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/juxinli/.m2/repository/net/jpountz/lz4/lz4/1.2.0/lz4-1.2.0.jar:/home/juxinli/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/juxinli/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/juxinli/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/juxinli/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar
[framework] 2015-12-16 12:51:54,819 - org.apache.zookeeper.ZooKeeper -57   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[framework] 2015-12-16 12:51:54,820 - org.apache.zookeeper.ZooKeeper -58   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp
[framework] 2015-12-16 12:51:54,820 - org.apache.zookeeper.ZooKeeper -58   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
[framework] 2015-12-16 12:51:54,820 - org.apache.zookeeper.ZooKeeper -58   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
[framework] 2015-12-16 12:51:54,820 - org.apache.zookeeper.ZooKeeper -58   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
[framework] 2015-12-16 12:51:54,820 - org.apache.zookeeper.ZooKeeper -58   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.2.0-19-generic
[framework] 2015-12-16 12:51:54,821 - org.apache.zookeeper.ZooKeeper -59   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.name=juxinli
[framework] 2015-12-16 12:51:54,821 - org.apache.zookeeper.ZooKeeper -59   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/juxinli
[framework] 2015-12-16 12:51:54,821 - org.apache.zookeeper.ZooKeeper -59   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/home/juxinli/workspace/infogen_etl
[framework] 2015-12-16 12:51:54,822 - org.apache.zookeeper.ZooKeeper -60   [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@43814d18
[framework] 2015-12-16 12:51:54,862 - org.apache.zookeeper.ClientCnxn -100  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.99/172.16.8.99:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-16 12:51:54,863 - com.infogen.zookeeper.InfoGen_ZooKeeper -101  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-16 12:51:54,865 - com.infogen.zookeeper.InfoGen_ZooKeeper -103  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers
[framework] 2015-12-16 12:51:54,998 - org.apache.zookeeper.ClientCnxn -236  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.99/172.16.8.99:2181, initiating session
[framework] 2015-12-16 12:51:55,021 - org.apache.zookeeper.ClientCnxn -259  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.99/172.16.8.99:2181, sessionid = 0x634f1aacb9811f8e, negotiated timeout = 10000
[framework] 2015-12-16 12:51:55,023 - com.infogen.zookeeper.InfoGen_ZooKeeper -261  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-16 12:51:55,038 - com.infogen.zookeeper.InfoGen_ZooKeeper -276  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers
[framework] 2015-12-16 12:51:55,039 - com.infogen.zookeeper.InfoGen_ZooKeeper -277  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-16 12:51:55,054 - com.infogen.zookeeper.InfoGen_ZooKeeper -292  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-16 12:51:55,054 - com.infogen.zookeeper.InfoGen_ZooKeeper -292  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset
[framework] 2015-12-16 12:51:55,068 - com.infogen.zookeeper.InfoGen_ZooKeeper -306  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset
[framework] 2015-12-16 12:51:55,068 - com.infogen.zookeeper.InfoGen_ZooKeeper -306  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-16 12:51:55,083 - com.infogen.zookeeper.InfoGen_ZooKeeper -321  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-16 12:51:55,085 - com.infogen.zookeeper.InfoGen_ZooKeeper -323  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-16 12:51:55,101 - com.infogen.zookeeper.InfoGen_ZooKeeper -339  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-16 12:51:55,101 - com.infogen.zookeeper.InfoGen_ZooKeeper -339  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset/0
[framework] 2015-12-16 12:51:55,115 - com.infogen.zookeeper.InfoGen_ZooKeeper -353  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset/0
[framework] 2015-12-16 12:51:55,119 - com.infogen.zookeeper.InfoGen_ZooKeeper -357  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-16 12:51:55,156 - com.infogen.zookeeper.InfoGen_ZooKeeper -394  [main] WARN  com.infogen.zookeeper.InfoGen_ZooKeeper  - 节点已经存在: /infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-16 12:51:55,156 - com.infogen.zookeeper.InfoGen_ZooKeeper -394  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-16 12:51:55,173 - com.infogen.zookeeper.InfoGen_ZooKeeper -411  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:51:55,187 - com.infogen.zookeeper.InfoGen_ZooKeeper -425  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:51:55,188 - com.infogen.zookeeper.InfoGen_ZooKeeper -426  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/partition/1
[framework] 2015-12-16 12:51:55,202 - com.infogen.zookeeper.InfoGen_ZooKeeper -440  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking/partition/1
[framework] 2015-12-16 12:51:55,203 - com.infogen.etl.InfoGen_Container -441  [main] INFO  com.infogen.etl.InfoGen_Container  - #创建partition成功:1
[framework] 2015-12-16 12:51:55,213 - com.infogen.zookeeper.InfoGen_ZooKeeper -451  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/ids
[framework] 2015-12-16 12:51:55,230 - com.infogen.zookeeper.InfoGen_ZooKeeper -468  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/ids
[framework] 2015-12-16 12:51:55,231 - com.infogen.zookeeper.InfoGen_ZooKeeper -469  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/1
[framework] 2015-12-16 12:51:55,246 - com.infogen.zookeeper.InfoGen_ZooKeeper -484  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/1
[framework] 2015-12-16 12:51:55,247 - com.infogen.zookeeper.InfoGen_ZooKeeper -485  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/2
[framework] 2015-12-16 12:51:55,269 - com.infogen.zookeeper.InfoGen_ZooKeeper -507  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/2
[framework] 2015-12-16 12:51:55,276 - com.infogen.zookeeper.InfoGen_ZooKeeper -514  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/3
[framework] 2015-12-16 12:51:55,297 - com.infogen.zookeeper.InfoGen_ZooKeeper -535  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/3
[framework] 2015-12-16 12:51:55,298 - com.infogen.zookeeper.InfoGen_ZooKeeper -536  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:51:55,314 - com.infogen.zookeeper.InfoGen_ZooKeeper -552  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:51:55,315 - com.infogen.kafka.InfoGen_Consumer -553  [main] INFO  com.infogen.kafka.InfoGen_Consumer  - #使用zookeeper 中 offset为:0
[framework] 2015-12-16 12:51:56,128 - com.infogen.kafka.InfoGen_Consumer -1366 [main] WARN  com.infogen.kafka.InfoGen_Consumer  - #offset不存在-从最早的offset开始获取:4494174
[framework] 2015-12-16 12:51:56,967 - org.apache.hadoop.util.NativeCodeLoader -2205 [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-16 12:51:57,911 - com.infogen.hdfs.InfoGen_LZOOutputStream -3149 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/9/1.4494174-
[framework] 2015-12-16 12:51:58,107 - com.hadoop.compression.lzo.GPLNativeCodeLoader -3345 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-16 12:51:58,109 - com.hadoop.compression.lzo.LzoCodec -3347 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-16 12:51:58,112 - org.apache.hadoop.conf.Configuration.deprecation -3350 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-16 12:51:58,114 - org.apache.hadoop.io.compress.CodecPool -3352 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:51:58,229 - com.infogen.hdfs.InfoGen_LZOOutputStream -3467 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/10/1.4494404-
[framework] 2015-12-16 12:51:58,325 - org.apache.hadoop.io.compress.CodecPool -3563 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:51:58,453 - com.infogen.zookeeper.InfoGen_ZooKeeper -3691 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:51:58,469 - com.infogen.zookeeper.InfoGen_ZooKeeper -3707 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:51:58,599 - com.infogen.zookeeper.InfoGen_ZooKeeper -3837 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:51:58,614 - com.infogen.zookeeper.InfoGen_ZooKeeper -3852 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:51:58,764 - com.infogen.hdfs.InfoGen_LZOOutputStream -4002 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/11/1.4496476-
[framework] 2015-12-16 12:51:58,863 - org.apache.hadoop.io.compress.CodecPool -4101 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:51:58,967 - com.infogen.zookeeper.InfoGen_ZooKeeper -4205 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:51:58,983 - com.infogen.zookeeper.InfoGen_ZooKeeper -4221 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:51:59,119 - com.infogen.zookeeper.InfoGen_ZooKeeper -4357 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:51:59,134 - com.infogen.zookeeper.InfoGen_ZooKeeper -4372 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:51:59,292 - com.infogen.zookeeper.InfoGen_ZooKeeper -4530 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:51:59,312 - com.infogen.zookeeper.InfoGen_ZooKeeper -4550 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:51:59,454 - com.infogen.zookeeper.InfoGen_ZooKeeper -4692 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:51:59,470 - com.infogen.zookeeper.InfoGen_ZooKeeper -4708 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:51:59,605 - com.infogen.zookeeper.InfoGen_ZooKeeper -4843 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:51:59,621 - com.infogen.zookeeper.InfoGen_ZooKeeper -4859 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:51:59,740 - com.infogen.zookeeper.InfoGen_ZooKeeper -4978 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:51:59,754 - com.infogen.zookeeper.InfoGen_ZooKeeper -4992 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:00,542 - com.infogen.zookeeper.InfoGen_ZooKeeper -5780 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:00,561 - com.infogen.zookeeper.InfoGen_ZooKeeper -5799 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:00,732 - com.infogen.zookeeper.InfoGen_ZooKeeper -5970 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:00,755 - com.infogen.zookeeper.InfoGen_ZooKeeper -5993 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:00,890 - com.infogen.zookeeper.InfoGen_ZooKeeper -6128 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:00,909 - com.infogen.zookeeper.InfoGen_ZooKeeper -6147 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:01,108 - com.infogen.zookeeper.InfoGen_ZooKeeper -6346 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:01,123 - com.infogen.zookeeper.InfoGen_ZooKeeper -6361 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:01,285 - com.infogen.zookeeper.InfoGen_ZooKeeper -6523 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:01,313 - com.infogen.zookeeper.InfoGen_ZooKeeper -6551 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:01,506 - com.infogen.zookeeper.InfoGen_ZooKeeper -6744 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:01,520 - com.infogen.zookeeper.InfoGen_ZooKeeper -6758 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:01,760 - com.infogen.zookeeper.InfoGen_ZooKeeper -6998 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:01,776 - com.infogen.zookeeper.InfoGen_ZooKeeper -7014 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:02,018 - com.infogen.zookeeper.InfoGen_ZooKeeper -7256 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:02,034 - com.infogen.zookeeper.InfoGen_ZooKeeper -7272 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:02,331 - com.infogen.zookeeper.InfoGen_ZooKeeper -7569 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:02,347 - com.infogen.zookeeper.InfoGen_ZooKeeper -7585 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:02,712 - com.infogen.zookeeper.InfoGen_ZooKeeper -7950 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:02,734 - com.infogen.zookeeper.InfoGen_ZooKeeper -7972 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:02,959 - com.infogen.zookeeper.InfoGen_ZooKeeper -8197 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:02,987 - com.infogen.zookeeper.InfoGen_ZooKeeper -8225 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:03,220 - com.infogen.zookeeper.InfoGen_ZooKeeper -8458 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:03,236 - com.infogen.zookeeper.InfoGen_ZooKeeper -8474 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:03,470 - com.infogen.zookeeper.InfoGen_ZooKeeper -8708 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:03,487 - com.infogen.zookeeper.InfoGen_ZooKeeper -8725 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:04,000 - com.infogen.zookeeper.InfoGen_ZooKeeper -9238 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:04,015 - com.infogen.zookeeper.InfoGen_ZooKeeper -9253 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:04,233 - com.infogen.zookeeper.InfoGen_ZooKeeper -9471 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:04,248 - com.infogen.zookeeper.InfoGen_ZooKeeper -9486 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:04,554 - com.infogen.zookeeper.InfoGen_ZooKeeper -9792 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:04,570 - com.infogen.zookeeper.InfoGen_ZooKeeper -9808 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:04,811 - com.infogen.zookeeper.InfoGen_ZooKeeper -10049 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:04,826 - com.infogen.zookeeper.InfoGen_ZooKeeper -10064 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:05,076 - com.infogen.hdfs.InfoGen_LZOOutputStream -10314 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/12/1.4519955-
[framework] 2015-12-16 12:52:05,181 - org.apache.hadoop.io.compress.CodecPool -10419 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 12:52:05,254 - com.infogen.zookeeper.InfoGen_ZooKeeper -10492 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:05,269 - com.infogen.zookeeper.InfoGen_ZooKeeper -10507 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:05,492 - com.infogen.zookeeper.InfoGen_ZooKeeper -10730 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:05,507 - com.infogen.zookeeper.InfoGen_ZooKeeper -10745 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:05,708 - com.infogen.zookeeper.InfoGen_ZooKeeper -10946 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:05,723 - com.infogen.zookeeper.InfoGen_ZooKeeper -10961 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:05,915 - com.infogen.zookeeper.InfoGen_ZooKeeper -11153 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:05,935 - com.infogen.zookeeper.InfoGen_ZooKeeper -11173 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:06,123 - com.infogen.zookeeper.InfoGen_ZooKeeper -11361 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:06,140 - com.infogen.zookeeper.InfoGen_ZooKeeper -11378 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:06,314 - com.infogen.zookeeper.InfoGen_ZooKeeper -11552 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:06,330 - com.infogen.zookeeper.InfoGen_ZooKeeper -11568 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:06,445 - com.infogen.zookeeper.InfoGen_ZooKeeper -11683 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:06,463 - com.infogen.zookeeper.InfoGen_ZooKeeper -11701 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:06,672 - com.infogen.zookeeper.InfoGen_ZooKeeper -11910 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:06,686 - com.infogen.zookeeper.InfoGen_ZooKeeper -11924 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:07,020 - com.infogen.zookeeper.InfoGen_ZooKeeper -12258 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:07,035 - com.infogen.zookeeper.InfoGen_ZooKeeper -12273 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:07,324 - com.infogen.zookeeper.InfoGen_ZooKeeper -12562 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:07,339 - com.infogen.zookeeper.InfoGen_ZooKeeper -12577 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:07,613 - com.infogen.zookeeper.InfoGen_ZooKeeper -12851 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:07,629 - com.infogen.zookeeper.InfoGen_ZooKeeper -12867 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:08,045 - com.infogen.zookeeper.InfoGen_ZooKeeper -13283 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:08,070 - com.infogen.zookeeper.InfoGen_ZooKeeper -13308 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:08,576 - com.infogen.zookeeper.InfoGen_ZooKeeper -13814 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:08,591 - com.infogen.zookeeper.InfoGen_ZooKeeper -13829 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:09,036 - com.infogen.zookeeper.InfoGen_ZooKeeper -14274 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:09,057 - com.infogen.zookeeper.InfoGen_ZooKeeper -14295 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:09,409 - com.infogen.zookeeper.InfoGen_ZooKeeper -14647 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:09,436 - com.infogen.zookeeper.InfoGen_ZooKeeper -14674 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:09,703 - com.infogen.zookeeper.InfoGen_ZooKeeper -14941 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:09,724 - com.infogen.zookeeper.InfoGen_ZooKeeper -14962 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 12:52:10,046 - com.infogen.zookeeper.InfoGen_ZooKeeper -15284 [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 写入节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 16:43:04,268 - com.infogen.zookeeper.InfoGen_ZooKeeper -0    [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-16 16:43:04,313 - org.apache.zookeeper.ZooKeeper -45   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[framework] 2015-12-16 16:43:04,313 - org.apache.zookeeper.ZooKeeper -45   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:host.name=localhost
[framework] 2015-12-16 16:43:04,313 - org.apache.zookeeper.ZooKeeper -45   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_20
[framework] 2015-12-16 16:43:04,314 - org.apache.zookeeper.ZooKeeper -46   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
[framework] 2015-12-16 16:43:04,314 - org.apache.zookeeper.ZooKeeper -46   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/lib/jvm/java-8-sun/jre
[framework] 2015-12-16 16:43:04,314 - org.apache.zookeeper.ZooKeeper -46   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/home/juxinli/workspace/infogen_etl/target/classes:/home/juxinli/workspace/infogen_etl/lib/hadoop-lzo-0.4.20-SNAPSHOT.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-client/2.7.1/hadoop-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-common/2.7.1/hadoop-common-2.7.1.jar:/home/juxinli/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/juxinli/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/juxinli/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/juxinli/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/juxinli/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/juxinli/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/juxinli/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/juxinli/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/juxinli/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/juxinli/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/juxinli/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/juxinli/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/juxinli/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/juxinli/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/juxinli/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/juxinli/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/juxinli/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.1/hadoop-auth-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/home/juxinli/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/juxinli/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/juxinli/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.1/hadoop-hdfs-2.7.1.jar:/home/juxinli/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/juxinli/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/juxinli/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/juxinli/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/juxinli/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.1/hadoop-mapreduce-client-app-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.1/hadoop-mapreduce-client-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.1/hadoop-yarn-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.1/hadoop-yarn-server-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.1/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.1/hadoop-yarn-api-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.1/hadoop-mapreduce-client-core-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.1/hadoop-yarn-common-2.7.1.jar:/home/juxinli/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/juxinli/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/juxinli/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/juxinli/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.1/hadoop-mapreduce-client-jobclient-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.1/hadoop-annotations-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka_2.11/0.8.2.2/kafka_2.11-0.8.2.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/juxinli/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar:/home/juxinli/.m2/repository/org/scala-lang/scala-library/2.11.5/scala-library-2.11.5.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.2/kafka-clients-0.8.2.2.jar:/home/juxinli/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/juxinli/.m2/repository/net/jpountz/lz4/lz4/1.2.0/lz4-1.2.0.jar:/home/juxinli/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/juxinli/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/juxinli/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/juxinli/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar
[framework] 2015-12-16 16:43:04,315 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[framework] 2015-12-16 16:43:04,315 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp
[framework] 2015-12-16 16:43:04,315 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
[framework] 2015-12-16 16:43:04,315 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
[framework] 2015-12-16 16:43:04,315 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
[framework] 2015-12-16 16:43:04,315 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.2.0-19-generic
[framework] 2015-12-16 16:43:04,315 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.name=juxinli
[framework] 2015-12-16 16:43:04,315 - org.apache.zookeeper.ZooKeeper -47   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/juxinli
[framework] 2015-12-16 16:43:04,316 - org.apache.zookeeper.ZooKeeper -48   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/home/juxinli/workspace/infogen_etl
[framework] 2015-12-16 16:43:04,318 - org.apache.zookeeper.ZooKeeper -50   [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@5ae63ade
[framework] 2015-12-16 16:43:04,353 - com.infogen.zookeeper.InfoGen_ZooKeeper -85   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-16 16:43:04,355 - com.infogen.zookeeper.InfoGen_ZooKeeper -87   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers
[framework] 2015-12-16 16:43:04,360 - org.apache.zookeeper.ClientCnxn -92   [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.97/172.16.8.97:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-16 16:43:04,441 - org.apache.zookeeper.ClientCnxn -173  [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.97/172.16.8.97:2181, initiating session
[framework] 2015-12-16 16:43:04,469 - org.apache.zookeeper.ClientCnxn -201  [main-SendThread(172.16.8.97:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.97/172.16.8.97:2181, sessionid = 0x614f1aad4d9c816f, negotiated timeout = 10000
[framework] 2015-12-16 16:43:04,472 - com.infogen.zookeeper.InfoGen_ZooKeeper -204  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-16 16:43:04,492 - com.infogen.zookeeper.InfoGen_ZooKeeper -224  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers
[framework] 2015-12-16 16:43:04,493 - com.infogen.zookeeper.InfoGen_ZooKeeper -225  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-16 16:43:04,722 - com.infogen.zookeeper.InfoGen_ZooKeeper -454  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-16 16:43:04,723 - com.infogen.zookeeper.InfoGen_ZooKeeper -455  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset
[framework] 2015-12-16 16:43:04,745 - com.infogen.zookeeper.InfoGen_ZooKeeper -477  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset
[framework] 2015-12-16 16:43:04,745 - com.infogen.zookeeper.InfoGen_ZooKeeper -477  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-16 16:43:04,770 - com.infogen.zookeeper.InfoGen_ZooKeeper -502  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-16 16:43:04,770 - com.infogen.zookeeper.InfoGen_ZooKeeper -502  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/ids
[framework] 2015-12-16 16:43:04,793 - com.infogen.zookeeper.InfoGen_ZooKeeper -525  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/ids
[framework] 2015-12-16 16:43:04,793 - com.infogen.zookeeper.InfoGen_ZooKeeper -525  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/1
[framework] 2015-12-16 16:43:04,824 - com.infogen.zookeeper.InfoGen_ZooKeeper -556  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/1
[framework] 2015-12-16 16:43:04,824 - com.infogen.zookeeper.InfoGen_ZooKeeper -556  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/2
[framework] 2015-12-16 16:43:04,845 - com.infogen.zookeeper.InfoGen_ZooKeeper -577  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/2
[framework] 2015-12-16 16:43:04,845 - com.infogen.zookeeper.InfoGen_ZooKeeper -577  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/3
[framework] 2015-12-16 16:43:04,870 - com.infogen.zookeeper.InfoGen_ZooKeeper -602  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/3
[framework] 2015-12-16 16:43:04,870 - com.infogen.zookeeper.InfoGen_ZooKeeper -602  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-16 16:43:04,892 - com.infogen.zookeeper.InfoGen_ZooKeeper -624  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-16 16:43:04,892 - com.infogen.zookeeper.InfoGen_ZooKeeper -624  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset/0
[framework] 2015-12-16 16:43:04,913 - com.infogen.zookeeper.InfoGen_ZooKeeper -645  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset/0
[framework] 2015-12-16 16:43:04,917 - com.infogen.zookeeper.InfoGen_ZooKeeper -649  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-16 16:43:04,950 - com.infogen.zookeeper.InfoGen_ZooKeeper -682  [main] WARN  com.infogen.zookeeper.InfoGen_ZooKeeper  - 节点已经存在: /infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-16 16:43:04,950 - com.infogen.etl.InfoGen_Container -682  [main] INFO  com.infogen.etl.InfoGen_Container  - #创建partition失败:0
[framework] 2015-12-16 16:43:04,950 - com.infogen.zookeeper.InfoGen_ZooKeeper -682  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 16:43:04,978 - com.infogen.zookeeper.InfoGen_ZooKeeper -710  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 16:43:04,978 - com.infogen.zookeeper.InfoGen_ZooKeeper -710  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/partition/1
[framework] 2015-12-16 16:43:05,003 - com.infogen.zookeeper.InfoGen_ZooKeeper -735  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking/partition/1
[framework] 2015-12-16 16:43:05,003 - com.infogen.etl.InfoGen_Container -735  [main] INFO  com.infogen.etl.InfoGen_Container  - #获取partition成功:1
[framework] 2015-12-16 16:43:05,004 - com.infogen.zookeeper.InfoGen_ZooKeeper -736  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 16:43:05,022 - com.infogen.zookeeper.InfoGen_ZooKeeper -754  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 16:43:05,023 - com.infogen.etl.InfoGen_Container -755  [main] INFO  com.infogen.etl.InfoGen_Container  - #使用zookeeper 中 offset为:null
[framework] 2015-12-16 16:43:05,023 - com.infogen.zookeeper.InfoGen_ZooKeeper -755  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 关闭zookeeper
[framework] 2015-12-16 16:43:05,044 - org.apache.zookeeper.ClientCnxn -776  [main-EventThread] INFO  org.apache.zookeeper.ClientCnxn  - EventThread shut down
[framework] 2015-12-16 16:43:05,045 - org.apache.zookeeper.ZooKeeper -777  [main] INFO  org.apache.zookeeper.ZooKeeper  - Session: 0x614f1aad4d9c816f closed
[framework] 2015-12-16 16:43:05,045 - com.infogen.zookeeper.InfoGen_ZooKeeper -777  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 关闭zookeeper成功
[framework] 2015-12-16 16:43:05,055 - com.infogen.zookeeper.InfoGen_ZooKeeper -787  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-16 16:43:05,055 - org.apache.zookeeper.ZooKeeper -787  [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@1b26f7b2
[framework] 2015-12-16 16:43:05,057 - org.apache.zookeeper.ClientCnxn -789  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.99/172.16.8.99:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-16 16:43:05,057 - com.infogen.zookeeper.InfoGen_ZooKeeper -789  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-16 16:43:05,092 - org.apache.zookeeper.ClientCnxn -824  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.99/172.16.8.99:2181, initiating session
[framework] 2015-12-16 16:43:05,107 - org.apache.zookeeper.ClientCnxn -839  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.99/172.16.8.99:2181, sessionid = 0x634f1aacb9811fa0, negotiated timeout = 10000
[framework] 2015-12-16 16:43:05,108 - com.infogen.zookeeper.InfoGen_ZooKeeper -840  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-16 16:43:06,596 - org.apache.hadoop.util.NativeCodeLoader -2328 [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-16 16:43:07,549 - com.infogen.hdfs.InfoGen_LZOOutputStream -3281 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/12/1.4536215-
[framework] 2015-12-16 16:43:07,752 - com.hadoop.compression.lzo.GPLNativeCodeLoader -3484 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-16 16:43:07,754 - com.hadoop.compression.lzo.LzoCodec -3486 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-16 16:43:07,755 - org.apache.hadoop.conf.Configuration.deprecation -3487 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-16 16:43:07,757 - org.apache.hadoop.io.compress.CodecPool -3489 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:08,113 - com.infogen.hdfs.InfoGen_LZOOutputStream -3845 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/13/1.4537552-
[framework] 2015-12-16 16:43:08,218 - org.apache.hadoop.io.compress.CodecPool -3950 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:08,349 - com.infogen.hdfs.InfoGen_LZOOutputStream -4081 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/14/1.4537719-
[framework] 2015-12-16 16:43:08,464 - org.apache.hadoop.io.compress.CodecPool -4196 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:08,533 - com.infogen.hdfs.InfoGen_LZOOutputStream -4265 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/15/1.4537891-
[framework] 2015-12-16 16:43:08,637 - org.apache.hadoop.io.compress.CodecPool -4369 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:08,890 - com.infogen.hdfs.InfoGen_LZOOutputStream -4622 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/16/1.4538791-
[framework] 2015-12-16 16:43:08,979 - org.apache.hadoop.io.compress.CodecPool -4711 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:10,905 - com.infogen.hdfs.InfoGen_LZOOutputStream -6637 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/17/1.4542732-
[framework] 2015-12-16 16:43:11,254 - org.apache.hadoop.io.compress.CodecPool -6986 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:11,991 - com.infogen.hdfs.InfoGen_LZOOutputStream -7723 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/18/1.4544732-
[framework] 2015-12-16 16:43:12,093 - org.apache.hadoop.io.compress.CodecPool -7825 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:12,256 - com.infogen.hdfs.InfoGen_LZOOutputStream -7988 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/19/1.4545163-
[framework] 2015-12-16 16:43:12,363 - org.apache.hadoop.io.compress.CodecPool -8095 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:12,592 - com.infogen.hdfs.InfoGen_LZOOutputStream -8324 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/20/1.4545770-
[framework] 2015-12-16 16:43:12,685 - org.apache.hadoop.io.compress.CodecPool -8417 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:12,742 - com.infogen.hdfs.InfoGen_LZOOutputStream -8474 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/21/1.4546042-
[framework] 2015-12-16 16:43:12,826 - org.apache.hadoop.io.compress.CodecPool -8558 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:12,956 - com.infogen.hdfs.InfoGen_LZOOutputStream -8688 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/22/1.4546181-
[framework] 2015-12-16 16:43:13,034 - org.apache.hadoop.io.compress.CodecPool -8766 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:13,084 - com.infogen.hdfs.InfoGen_LZOOutputStream -8816 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-3/23/1.4546269-
[framework] 2015-12-16 16:43:13,167 - org.apache.hadoop.io.compress.CodecPool -8899 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:13,216 - com.infogen.hdfs.InfoGen_LZOOutputStream -8948 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/0/1.4546361-
[framework] 2015-12-16 16:43:13,317 - org.apache.hadoop.io.compress.CodecPool -9049 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:13,364 - com.infogen.hdfs.InfoGen_LZOOutputStream -9096 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/1/1.4546429-
[framework] 2015-12-16 16:43:13,476 - org.apache.hadoop.io.compress.CodecPool -9208 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:13,643 - com.infogen.hdfs.InfoGen_LZOOutputStream -9375 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/2/1.4546507-
[framework] 2015-12-16 16:43:13,736 - org.apache.hadoop.io.compress.CodecPool -9468 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:13,789 - com.infogen.hdfs.InfoGen_LZOOutputStream -9521 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/3/1.4546573-
[framework] 2015-12-16 16:43:13,900 - org.apache.hadoop.io.compress.CodecPool -9632 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:13,958 - com.infogen.hdfs.InfoGen_LZOOutputStream -9690 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/4/1.4546651-
[framework] 2015-12-16 16:43:14,059 - org.apache.hadoop.io.compress.CodecPool -9791 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:14,113 - com.infogen.hdfs.InfoGen_LZOOutputStream -9845 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/5/1.4546723-
[framework] 2015-12-16 16:43:14,226 - org.apache.hadoop.io.compress.CodecPool -9958 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:14,294 - com.infogen.hdfs.InfoGen_LZOOutputStream -10026 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/6/1.4546804-
[framework] 2015-12-16 16:43:14,400 - org.apache.hadoop.io.compress.CodecPool -10132 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:14,766 - com.infogen.hdfs.InfoGen_LZOOutputStream -10498 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/7/1.4546876-
[framework] 2015-12-16 16:43:14,878 - org.apache.hadoop.io.compress.CodecPool -10610 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:14,937 - com.infogen.hdfs.InfoGen_LZOOutputStream -10669 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/8/1.4546962-
[framework] 2015-12-16 16:43:15,042 - org.apache.hadoop.io.compress.CodecPool -10774 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:15,094 - com.infogen.hdfs.InfoGen_LZOOutputStream -10826 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/9/1.4547029-
[framework] 2015-12-16 16:43:15,187 - org.apache.hadoop.io.compress.CodecPool -10919 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:15,256 - com.infogen.hdfs.InfoGen_LZOOutputStream -10988 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/10/1.4547109-
[framework] 2015-12-16 16:43:15,525 - org.apache.hadoop.io.compress.CodecPool -11257 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:15,985 - com.infogen.hdfs.InfoGen_LZOOutputStream -11717 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/11/1.4549013-
[framework] 2015-12-16 16:43:16,066 - org.apache.hadoop.io.compress.CodecPool -11798 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:16,524 - com.infogen.hdfs.InfoGen_LZOOutputStream -12256 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/12/1.4550205-
[framework] 2015-12-16 16:43:16,616 - org.apache.hadoop.io.compress.CodecPool -12348 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:16,851 - com.infogen.hdfs.InfoGen_LZOOutputStream -12583 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/13/1.4550967-
[framework] 2015-12-16 16:43:17,016 - org.apache.hadoop.io.compress.CodecPool -12748 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:17,067 - com.infogen.hdfs.InfoGen_LZOOutputStream -12799 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/14/1.4551147-
[framework] 2015-12-16 16:43:17,166 - org.apache.hadoop.io.compress.CodecPool -12898 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:17,477 - com.infogen.hdfs.InfoGen_LZOOutputStream -13209 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/15/1.4553052-
[framework] 2015-12-16 16:43:17,574 - org.apache.hadoop.io.compress.CodecPool -13306 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:17,922 - com.infogen.hdfs.InfoGen_LZOOutputStream -13654 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/16/1.4554636-
[framework] 2015-12-16 16:43:18,016 - org.apache.hadoop.io.compress.CodecPool -13748 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:18,426 - com.infogen.hdfs.InfoGen_LZOOutputStream -14158 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/17/1.4556409-
[framework] 2015-12-16 16:43:18,516 - org.apache.hadoop.io.compress.CodecPool -14248 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:18,696 - com.infogen.hdfs.InfoGen_LZOOutputStream -14428 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/18/1.4557030-
[framework] 2015-12-16 16:43:18,795 - org.apache.hadoop.io.compress.CodecPool -14527 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:18,904 - com.infogen.hdfs.InfoGen_LZOOutputStream -14636 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/19/1.4557299-
[framework] 2015-12-16 16:43:19,010 - org.apache.hadoop.io.compress.CodecPool -14742 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:19,177 - com.infogen.hdfs.InfoGen_LZOOutputStream -14909 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/20/1.4557930-
[framework] 2015-12-16 16:43:19,265 - org.apache.hadoop.io.compress.CodecPool -14997 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:43:19,365 - com.infogen.hdfs.InfoGen_LZOOutputStream -15097 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/21/1.4558448-
[framework] 2015-12-16 16:44:11,752 - com.infogen.zookeeper.InfoGen_ZooKeeper -0    [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-16 16:44:11,788 - org.apache.zookeeper.ZooKeeper -36   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
[framework] 2015-12-16 16:44:11,789 - org.apache.zookeeper.ZooKeeper -37   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:host.name=localhost
[framework] 2015-12-16 16:44:11,789 - org.apache.zookeeper.ZooKeeper -37   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.version=1.8.0_20
[framework] 2015-12-16 16:44:11,789 - org.apache.zookeeper.ZooKeeper -37   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.vendor=Oracle Corporation
[framework] 2015-12-16 16:44:11,789 - org.apache.zookeeper.ZooKeeper -37   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.home=/usr/lib/jvm/java-8-sun/jre
[framework] 2015-12-16 16:44:11,789 - org.apache.zookeeper.ZooKeeper -37   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.class.path=/home/juxinli/workspace/infogen_etl/target/classes:/home/juxinli/workspace/infogen_etl/lib/hadoop-lzo-0.4.20-SNAPSHOT.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-client/2.7.1/hadoop-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-common/2.7.1/hadoop-common-2.7.1.jar:/home/juxinli/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/juxinli/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/juxinli/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/juxinli/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/juxinli/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/juxinli/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/juxinli/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/juxinli/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/juxinli/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/juxinli/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/home/juxinli/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/juxinli/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/juxinli/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/juxinli/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/juxinli/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-api/1.7.10/slf4j-api-1.7.10.jar:/home/juxinli/.m2/repository/org/slf4j/slf4j-log4j12/1.7.10/slf4j-log4j12-1.7.10.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/juxinli/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/juxinli/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/juxinli/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-auth/2.7.1/hadoop-auth-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/juxinli/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-framework/2.7.1/curator-framework-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/curator/curator-recipes/2.7.1/curator-recipes-2.7.1.jar:/home/juxinli/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/juxinli/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/juxinli/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/juxinli/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.1/hadoop-hdfs-2.7.1.jar:/home/juxinli/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/juxinli/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/juxinli/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/juxinli/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/juxinli/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.1/hadoop-mapreduce-client-app-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.1/hadoop-mapreduce-client-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.1/hadoop-yarn-client-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.1/hadoop-yarn-server-common-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.1/hadoop-mapreduce-client-shuffle-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.1/hadoop-yarn-api-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.1/hadoop-mapreduce-client-core-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.1/hadoop-yarn-common-2.7.1.jar:/home/juxinli/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/juxinli/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/juxinli/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/juxinli/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/juxinli/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/juxinli/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.1/hadoop-mapreduce-client-jobclient-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.1/hadoop-annotations-2.7.1.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka_2.11/0.8.2.2/kafka_2.11-0.8.2.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/juxinli/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar:/home/juxinli/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar:/home/juxinli/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar:/home/juxinli/.m2/repository/org/scala-lang/scala-library/2.11.5/scala-library-2.11.5.jar:/home/juxinli/.m2/repository/org/apache/kafka/kafka-clients/0.8.2.2/kafka-clients-0.8.2.2.jar:/home/juxinli/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/juxinli/.m2/repository/net/jpountz/lz4/lz4/1.2.0/lz4-1.2.0.jar:/home/juxinli/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/juxinli/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/juxinli/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/juxinli/.m2/repository/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar
[framework] 2015-12-16 16:44:11,790 - org.apache.zookeeper.ZooKeeper -38   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
[framework] 2015-12-16 16:44:11,790 - org.apache.zookeeper.ZooKeeper -38   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.io.tmpdir=/tmp
[framework] 2015-12-16 16:44:11,790 - org.apache.zookeeper.ZooKeeper -38   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:java.compiler=<NA>
[framework] 2015-12-16 16:44:11,790 - org.apache.zookeeper.ZooKeeper -38   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.name=Linux
[framework] 2015-12-16 16:44:11,790 - org.apache.zookeeper.ZooKeeper -38   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.arch=amd64
[framework] 2015-12-16 16:44:11,790 - org.apache.zookeeper.ZooKeeper -38   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:os.version=4.2.0-19-generic
[framework] 2015-12-16 16:44:11,790 - org.apache.zookeeper.ZooKeeper -38   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.name=juxinli
[framework] 2015-12-16 16:44:11,791 - org.apache.zookeeper.ZooKeeper -39   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.home=/home/juxinli
[framework] 2015-12-16 16:44:11,791 - org.apache.zookeeper.ZooKeeper -39   [main] INFO  org.apache.zookeeper.ZooKeeper  - Client environment:user.dir=/home/juxinli/workspace/infogen_etl
[framework] 2015-12-16 16:44:11,792 - org.apache.zookeeper.ZooKeeper -40   [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@5ae63ade
[framework] 2015-12-16 16:44:11,820 - com.infogen.zookeeper.InfoGen_ZooKeeper -68   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-16 16:44:11,822 - com.infogen.zookeeper.InfoGen_ZooKeeper -70   [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers
[framework] 2015-12-16 16:44:11,829 - org.apache.zookeeper.ClientCnxn -77   [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.98/172.16.8.98:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-16 16:44:11,907 - org.apache.zookeeper.ClientCnxn -155  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.98/172.16.8.98:2181, initiating session
[framework] 2015-12-16 16:44:11,929 - org.apache.zookeeper.ClientCnxn -177  [main-SendThread(172.16.8.98:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.98/172.16.8.98:2181, sessionid = 0x6250c64e4256073a, negotiated timeout = 10000
[framework] 2015-12-16 16:44:11,931 - com.infogen.zookeeper.InfoGen_ZooKeeper -179  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-16 16:44:11,947 - com.infogen.zookeeper.InfoGen_ZooKeeper -195  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers
[framework] 2015-12-16 16:44:11,947 - com.infogen.zookeeper.InfoGen_ZooKeeper -195  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-16 16:44:11,961 - com.infogen.zookeeper.InfoGen_ZooKeeper -209  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking
[framework] 2015-12-16 16:44:11,962 - com.infogen.zookeeper.InfoGen_ZooKeeper -210  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset
[framework] 2015-12-16 16:44:11,976 - com.infogen.zookeeper.InfoGen_ZooKeeper -224  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset
[framework] 2015-12-16 16:44:11,977 - com.infogen.zookeeper.InfoGen_ZooKeeper -225  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-16 16:44:11,990 - com.infogen.zookeeper.InfoGen_ZooKeeper -238  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/partition
[framework] 2015-12-16 16:44:11,990 - com.infogen.zookeeper.InfoGen_ZooKeeper -238  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/ids
[framework] 2015-12-16 16:44:12,008 - com.infogen.zookeeper.InfoGen_ZooKeeper -256  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/ids
[framework] 2015-12-16 16:44:12,008 - com.infogen.zookeeper.InfoGen_ZooKeeper -256  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/1
[framework] 2015-12-16 16:44:12,024 - com.infogen.zookeeper.InfoGen_ZooKeeper -272  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/1
[framework] 2015-12-16 16:44:12,025 - com.infogen.zookeeper.InfoGen_ZooKeeper -273  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/2
[framework] 2015-12-16 16:44:12,040 - com.infogen.zookeeper.InfoGen_ZooKeeper -288  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/2
[framework] 2015-12-16 16:44:12,040 - com.infogen.zookeeper.InfoGen_ZooKeeper -288  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/brokers/ids/3
[framework] 2015-12-16 16:44:12,054 - com.infogen.zookeeper.InfoGen_ZooKeeper -302  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/brokers/ids/3
[framework] 2015-12-16 16:44:12,054 - com.infogen.zookeeper.InfoGen_ZooKeeper -302  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-16 16:44:12,069 - com.infogen.zookeeper.InfoGen_ZooKeeper -317  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取子节点目录成功:/brokers/topics/infogen_topic_tracking/partitions
[framework] 2015-12-16 16:44:12,069 - com.infogen.zookeeper.InfoGen_ZooKeeper -317  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset/0
[framework] 2015-12-16 16:44:12,083 - com.infogen.zookeeper.InfoGen_ZooKeeper -331  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset/0
[framework] 2015-12-16 16:44:12,086 - com.infogen.zookeeper.InfoGen_ZooKeeper -334  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-16 16:44:12,116 - com.infogen.zookeeper.InfoGen_ZooKeeper -364  [main] WARN  com.infogen.zookeeper.InfoGen_ZooKeeper  - 节点已经存在: /infogen_consumers/infogen_topic_tracking/partition/0
[framework] 2015-12-16 16:44:12,116 - com.infogen.etl.InfoGen_Container -364  [main] INFO  com.infogen.etl.InfoGen_Container  - #创建partition失败:0
[framework] 2015-12-16 16:44:12,117 - com.infogen.zookeeper.InfoGen_ZooKeeper -365  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 16:44:12,130 - com.infogen.zookeeper.InfoGen_ZooKeeper -378  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 判断节点是否存在成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 16:44:12,130 - com.infogen.zookeeper.InfoGen_ZooKeeper -378  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点:/infogen_consumers/infogen_topic_tracking/partition/1
[framework] 2015-12-16 16:44:12,152 - com.infogen.zookeeper.InfoGen_ZooKeeper -400  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 创建节点成功:/infogen_consumers/infogen_topic_tracking/partition/1
[framework] 2015-12-16 16:44:12,153 - com.infogen.etl.InfoGen_Container -401  [main] INFO  com.infogen.etl.InfoGen_Container  - #获取partition成功:1
[framework] 2015-12-16 16:44:12,153 - com.infogen.zookeeper.InfoGen_ZooKeeper -401  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 16:44:12,166 - com.infogen.zookeeper.InfoGen_ZooKeeper -414  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 获取节点数据成功:/infogen_consumers/infogen_topic_tracking/offset/1
[framework] 2015-12-16 16:44:12,166 - com.infogen.etl.InfoGen_Container -414  [main] INFO  com.infogen.etl.InfoGen_Container  - #使用zookeeper 中 offset为:null
[framework] 2015-12-16 16:44:12,166 - com.infogen.zookeeper.InfoGen_ZooKeeper -414  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 关闭zookeeper
[framework] 2015-12-16 16:44:12,183 - org.apache.zookeeper.ZooKeeper -431  [main] INFO  org.apache.zookeeper.ZooKeeper  - Session: 0x6250c64e4256073a closed
[framework] 2015-12-16 16:44:12,184 - com.infogen.zookeeper.InfoGen_ZooKeeper -432  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 关闭zookeeper成功
[framework] 2015-12-16 16:44:12,183 - org.apache.zookeeper.ClientCnxn -431  [main-EventThread] INFO  org.apache.zookeeper.ClientCnxn  - EventThread shut down
[framework] 2015-12-16 16:44:12,195 - com.infogen.zookeeper.InfoGen_ZooKeeper -443  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-16 16:44:12,196 - org.apache.zookeeper.ZooKeeper -444  [main] INFO  org.apache.zookeeper.ZooKeeper  - Initiating client connection, connectString=172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181 sessionTimeout=10000 watcher=com.infogen.zookeeper.InfoGen_ZooKeeper$1@1b26f7b2
[framework] 2015-12-16 16:44:12,197 - org.apache.zookeeper.ClientCnxn -445  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Opening socket connection to server 172.16.8.99/172.16.8.99:2181. Will not attempt to authenticate using SASL (unknown error)
[framework] 2015-12-16 16:44:12,197 - com.infogen.zookeeper.InfoGen_ZooKeeper -445  [main] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 启动zookeeper成功:172.16.8.97:2181,172.16.8.98:2181,172.16.8.99:2181
[framework] 2015-12-16 16:44:12,210 - org.apache.zookeeper.ClientCnxn -458  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Socket connection established to 172.16.8.99/172.16.8.99:2181, initiating session
[framework] 2015-12-16 16:44:12,224 - org.apache.zookeeper.ClientCnxn -472  [main-SendThread(172.16.8.99:2181)] INFO  org.apache.zookeeper.ClientCnxn  - Session establishment complete on server 172.16.8.99/172.16.8.99:2181, sessionid = 0x634f1aacb9811fa1, negotiated timeout = 10000
[framework] 2015-12-16 16:44:12,225 - com.infogen.zookeeper.InfoGen_ZooKeeper -473  [main-EventThread] INFO  com.infogen.zookeeper.InfoGen_ZooKeeper  - 连接事件  path:null  state:SyncConnected  type:None
[framework] 2015-12-16 16:44:13,501 - org.apache.hadoop.util.NativeCodeLoader -1749 [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[framework] 2015-12-16 16:44:14,560 - com.infogen.hdfs.InfoGen_LZOOutputStream -2808 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/20/1.4558218-
[framework] 2015-12-16 16:44:14,806 - com.hadoop.compression.lzo.GPLNativeCodeLoader -3054 [main] INFO  com.hadoop.compression.lzo.GPLNativeCodeLoader  - Loaded native gpl library from the embedded binaries
[framework] 2015-12-16 16:44:14,809 - com.hadoop.compression.lzo.LzoCodec -3057 [main] INFO  com.hadoop.compression.lzo.LzoCodec  - Successfully loaded & initialized native-lzo library [hadoop-lzo rev 826e7d8d3e839964dd9ed2d5f83296254b2c71d3]
[framework] 2015-12-16 16:44:14,811 - org.apache.hadoop.conf.Configuration.deprecation -3059 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - hadoop.native.lib is deprecated. Instead, use io.native.lib.available
[framework] 2015-12-16 16:44:14,814 - org.apache.hadoop.io.compress.CodecPool -3062 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:14,990 - com.infogen.hdfs.InfoGen_LZOOutputStream -3238 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/21/1.4558448-
[framework] 2015-12-16 16:44:15,109 - org.apache.hadoop.io.compress.CodecPool -3357 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:15,213 - com.infogen.hdfs.InfoGen_LZOOutputStream -3461 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/22/1.4558529-
[framework] 2015-12-16 16:44:15,283 - org.apache.hadoop.io.compress.CodecPool -3531 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:15,423 - com.infogen.hdfs.InfoGen_LZOOutputStream -3671 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/23/1.4558604-
[framework] 2015-12-16 16:44:15,493 - org.apache.hadoop.io.compress.CodecPool -3741 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:15,560 - com.infogen.hdfs.InfoGen_LZOOutputStream -3808 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/0/1.4558667-
[framework] 2015-12-16 16:44:15,660 - org.apache.hadoop.io.compress.CodecPool -3908 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:15,726 - com.infogen.hdfs.InfoGen_LZOOutputStream -3974 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/1/1.4558742-
[framework] 2015-12-16 16:44:15,793 - org.apache.hadoop.io.compress.CodecPool -4041 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:15,853 - com.infogen.hdfs.InfoGen_LZOOutputStream -4101 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/2/1.4558820-
[framework] 2015-12-16 16:44:16,020 - org.apache.hadoop.io.compress.CodecPool -4268 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:16,085 - com.infogen.hdfs.InfoGen_LZOOutputStream -4333 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/3/1.4558896-
[framework] 2015-12-16 16:44:16,250 - org.apache.hadoop.io.compress.CodecPool -4498 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:16,413 - com.infogen.hdfs.InfoGen_LZOOutputStream -4661 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/4/1.4558975-
[framework] 2015-12-16 16:44:16,492 - org.apache.hadoop.io.compress.CodecPool -4740 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:16,543 - com.infogen.hdfs.InfoGen_LZOOutputStream -4791 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/5/1.4559038-
[framework] 2015-12-16 16:44:16,625 - org.apache.hadoop.io.compress.CodecPool -4873 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:16,689 - com.infogen.hdfs.InfoGen_LZOOutputStream -4937 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/6/1.4559105-
[framework] 2015-12-16 16:44:16,758 - org.apache.hadoop.io.compress.CodecPool -5006 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:16,813 - com.infogen.hdfs.InfoGen_LZOOutputStream -5061 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/7/1.4559182-
[framework] 2015-12-16 16:44:17,019 - org.apache.hadoop.io.compress.CodecPool -5267 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:17,238 - com.infogen.hdfs.InfoGen_LZOOutputStream -5486 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/8/1.4559701-
[framework] 2015-12-16 16:44:17,309 - org.apache.hadoop.io.compress.CodecPool -5557 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:17,372 - com.infogen.hdfs.InfoGen_LZOOutputStream -5620 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/9/1.4559777-
[framework] 2015-12-16 16:44:17,468 - org.apache.hadoop.io.compress.CodecPool -5716 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:17,536 - com.infogen.hdfs.InfoGen_LZOOutputStream -5784 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/10/1.4559842-
[framework] 2015-12-16 16:44:17,705 - org.apache.hadoop.io.compress.CodecPool -5953 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:17,776 - com.infogen.hdfs.InfoGen_LZOOutputStream -6024 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/11/1.4559923-
[framework] 2015-12-16 16:44:17,877 - org.apache.hadoop.io.compress.CodecPool -6125 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:17,943 - com.infogen.hdfs.InfoGen_LZOOutputStream -6191 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/12/1.4560005-
[framework] 2015-12-16 16:44:18,060 - org.apache.hadoop.io.compress.CodecPool -6308 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:18,264 - com.infogen.hdfs.InfoGen_LZOOutputStream -6512 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/13/1.4560078-
[framework] 2015-12-16 16:44:18,350 - org.apache.hadoop.io.compress.CodecPool -6598 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:18,399 - com.infogen.hdfs.InfoGen_LZOOutputStream -6647 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/14/1.4560147-
[framework] 2015-12-16 16:44:18,466 - org.apache.hadoop.io.compress.CodecPool -6714 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:18,619 - com.infogen.hdfs.InfoGen_LZOOutputStream -6867 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/15/1.4560571-
[framework] 2015-12-16 16:44:18,775 - org.apache.hadoop.io.compress.CodecPool -7023 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:18,907 - com.infogen.hdfs.InfoGen_LZOOutputStream -7155 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/16/1.4560776-
[framework] 2015-12-16 16:44:19,166 - org.apache.hadoop.io.compress.CodecPool -7414 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:19,231 - com.infogen.hdfs.InfoGen_LZOOutputStream -7479 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/17/1.4560972-
[framework] 2015-12-16 16:44:19,525 - org.apache.hadoop.io.compress.CodecPool -7773 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:19,722 - com.infogen.hdfs.InfoGen_LZOOutputStream -7970 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/18/1.4561528-
[framework] 2015-12-16 16:44:19,916 - org.apache.hadoop.io.compress.CodecPool -8164 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:19,966 - com.infogen.hdfs.InfoGen_LZOOutputStream -8214 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/19/1.4561634-
[framework] 2015-12-16 16:44:20,047 - org.apache.hadoop.io.compress.CodecPool -8295 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:20,165 - com.infogen.hdfs.InfoGen_LZOOutputStream -8413 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/20/1.4561854-
[framework] 2015-12-16 16:44:20,242 - org.apache.hadoop.io.compress.CodecPool -8490 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:20,309 - com.infogen.hdfs.InfoGen_LZOOutputStream -8557 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/21/1.4561920-
[framework] 2015-12-16 16:44:20,382 - org.apache.hadoop.io.compress.CodecPool -8630 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:20,428 - com.infogen.hdfs.InfoGen_LZOOutputStream -8676 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/22/1.4561999-
[framework] 2015-12-16 16:44:20,556 - org.apache.hadoop.io.compress.CodecPool -8804 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:20,609 - com.infogen.hdfs.InfoGen_LZOOutputStream -8857 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/23/1.4562073-
[framework] 2015-12-16 16:44:20,774 - org.apache.hadoop.io.compress.CodecPool -9022 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:20,939 - com.infogen.hdfs.InfoGen_LZOOutputStream -9187 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/0/1.4562158-
[framework] 2015-12-16 16:44:21,181 - org.apache.hadoop.io.compress.CodecPool -9429 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:21,238 - com.infogen.hdfs.InfoGen_LZOOutputStream -9486 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/1/1.4562250-
[framework] 2015-12-16 16:44:21,426 - org.apache.hadoop.io.compress.CodecPool -9674 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:21,497 - com.infogen.hdfs.InfoGen_LZOOutputStream -9745 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/2/1.4562325-
[framework] 2015-12-16 16:44:21,582 - org.apache.hadoop.io.compress.CodecPool -9830 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:21,627 - com.infogen.hdfs.InfoGen_LZOOutputStream -9875 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/3/1.4562405-
[framework] 2015-12-16 16:44:21,724 - org.apache.hadoop.io.compress.CodecPool -9972 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:21,772 - com.infogen.hdfs.InfoGen_LZOOutputStream -10020 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/4/1.4562471-
[framework] 2015-12-16 16:44:21,840 - org.apache.hadoop.io.compress.CodecPool -10088 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:22,010 - com.infogen.hdfs.InfoGen_LZOOutputStream -10258 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/5/1.4562537-
[framework] 2015-12-16 16:44:22,159 - org.apache.hadoop.io.compress.CodecPool -10407 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:22,216 - com.infogen.hdfs.InfoGen_LZOOutputStream -10464 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/6/1.4562607-
[framework] 2015-12-16 16:44:22,374 - org.apache.hadoop.io.compress.CodecPool -10622 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:22,430 - com.infogen.hdfs.InfoGen_LZOOutputStream -10678 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/7/1.4562675-
[framework] 2015-12-16 16:44:22,498 - org.apache.hadoop.io.compress.CodecPool -10746 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:22,688 - com.infogen.hdfs.InfoGen_LZOOutputStream -10936 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/8/1.4563235-
[framework] 2015-12-16 16:44:22,807 - org.apache.hadoop.io.compress.CodecPool -11055 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:22,861 - com.infogen.hdfs.InfoGen_LZOOutputStream -11109 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/9/1.4563304-
[framework] 2015-12-16 16:44:22,957 - org.apache.hadoop.io.compress.CodecPool -11205 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:23,018 - com.infogen.hdfs.InfoGen_LZOOutputStream -11266 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/10/1.4563390-
[framework] 2015-12-16 16:44:23,088 - org.apache.hadoop.io.compress.CodecPool -11336 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:23,144 - com.infogen.hdfs.InfoGen_LZOOutputStream -11392 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/11/1.4563505-
[framework] 2015-12-16 16:44:23,325 - org.apache.hadoop.io.compress.CodecPool -11573 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:23,469 - com.infogen.hdfs.InfoGen_LZOOutputStream -11717 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/12/1.4563580-
[framework] 2015-12-16 16:44:23,718 - org.apache.hadoop.io.compress.CodecPool -11966 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:23,776 - com.infogen.hdfs.InfoGen_LZOOutputStream -12024 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/13/1.4563650-
[framework] 2015-12-16 16:44:23,857 - org.apache.hadoop.io.compress.CodecPool -12105 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:23,924 - com.infogen.hdfs.InfoGen_LZOOutputStream -12172 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/14/1.4563727-
[framework] 2015-12-16 16:44:23,990 - org.apache.hadoop.io.compress.CodecPool -12238 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:24,128 - com.infogen.hdfs.InfoGen_LZOOutputStream -12376 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/15/1.4563962-
[framework] 2015-12-16 16:44:24,189 - org.apache.hadoop.io.compress.CodecPool -12437 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:24,235 - com.infogen.hdfs.InfoGen_LZOOutputStream -12483 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/16/1.4564183-
[framework] 2015-12-16 16:44:24,298 - org.apache.hadoop.io.compress.CodecPool -12546 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:24,352 - com.infogen.hdfs.InfoGen_LZOOutputStream -12600 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/17/1.4564260-
[framework] 2015-12-16 16:44:24,432 - org.apache.hadoop.io.compress.CodecPool -12680 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:24,575 - com.infogen.hdfs.InfoGen_LZOOutputStream -12823 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/18/1.4564337-
[framework] 2015-12-16 16:44:24,640 - org.apache.hadoop.io.compress.CodecPool -12888 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:24,711 - com.infogen.hdfs.InfoGen_LZOOutputStream -12959 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/19/1.4564422-
[framework] 2015-12-16 16:44:24,859 - org.apache.hadoop.io.compress.CodecPool -13107 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:24,911 - com.infogen.hdfs.InfoGen_LZOOutputStream -13159 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/20/1.4564492-
[framework] 2015-12-16 16:44:24,999 - org.apache.hadoop.io.compress.CodecPool -13247 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:25,052 - com.infogen.hdfs.InfoGen_LZOOutputStream -13300 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/21/1.4564576-
[framework] 2015-12-16 16:44:25,156 - org.apache.hadoop.io.compress.CodecPool -13404 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:25,559 - com.infogen.hdfs.InfoGen_LZOOutputStream -13807 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/22/1.4564647-
[framework] 2015-12-16 16:44:25,631 - org.apache.hadoop.io.compress.CodecPool -13879 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:25,685 - com.infogen.hdfs.InfoGen_LZOOutputStream -13933 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/23/1.4564718-
[framework] 2015-12-16 16:44:25,849 - org.apache.hadoop.io.compress.CodecPool -14097 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:25,900 - com.infogen.hdfs.InfoGen_LZOOutputStream -14148 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/0/1.4564777-
[framework] 2015-12-16 16:44:25,967 - org.apache.hadoop.io.compress.CodecPool -14215 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:26,030 - com.infogen.hdfs.InfoGen_LZOOutputStream -14278 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/1/1.4564849-
[framework] 2015-12-16 16:44:26,169 - org.apache.hadoop.io.compress.CodecPool -14417 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:26,247 - com.infogen.hdfs.InfoGen_LZOOutputStream -14495 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/2/1.4564922-
[framework] 2015-12-16 16:44:26,339 - org.apache.hadoop.io.compress.CodecPool -14587 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:26,384 - com.infogen.hdfs.InfoGen_LZOOutputStream -14632 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/3/1.4564990-
[framework] 2015-12-16 16:44:26,455 - org.apache.hadoop.io.compress.CodecPool -14703 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:26,586 - com.infogen.hdfs.InfoGen_LZOOutputStream -14834 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/4/1.4565069-
[framework] 2015-12-16 16:44:26,673 - org.apache.hadoop.io.compress.CodecPool -14921 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:26,727 - com.infogen.hdfs.InfoGen_LZOOutputStream -14975 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/5/1.4565136-
[framework] 2015-12-16 16:44:26,802 - org.apache.hadoop.io.compress.CodecPool -15050 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:26,855 - com.infogen.hdfs.InfoGen_LZOOutputStream -15103 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/6/1.4565207-
[framework] 2015-12-16 16:44:26,923 - org.apache.hadoop.io.compress.CodecPool -15171 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:26,981 - com.infogen.hdfs.InfoGen_LZOOutputStream -15229 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/7/1.4565283-
[framework] 2015-12-16 16:44:27,064 - org.apache.hadoop.io.compress.CodecPool -15312 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:27,261 - com.infogen.hdfs.InfoGen_LZOOutputStream -15509 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/8/1.4565737-
[framework] 2015-12-16 16:44:27,340 - org.apache.hadoop.io.compress.CodecPool -15588 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:27,387 - com.infogen.hdfs.InfoGen_LZOOutputStream -15635 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/9/1.4565804-
[framework] 2015-12-16 16:44:27,582 - org.apache.hadoop.io.compress.CodecPool -15830 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:27,648 - com.infogen.hdfs.InfoGen_LZOOutputStream -15896 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/10/1.4566067-
[framework] 2015-12-16 16:44:27,831 - org.apache.hadoop.io.compress.CodecPool -16079 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:28,089 - com.infogen.hdfs.InfoGen_LZOOutputStream -16337 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/11/1.4566804-
[framework] 2015-12-16 16:44:28,289 - org.apache.hadoop.io.compress.CodecPool -16537 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:28,652 - com.infogen.hdfs.InfoGen_LZOOutputStream -16900 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/12/1.4568307-
[framework] 2015-12-16 16:44:28,723 - org.apache.hadoop.io.compress.CodecPool -16971 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:28,772 - com.infogen.hdfs.InfoGen_LZOOutputStream -17020 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/13/1.4568364-
[framework] 2015-12-16 16:44:28,865 - org.apache.hadoop.io.compress.CodecPool -17113 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:28,983 - com.infogen.hdfs.InfoGen_LZOOutputStream -17231 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/14/1.4568555-
[framework] 2015-12-16 16:44:29,087 - org.apache.hadoop.io.compress.CodecPool -17335 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:29,190 - com.infogen.hdfs.InfoGen_LZOOutputStream -17438 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/15/1.4569046-
[framework] 2015-12-16 16:44:29,402 - org.apache.hadoop.io.compress.CodecPool -17650 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:29,873 - com.infogen.hdfs.InfoGen_LZOOutputStream -18121 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/16/1.4569858-
[framework] 2015-12-16 16:44:29,952 - org.apache.hadoop.io.compress.CodecPool -18200 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:30,323 - com.infogen.hdfs.InfoGen_LZOOutputStream -18571 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/17/1.4571349-
[framework] 2015-12-16 16:44:30,400 - org.apache.hadoop.io.compress.CodecPool -18648 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:30,615 - com.infogen.hdfs.InfoGen_LZOOutputStream -18863 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/18/1.4572295-
[framework] 2015-12-16 16:44:30,689 - org.apache.hadoop.io.compress.CodecPool -18937 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:30,804 - com.infogen.hdfs.InfoGen_LZOOutputStream -19052 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/19/1.4572661-
[framework] 2015-12-16 16:44:30,872 - org.apache.hadoop.io.compress.CodecPool -19120 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:31,213 - com.infogen.hdfs.InfoGen_LZOOutputStream -19461 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/20/1.4573839-
[framework] 2015-12-16 16:44:31,282 - org.apache.hadoop.io.compress.CodecPool -19530 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:31,522 - com.infogen.hdfs.InfoGen_LZOOutputStream -19770 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/21/1.4574970-
[framework] 2015-12-16 16:44:31,589 - org.apache.hadoop.io.compress.CodecPool -19837 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:31,680 - com.infogen.hdfs.InfoGen_LZOOutputStream -19928 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/22/1.4575096-
[framework] 2015-12-16 16:44:31,867 - org.apache.hadoop.io.compress.CodecPool -20115 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:31,915 - com.infogen.hdfs.InfoGen_LZOOutputStream -20163 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/23/1.4575191-
[framework] 2015-12-16 16:44:32,021 - org.apache.hadoop.io.compress.CodecPool -20269 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:32,072 - com.infogen.hdfs.InfoGen_LZOOutputStream -20320 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/0/1.4575261-
[framework] 2015-12-16 16:44:32,138 - org.apache.hadoop.io.compress.CodecPool -20386 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:32,178 - com.infogen.hdfs.InfoGen_LZOOutputStream -20426 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/1/1.4575344-
[framework] 2015-12-16 16:44:32,358 - org.apache.hadoop.io.compress.CodecPool -20606 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:32,470 - com.infogen.hdfs.InfoGen_LZOOutputStream -20718 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/2/1.4575427-
[framework] 2015-12-16 16:44:32,639 - org.apache.hadoop.io.compress.CodecPool -20887 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:32,694 - com.infogen.hdfs.InfoGen_LZOOutputStream -20942 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/3/1.4575499-
[framework] 2015-12-16 16:44:32,763 - org.apache.hadoop.io.compress.CodecPool -21011 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:32,815 - com.infogen.hdfs.InfoGen_LZOOutputStream -21063 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/4/1.4575564-
[framework] 2015-12-16 16:44:32,972 - org.apache.hadoop.io.compress.CodecPool -21220 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:33,022 - com.infogen.hdfs.InfoGen_LZOOutputStream -21270 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/5/1.4575633-
[framework] 2015-12-16 16:44:33,097 - org.apache.hadoop.io.compress.CodecPool -21345 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:33,200 - com.infogen.hdfs.InfoGen_LZOOutputStream -21448 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/6/1.4575685-
[framework] 2015-12-16 16:44:33,412 - org.apache.hadoop.io.compress.CodecPool -21660 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:33,539 - com.infogen.hdfs.InfoGen_LZOOutputStream -21787 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/7/1.4575753-
[framework] 2015-12-16 16:44:33,614 - org.apache.hadoop.io.compress.CodecPool -21862 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:33,660 - com.infogen.hdfs.InfoGen_LZOOutputStream -21908 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/8/1.4575824-
[framework] 2015-12-16 16:44:33,730 - org.apache.hadoop.io.compress.CodecPool -21978 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:33,772 - com.infogen.hdfs.InfoGen_LZOOutputStream -22020 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/9/1.4575896-
[framework] 2015-12-16 16:44:33,850 - org.apache.hadoop.io.compress.CodecPool -22098 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:33,968 - com.infogen.hdfs.InfoGen_LZOOutputStream -22216 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/10/1.4576268-
[framework] 2015-12-16 16:44:34,058 - org.apache.hadoop.io.compress.CodecPool -22306 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:34,352 - com.infogen.hdfs.InfoGen_LZOOutputStream -22600 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/11/1.4577741-
[framework] 2015-12-16 16:44:34,421 - org.apache.hadoop.io.compress.CodecPool -22669 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:35,340 - com.infogen.hdfs.InfoGen_LZOOutputStream -23588 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/12/1.4579671-
[framework] 2015-12-16 16:44:35,428 - org.apache.hadoop.io.compress.CodecPool -23676 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:35,674 - com.infogen.hdfs.InfoGen_LZOOutputStream -23922 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/13/1.4580278-
[framework] 2015-12-16 16:44:35,788 - org.apache.hadoop.io.compress.CodecPool -24036 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:36,016 - com.infogen.hdfs.InfoGen_LZOOutputStream -24264 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/14/1.4581029-
[framework] 2015-12-16 16:44:36,118 - org.apache.hadoop.io.compress.CodecPool -24366 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:37,714 - com.infogen.hdfs.InfoGen_LZOOutputStream -25962 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/15/1.4582541-
[framework] 2015-12-16 16:44:37,787 - org.apache.hadoop.io.compress.CodecPool -26035 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:38,216 - com.infogen.hdfs.InfoGen_LZOOutputStream -26464 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/16/1.4582968-
[framework] 2015-12-16 16:44:38,296 - org.apache.hadoop.io.compress.CodecPool -26544 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:39,237 - com.infogen.hdfs.InfoGen_LZOOutputStream -27485 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/17/1.4585031-
[framework] 2015-12-16 16:44:39,303 - org.apache.hadoop.io.compress.CodecPool -27551 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:40,022 - com.infogen.hdfs.InfoGen_LZOOutputStream -28270 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/18/1.4587331-
[framework] 2015-12-16 16:44:40,095 - org.apache.hadoop.io.compress.CodecPool -28343 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:40,795 - com.infogen.hdfs.InfoGen_LZOOutputStream -29043 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/19/1.4588866-
[framework] 2015-12-16 16:44:40,897 - org.apache.hadoop.io.compress.CodecPool -29145 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:41,111 - com.infogen.hdfs.InfoGen_LZOOutputStream -29359 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/20/1.4589188-
[framework] 2015-12-16 16:44:41,189 - org.apache.hadoop.io.compress.CodecPool -29437 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:41,537 - com.infogen.hdfs.InfoGen_LZOOutputStream -29785 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/21/1.4589749-
[framework] 2015-12-16 16:44:41,611 - org.apache.hadoop.io.compress.CodecPool -29859 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:41,676 - com.infogen.hdfs.InfoGen_LZOOutputStream -29924 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/22/1.4589854-
[framework] 2015-12-16 16:44:41,777 - org.apache.hadoop.io.compress.CodecPool -30025 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:41,829 - com.infogen.hdfs.InfoGen_LZOOutputStream -30077 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/23/1.4589915-
[framework] 2015-12-16 16:44:41,976 - org.apache.hadoop.io.compress.CodecPool -30224 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:42,023 - com.infogen.hdfs.InfoGen_LZOOutputStream -30271 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/0/1.4589999-
[framework] 2015-12-16 16:44:42,161 - org.apache.hadoop.io.compress.CodecPool -30409 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:42,376 - com.infogen.hdfs.InfoGen_LZOOutputStream -30624 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/1/1.4590074-
[framework] 2015-12-16 16:44:42,536 - org.apache.hadoop.io.compress.CodecPool -30784 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:42,583 - com.infogen.hdfs.InfoGen_LZOOutputStream -30831 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/2/1.4590145-
[framework] 2015-12-16 16:44:42,719 - org.apache.hadoop.io.compress.CodecPool -30967 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:42,765 - com.infogen.hdfs.InfoGen_LZOOutputStream -31013 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/3/1.4590213-
[framework] 2015-12-16 16:44:42,828 - org.apache.hadoop.io.compress.CodecPool -31076 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:42,874 - com.infogen.hdfs.InfoGen_LZOOutputStream -31122 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/4/1.4590293-
[framework] 2015-12-16 16:44:42,936 - org.apache.hadoop.io.compress.CodecPool -31184 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:42,983 - com.infogen.hdfs.InfoGen_LZOOutputStream -31231 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/5/1.4590374-
[framework] 2015-12-16 16:44:43,044 - org.apache.hadoop.io.compress.CodecPool -31292 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:43,478 - com.infogen.hdfs.InfoGen_LZOOutputStream -31726 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/6/1.4590443-
[framework] 2015-12-16 16:44:43,561 - org.apache.hadoop.io.compress.CodecPool -31809 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:43,614 - com.infogen.hdfs.InfoGen_LZOOutputStream -31862 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/7/1.4590510-
[framework] 2015-12-16 16:44:43,669 - org.apache.hadoop.io.compress.CodecPool -31917 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:43,721 - com.infogen.hdfs.InfoGen_LZOOutputStream -31969 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/8/1.4590588-
[framework] 2015-12-16 16:44:43,786 - org.apache.hadoop.io.compress.CodecPool -32034 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:43,832 - com.infogen.hdfs.InfoGen_LZOOutputStream -32080 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/9/1.4590678-
[framework] 2015-12-16 16:44:43,885 - org.apache.hadoop.io.compress.CodecPool -32133 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:44,143 - com.infogen.hdfs.InfoGen_LZOOutputStream -32391 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/10/1.4591359-
[framework] 2015-12-16 16:44:44,211 - org.apache.hadoop.io.compress.CodecPool -32459 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:44,490 - com.infogen.hdfs.InfoGen_LZOOutputStream -32738 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/11/1.4592199-
[framework] 2015-12-16 16:44:44,585 - org.apache.hadoop.io.compress.CodecPool -32833 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:46,967 - com.infogen.hdfs.InfoGen_LZOOutputStream -35215 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/12/1.4598713-
[framework] 2015-12-16 16:44:47,073 - org.apache.hadoop.io.compress.CodecPool -35321 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:49,897 - com.infogen.hdfs.InfoGen_LZOOutputStream -38145 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/13/1.4607103-
[framework] 2015-12-16 16:44:49,967 - org.apache.hadoop.io.compress.CodecPool -38215 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:50,014 - com.infogen.hdfs.InfoGen_LZOOutputStream -38262 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/14/1.4607328-
[framework] 2015-12-16 16:44:50,109 - org.apache.hadoop.io.compress.CodecPool -38357 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:50,928 - com.infogen.hdfs.InfoGen_LZOOutputStream -39176 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/15/1.4609030-
[framework] 2015-12-16 16:44:50,992 - org.apache.hadoop.io.compress.CodecPool -39240 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:51,731 - com.infogen.hdfs.InfoGen_LZOOutputStream -39979 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/16/1.4610729-
[framework] 2015-12-16 16:44:51,793 - org.apache.hadoop.io.compress.CodecPool -40041 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:52,227 - com.infogen.hdfs.InfoGen_LZOOutputStream -40475 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/17/1.4612066-
[framework] 2015-12-16 16:44:52,292 - org.apache.hadoop.io.compress.CodecPool -40540 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:53,709 - com.infogen.hdfs.InfoGen_LZOOutputStream -41957 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/18/1.4615863-
[framework] 2015-12-16 16:44:53,802 - org.apache.hadoop.io.compress.CodecPool -42050 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:54,393 - com.infogen.hdfs.InfoGen_LZOOutputStream -42641 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/19/1.4617020-
[framework] 2015-12-16 16:44:54,458 - org.apache.hadoop.io.compress.CodecPool -42706 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:54,743 - com.infogen.hdfs.InfoGen_LZOOutputStream -42991 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/20/1.4617965-
[framework] 2015-12-16 16:44:54,833 - org.apache.hadoop.io.compress.CodecPool -43081 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:55,723 - com.infogen.hdfs.InfoGen_LZOOutputStream -43971 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/21/1.4620188-
[framework] 2015-12-16 16:44:55,774 - org.apache.hadoop.io.compress.CodecPool -44022 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:56,261 - com.infogen.hdfs.InfoGen_LZOOutputStream -44509 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/22/1.4620689-
[framework] 2015-12-16 16:44:56,324 - org.apache.hadoop.io.compress.CodecPool -44572 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:56,462 - com.infogen.hdfs.InfoGen_LZOOutputStream -44710 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/23/1.4620773-
[framework] 2015-12-16 16:44:56,540 - org.apache.hadoop.io.compress.CodecPool -44788 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:56,598 - com.infogen.hdfs.InfoGen_LZOOutputStream -44846 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/0/1.4620850-
[framework] 2015-12-16 16:44:56,657 - org.apache.hadoop.io.compress.CodecPool -44905 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:56,705 - com.infogen.hdfs.InfoGen_LZOOutputStream -44953 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/1/1.4620930-
[framework] 2015-12-16 16:44:56,790 - org.apache.hadoop.io.compress.CodecPool -45038 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:56,832 - com.infogen.hdfs.InfoGen_LZOOutputStream -45080 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/2/1.4621001-
[framework] 2015-12-16 16:44:56,907 - org.apache.hadoop.io.compress.CodecPool -45155 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:57,083 - com.infogen.hdfs.InfoGen_LZOOutputStream -45331 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/3/1.4621084-
[framework] 2015-12-16 16:44:57,149 - org.apache.hadoop.io.compress.CodecPool -45397 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:57,193 - com.infogen.hdfs.InfoGen_LZOOutputStream -45441 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/4/1.4621160-
[framework] 2015-12-16 16:44:57,257 - org.apache.hadoop.io.compress.CodecPool -45505 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:57,322 - com.infogen.hdfs.InfoGen_LZOOutputStream -45570 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/5/1.4621228-
[framework] 2015-12-16 16:44:57,381 - org.apache.hadoop.io.compress.CodecPool -45629 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:57,435 - com.infogen.hdfs.InfoGen_LZOOutputStream -45683 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/6/1.4621302-
[framework] 2015-12-16 16:44:57,515 - org.apache.hadoop.io.compress.CodecPool -45763 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:57,555 - com.infogen.hdfs.InfoGen_LZOOutputStream -45803 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/7/1.4621368-
[framework] 2015-12-16 16:44:57,640 - org.apache.hadoop.io.compress.CodecPool -45888 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:57,789 - com.infogen.hdfs.InfoGen_LZOOutputStream -46037 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/8/1.4621464-
[framework] 2015-12-16 16:44:57,915 - org.apache.hadoop.io.compress.CodecPool -46163 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:57,962 - com.infogen.hdfs.InfoGen_LZOOutputStream -46210 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/9/1.4621530-
[framework] 2015-12-16 16:44:58,148 - org.apache.hadoop.io.compress.CodecPool -46396 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:58,327 - com.infogen.hdfs.InfoGen_LZOOutputStream -46575 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/10/1.4622142-
[framework] 2015-12-16 16:44:58,417 - org.apache.hadoop.io.compress.CodecPool -46665 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:58,914 - com.infogen.hdfs.InfoGen_LZOOutputStream -47162 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/11/1.4624106-
[framework] 2015-12-16 16:44:58,985 - org.apache.hadoop.io.compress.CodecPool -47233 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:59,568 - com.infogen.hdfs.InfoGen_LZOOutputStream -47816 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/12/1.4624990-
[framework] 2015-12-16 16:44:59,648 - org.apache.hadoop.io.compress.CodecPool -47896 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:59,705 - com.infogen.hdfs.InfoGen_LZOOutputStream -47953 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/13/1.4625234-
[framework] 2015-12-16 16:44:59,781 - org.apache.hadoop.io.compress.CodecPool -48029 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:44:59,970 - com.infogen.hdfs.InfoGen_LZOOutputStream -48218 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/14/1.4625383-
[framework] 2015-12-16 16:45:00,047 - org.apache.hadoop.io.compress.CodecPool -48295 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:00,374 - com.infogen.hdfs.InfoGen_LZOOutputStream -48622 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/15/1.4626461-
[framework] 2015-12-16 16:45:00,457 - org.apache.hadoop.io.compress.CodecPool -48705 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:00,688 - com.infogen.hdfs.InfoGen_LZOOutputStream -48936 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/16/1.4627515-
[framework] 2015-12-16 16:45:00,739 - org.apache.hadoop.io.compress.CodecPool -48987 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:01,439 - com.infogen.hdfs.InfoGen_LZOOutputStream -49687 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/17/1.4631070-
[framework] 2015-12-16 16:45:01,495 - org.apache.hadoop.io.compress.CodecPool -49743 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:02,148 - com.infogen.hdfs.InfoGen_LZOOutputStream -50396 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/18/1.4633530-
[framework] 2015-12-16 16:45:02,214 - org.apache.hadoop.io.compress.CodecPool -50462 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:02,471 - com.infogen.hdfs.InfoGen_LZOOutputStream -50719 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/19/1.4634378-
[framework] 2015-12-16 16:45:02,546 - org.apache.hadoop.io.compress.CodecPool -50794 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:02,762 - com.infogen.hdfs.InfoGen_LZOOutputStream -51010 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/20/1.4635058-
[framework] 2015-12-16 16:45:02,980 - org.apache.hadoop.io.compress.CodecPool -51228 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:03,429 - com.infogen.hdfs.InfoGen_LZOOutputStream -51677 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/21/1.4636481-
[framework] 2015-12-16 16:45:03,488 - org.apache.hadoop.io.compress.CodecPool -51736 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:03,528 - com.infogen.hdfs.InfoGen_LZOOutputStream -51776 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/22/1.4636584-
[framework] 2015-12-16 16:45:03,596 - org.apache.hadoop.io.compress.CodecPool -51844 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:03,637 - com.infogen.hdfs.InfoGen_LZOOutputStream -51885 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/23/1.4636707-
[framework] 2015-12-16 16:45:03,712 - org.apache.hadoop.io.compress.CodecPool -51960 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:03,842 - com.infogen.hdfs.InfoGen_LZOOutputStream -52090 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/0/1.4636869-
[framework] 2015-12-16 16:45:03,939 - org.apache.hadoop.io.compress.CodecPool -52187 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:03,992 - com.infogen.hdfs.InfoGen_LZOOutputStream -52240 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/1/1.4636979-
[framework] 2015-12-16 16:45:04,079 - org.apache.hadoop.io.compress.CodecPool -52327 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:04,129 - com.infogen.hdfs.InfoGen_LZOOutputStream -52377 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/2/1.4637102-
[framework] 2015-12-16 16:45:04,212 - org.apache.hadoop.io.compress.CodecPool -52460 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:04,341 - com.infogen.hdfs.InfoGen_LZOOutputStream -52589 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/3/1.4637195-
[framework] 2015-12-16 16:45:04,420 - org.apache.hadoop.io.compress.CodecPool -52668 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:04,469 - com.infogen.hdfs.InfoGen_LZOOutputStream -52717 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/4/1.4637295-
[framework] 2015-12-16 16:45:04,538 - org.apache.hadoop.io.compress.CodecPool -52786 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:04,610 - com.infogen.hdfs.InfoGen_LZOOutputStream -52858 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/5/1.4637403-
[framework] 2015-12-16 16:45:04,705 - org.apache.hadoop.io.compress.CodecPool -52953 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:04,751 - com.infogen.hdfs.InfoGen_LZOOutputStream -52999 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/6/1.4637515-
[framework] 2015-12-16 16:45:04,845 - org.apache.hadoop.io.compress.CodecPool -53093 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:05,027 - com.infogen.hdfs.InfoGen_LZOOutputStream -53275 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/7/1.4637620-
[framework] 2015-12-16 16:45:05,128 - org.apache.hadoop.io.compress.CodecPool -53376 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:05,190 - com.infogen.hdfs.InfoGen_LZOOutputStream -53438 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/8/1.4637739-
[framework] 2015-12-16 16:45:05,280 - org.apache.hadoop.io.compress.CodecPool -53528 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:05,332 - com.infogen.hdfs.InfoGen_LZOOutputStream -53580 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/9/1.4637835-
[framework] 2015-12-16 16:45:05,413 - org.apache.hadoop.io.compress.CodecPool -53661 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:06,122 - com.infogen.hdfs.InfoGen_LZOOutputStream -54370 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/10/1.4640398-
[framework] 2015-12-16 16:45:06,210 - org.apache.hadoop.io.compress.CodecPool -54458 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:06,475 - com.infogen.hdfs.InfoGen_LZOOutputStream -54723 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/11/1.4641508-
[framework] 2015-12-16 16:45:06,618 - org.apache.hadoop.io.compress.CodecPool -54866 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:06,876 - com.infogen.hdfs.InfoGen_LZOOutputStream -55124 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/12/1.4642517-
[framework] 2015-12-16 16:45:06,992 - org.apache.hadoop.io.compress.CodecPool -55240 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:07,104 - com.infogen.hdfs.InfoGen_LZOOutputStream -55352 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/13/1.4642993-
[framework] 2015-12-16 16:45:07,217 - org.apache.hadoop.io.compress.CodecPool -55465 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:07,326 - com.infogen.hdfs.InfoGen_LZOOutputStream -55574 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/14/1.4643091-
[framework] 2015-12-16 16:45:07,425 - org.apache.hadoop.io.compress.CodecPool -55673 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:07,602 - com.infogen.hdfs.InfoGen_LZOOutputStream -55850 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/15/1.4643976-
[framework] 2015-12-16 16:45:07,676 - org.apache.hadoop.io.compress.CodecPool -55924 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:07,987 - com.infogen.hdfs.InfoGen_LZOOutputStream -56235 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/16/1.4645519-
[framework] 2015-12-16 16:45:08,176 - org.apache.hadoop.io.compress.CodecPool -56424 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:08,387 - com.infogen.hdfs.InfoGen_LZOOutputStream -56635 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/17/1.4646424-
[framework] 2015-12-16 16:45:08,574 - org.apache.hadoop.io.compress.CodecPool -56822 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:08,762 - com.infogen.hdfs.InfoGen_LZOOutputStream -57010 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/18/1.4647149-
[framework] 2015-12-16 16:45:08,951 - org.apache.hadoop.io.compress.CodecPool -57199 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:09,097 - com.infogen.hdfs.InfoGen_LZOOutputStream -57345 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/19/1.4647631-
[framework] 2015-12-16 16:45:09,358 - org.apache.hadoop.io.compress.CodecPool -57606 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:09,471 - com.infogen.hdfs.InfoGen_LZOOutputStream -57719 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/20/1.4647912-
[framework] 2015-12-16 16:45:09,552 - org.apache.hadoop.io.compress.CodecPool -57800 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:09,645 - com.infogen.hdfs.InfoGen_LZOOutputStream -57893 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/21/1.4648250-
[framework] 2015-12-16 16:45:09,751 - org.apache.hadoop.io.compress.CodecPool -57999 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:09,797 - com.infogen.hdfs.InfoGen_LZOOutputStream -58045 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/22/1.4648375-
[framework] 2015-12-16 16:45:09,966 - org.apache.hadoop.io.compress.CodecPool -58214 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:10,105 - com.infogen.hdfs.InfoGen_LZOOutputStream -58353 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/23/1.4648473-
[framework] 2015-12-16 16:45:10,291 - org.apache.hadoop.io.compress.CodecPool -58539 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:10,348 - com.infogen.hdfs.InfoGen_LZOOutputStream -58596 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/0/1.4648564-
[framework] 2015-12-16 16:45:10,474 - org.apache.hadoop.io.compress.CodecPool -58722 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:10,767 - com.infogen.hdfs.InfoGen_LZOOutputStream -59015 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/1/1.4648686-
[framework] 2015-12-16 16:45:11,135 - org.apache.hadoop.io.compress.CodecPool -59383 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:11,293 - com.infogen.hdfs.InfoGen_LZOOutputStream -59541 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/2/1.4648924-
[framework] 2015-12-16 16:45:11,490 - org.apache.hadoop.io.compress.CodecPool -59738 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:11,538 - com.infogen.hdfs.InfoGen_LZOOutputStream -59786 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/3/1.4649026-
[framework] 2015-12-16 16:45:11,700 - org.apache.hadoop.io.compress.CodecPool -59948 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:11,820 - com.infogen.hdfs.InfoGen_LZOOutputStream -60068 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/4/1.4649144-
[framework] 2015-12-16 16:45:11,911 - org.apache.hadoop.io.compress.CodecPool -60159 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:11,951 - com.infogen.hdfs.InfoGen_LZOOutputStream -60199 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/5/1.4649235-
[framework] 2015-12-16 16:45:12,059 - org.apache.hadoop.io.compress.CodecPool -60307 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:12,109 - com.infogen.hdfs.InfoGen_LZOOutputStream -60357 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/6/1.4649318-
[framework] 2015-12-16 16:45:12,185 - org.apache.hadoop.io.compress.CodecPool -60433 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:12,226 - com.infogen.hdfs.InfoGen_LZOOutputStream -60474 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/7/1.4649417-
[framework] 2015-12-16 16:45:12,358 - org.apache.hadoop.io.compress.CodecPool -60606 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:12,506 - com.infogen.hdfs.InfoGen_LZOOutputStream -60754 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/8/1.4649531-
[framework] 2015-12-16 16:45:12,584 - org.apache.hadoop.io.compress.CodecPool -60832 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:12,642 - com.infogen.hdfs.InfoGen_LZOOutputStream -60890 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/9/1.4649642-
[framework] 2015-12-16 16:45:12,716 - org.apache.hadoop.io.compress.CodecPool -60964 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:12,758 - com.infogen.hdfs.InfoGen_LZOOutputStream -61006 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/10/1.4649819-
[framework] 2015-12-16 16:45:12,929 - org.apache.hadoop.io.compress.CodecPool -61177 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:13,057 - com.infogen.hdfs.InfoGen_LZOOutputStream -61305 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/11/1.4649948-
[framework] 2015-12-16 16:45:13,116 - com.infogen.hdfs.InfoGen_LZOOutputStream -61364 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/20/1.4558218-
[framework] 2015-12-16 16:45:13,245 - com.infogen.hdfs.InfoGen_LZOOutputStream -61493 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/12/1.4650386-
[framework] 2015-12-16 16:45:13,342 - org.apache.hadoop.io.compress.CodecPool -61590 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:13,392 - com.infogen.hdfs.InfoGen_LZOOutputStream -61640 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/13/1.4650487-
[framework] 2015-12-16 16:45:13,483 - org.apache.hadoop.io.compress.CodecPool -61731 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:13,650 - com.infogen.hdfs.InfoGen_LZOOutputStream -61898 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/14/1.4650934-
[framework] 2015-12-16 16:45:13,750 - org.apache.hadoop.io.compress.CodecPool -61998 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:13,851 - com.infogen.hdfs.InfoGen_LZOOutputStream -62099 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/15/1.4651463-
[framework] 2015-12-16 16:45:13,937 - org.apache.hadoop.io.compress.CodecPool -62185 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:14,118 - com.infogen.hdfs.InfoGen_LZOOutputStream -62366 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/16/1.4651929-
[framework] 2015-12-16 16:45:14,200 - org.apache.hadoop.io.compress.CodecPool -62448 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:14,307 - com.infogen.hdfs.InfoGen_LZOOutputStream -62555 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/17/1.4652404-
[framework] 2015-12-16 16:45:14,384 - org.apache.hadoop.io.compress.CodecPool -62632 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:14,496 - com.infogen.hdfs.InfoGen_LZOOutputStream -62744 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/18/1.4652890-
[framework] 2015-12-16 16:45:14,592 - org.apache.hadoop.io.compress.CodecPool -62840 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:14,754 - com.infogen.hdfs.InfoGen_LZOOutputStream -63002 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/19/1.4653352-
[framework] 2015-12-16 16:45:14,849 - com.infogen.hdfs.InfoGen_LZOOutputStream -63097 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/21/1.4558448-
[framework] 2015-12-16 16:45:15,026 - com.infogen.hdfs.InfoGen_LZOOutputStream -63274 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/20/1.4653823-
[framework] 2015-12-16 16:45:15,144 - org.apache.hadoop.io.compress.CodecPool -63392 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:15,520 - com.infogen.hdfs.InfoGen_LZOOutputStream -63768 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/21/1.4654280-
[framework] 2015-12-16 16:45:15,610 - org.apache.hadoop.io.compress.CodecPool -63858 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:15,878 - com.infogen.hdfs.InfoGen_LZOOutputStream -64126 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/22/1.4654706-
[framework] 2015-12-16 16:45:15,962 - org.apache.hadoop.io.compress.CodecPool -64210 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:16,013 - com.infogen.hdfs.InfoGen_LZOOutputStream -64261 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/22/1.4558529-
[framework] 2015-12-16 16:45:16,351 - com.infogen.hdfs.InfoGen_LZOOutputStream -64599 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/23/1.4655178-
[framework] 2015-12-16 16:45:16,951 - com.infogen.hdfs.InfoGen_LZOOutputStream -65199 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/0/1.4655637-
[framework] 2015-12-16 16:45:17,123 - com.infogen.hdfs.InfoGen_LZOOutputStream -65371 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-4/23/1.4558604-
[framework] 2015-12-16 16:45:17,386 - com.infogen.hdfs.InfoGen_LZOOutputStream -65634 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/1/1.4656126-
[framework] 2015-12-16 16:45:17,551 - org.apache.hadoop.io.compress.CodecPool -65799 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:17,656 - com.infogen.hdfs.InfoGen_LZOOutputStream -65904 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/2/1.4656585-
[framework] 2015-12-16 16:45:17,682 - com.infogen.hdfs.InfoGen_LZOOutputStream -65930 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/0/1.4558667-
[framework] 2015-12-16 16:45:17,886 - com.infogen.hdfs.InfoGen_LZOOutputStream -66134 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/3/1.4657052-
[framework] 2015-12-16 16:45:18,189 - org.apache.hadoop.io.compress.CodecPool -66437 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:18,273 - com.infogen.hdfs.InfoGen_LZOOutputStream -66521 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/1/1.4558742-
[framework] 2015-12-16 16:45:18,340 - com.infogen.hdfs.InfoGen_LZOOutputStream -66588 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/4/1.4657528-
[framework] 2015-12-16 16:45:18,527 - com.infogen.hdfs.InfoGen_LZOOutputStream -66775 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/5/1.4657998-
[framework] 2015-12-16 16:45:18,775 - org.apache.hadoop.io.compress.CodecPool -67023 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:18,848 - com.infogen.hdfs.InfoGen_LZOOutputStream -67096 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/2/1.4558820-
[framework] 2015-12-16 16:45:18,878 - com.infogen.hdfs.InfoGen_LZOOutputStream -67126 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/6/1.4658458-
[framework] 2015-12-16 16:45:19,085 - com.infogen.hdfs.InfoGen_LZOOutputStream -67333 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/7/1.4658906-
[framework] 2015-12-16 16:45:19,173 - org.apache.hadoop.io.compress.CodecPool -67421 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:19,271 - com.infogen.hdfs.InfoGen_LZOOutputStream -67519 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/8/1.4659342-
[framework] 2015-12-16 16:45:19,281 - com.infogen.hdfs.InfoGen_LZOOutputStream -67529 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/3/1.4558896-
[framework] 2015-12-16 16:45:19,468 - com.infogen.hdfs.InfoGen_LZOOutputStream -67716 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/9/1.4659780-
[framework] 2015-12-16 16:45:19,690 - org.apache.hadoop.io.compress.CodecPool -67938 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:19,794 - com.infogen.hdfs.InfoGen_LZOOutputStream -68042 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/10/1.4660189-
[framework] 2015-12-16 16:45:19,906 - com.infogen.hdfs.InfoGen_LZOOutputStream -68154 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/4/1.4558975-
[framework] 2015-12-16 16:45:20,108 - com.infogen.hdfs.InfoGen_LZOOutputStream -68356 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/11/1.4660643-
[framework] 2015-12-16 16:45:20,350 - org.apache.hadoop.io.compress.CodecPool -68598 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:20,454 - com.infogen.hdfs.InfoGen_LZOOutputStream -68702 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/12/1.4661127-
[framework] 2015-12-16 16:45:20,707 - org.apache.hadoop.io.compress.CodecPool -68955 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:20,722 - com.infogen.hdfs.InfoGen_LZOOutputStream -68970 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/5/1.4559038-
[framework] 2015-12-16 16:45:20,827 - com.infogen.hdfs.InfoGen_LZOOutputStream -69075 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/13/1.4661583-
[framework] 2015-12-16 16:45:21,092 - com.infogen.hdfs.InfoGen_LZOOutputStream -69340 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/14/1.4662035-
[framework] 2015-12-16 16:45:21,353 - org.apache.hadoop.io.compress.CodecPool -69601 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:21,498 - com.infogen.hdfs.InfoGen_LZOOutputStream -69746 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/15/1.4662497-
[framework] 2015-12-16 16:45:21,700 - org.apache.hadoop.io.compress.CodecPool -69948 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:21,725 - com.infogen.hdfs.InfoGen_LZOOutputStream -69973 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/6/1.4559105-
[framework] 2015-12-16 16:45:21,901 - com.infogen.hdfs.InfoGen_LZOOutputStream -70149 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/16/1.4662984-
[framework] 2015-12-16 16:45:22,559 - com.infogen.hdfs.InfoGen_LZOOutputStream -70807 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/7/1.4559182-
[framework] 2015-12-16 16:45:22,658 - com.infogen.hdfs.InfoGen_LZOOutputStream -70906 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/17/1.4663432-
[framework] 2015-12-16 16:45:22,987 - com.infogen.hdfs.InfoGen_LZOOutputStream -71235 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/18/1.4663907-
[framework] 2015-12-16 16:45:22,997 - com.infogen.hdfs.InfoGen_LZOOutputStream -71245 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/8/1.4559701-
[framework] 2015-12-16 16:45:23,346 - com.infogen.hdfs.InfoGen_LZOOutputStream -71594 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/19/1.4664383-
[framework] 2015-12-16 16:45:23,498 - org.apache.hadoop.io.compress.CodecPool -71746 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:23,555 - com.infogen.hdfs.InfoGen_LZOOutputStream -71803 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/9/1.4559777-
[framework] 2015-12-16 16:45:23,823 - com.infogen.hdfs.InfoGen_LZOOutputStream -72071 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/20/1.4664841-
[framework] 2015-12-16 16:45:24,119 - com.infogen.hdfs.InfoGen_LZOOutputStream -72367 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/10/1.4559842-
[framework] 2015-12-16 16:45:24,260 - com.infogen.hdfs.InfoGen_LZOOutputStream -72508 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/21/1.4665351-
[framework] 2015-12-16 16:45:25,373 - com.infogen.hdfs.InfoGen_LZOOutputStream -73621 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/22/1.4665807-
[framework] 2015-12-16 16:45:25,573 - org.apache.hadoop.io.compress.CodecPool -73821 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:25,755 - com.infogen.hdfs.InfoGen_LZOOutputStream -74003 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/11/1.4559923-
[framework] 2015-12-16 16:45:25,823 - com.infogen.hdfs.InfoGen_LZOOutputStream -74071 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/23/1.4666298-
[framework] 2015-12-16 16:45:26,232 - com.infogen.hdfs.InfoGen_LZOOutputStream -74480 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/0/1.4666804-
[framework] 2015-12-16 16:45:26,547 - org.apache.hadoop.io.compress.CodecPool -74795 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:26,596 - com.infogen.hdfs.InfoGen_LZOOutputStream -74844 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/12/1.4560005-
[framework] 2015-12-16 16:45:27,029 - com.infogen.hdfs.InfoGen_LZOOutputStream -75277 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/1/1.4666925-
[framework] 2015-12-16 16:45:27,142 - com.infogen.hdfs.InfoGen_LZOOutputStream -75390 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/13/1.4560078-
[framework] 2015-12-16 16:45:27,222 - com.infogen.hdfs.InfoGen_LZOOutputStream -75470 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/2/1.4667039-
[framework] 2015-12-16 16:45:27,661 - com.infogen.hdfs.InfoGen_LZOOutputStream -75909 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/3/1.4667142-
[framework] 2015-12-16 16:45:27,847 - org.apache.hadoop.io.compress.CodecPool -76095 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:27,899 - com.infogen.hdfs.InfoGen_LZOOutputStream -76147 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/4/1.4667238-
[framework] 2015-12-16 16:45:28,000 - com.infogen.hdfs.InfoGen_LZOOutputStream -76248 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/14/1.4560147-
[framework] 2015-12-16 16:45:28,312 - com.infogen.hdfs.InfoGen_LZOOutputStream -76560 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/5/1.4667349-
[framework] 2015-12-16 16:45:28,416 - org.apache.hadoop.io.compress.CodecPool -76664 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:28,461 - com.infogen.hdfs.InfoGen_LZOOutputStream -76709 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/6/1.4667455-
[framework] 2015-12-16 16:45:28,546 - org.apache.hadoop.io.compress.CodecPool -76794 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:28,588 - com.infogen.hdfs.InfoGen_LZOOutputStream -76836 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/7/1.4667561-
[framework] 2015-12-16 16:45:28,780 - org.apache.hadoop.io.compress.CodecPool -77028 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:28,939 - com.infogen.hdfs.InfoGen_LZOOutputStream -77187 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/8/1.4667656-
[framework] 2015-12-16 16:45:29,122 - org.apache.hadoop.io.compress.CodecPool -77370 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:29,168 - com.infogen.hdfs.InfoGen_LZOOutputStream -77416 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/9/1.4667779-
[framework] 2015-12-16 16:45:29,305 - org.apache.hadoop.io.compress.CodecPool -77553 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:29,452 - com.infogen.hdfs.InfoGen_LZOOutputStream -77700 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/10/1.4668127-
[framework] 2015-12-16 16:45:29,755 - org.apache.hadoop.io.compress.CodecPool -78003 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:29,779 - com.infogen.hdfs.InfoGen_LZOOutputStream -78027 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/15/1.4560571-
[framework] 2015-12-16 16:45:30,153 - com.infogen.hdfs.InfoGen_LZOOutputStream -78401 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/11/1.4669620-
[framework] 2015-12-16 16:45:30,762 - com.infogen.hdfs.InfoGen_LZOOutputStream -79010 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/16/1.4560776-
[framework] 2015-12-16 16:45:31,082 - com.infogen.hdfs.InfoGen_LZOOutputStream -79330 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/12/1.4670920-
[framework] 2015-12-16 16:45:31,254 - com.infogen.hdfs.InfoGen_LZOOutputStream -79502 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/17/1.4560972-
[framework] 2015-12-16 16:45:31,294 - com.infogen.hdfs.InfoGen_LZOOutputStream -79542 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/13/1.4671122-
[framework] 2015-12-16 16:45:31,429 - com.infogen.hdfs.InfoGen_LZOOutputStream -79677 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/14/1.4671387-
[framework] 2015-12-16 16:45:31,588 - org.apache.hadoop.io.compress.CodecPool -79836 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:31,778 - com.infogen.hdfs.InfoGen_LZOOutputStream -80026 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/18/1.4561528-
[framework] 2015-12-16 16:45:31,951 - com.infogen.hdfs.InfoGen_LZOOutputStream -80199 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/15/1.4672445-
[framework] 2015-12-16 16:45:32,361 - com.infogen.hdfs.InfoGen_LZOOutputStream -80609 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/19/1.4561634-
[framework] 2015-12-16 16:45:32,409 - com.infogen.hdfs.InfoGen_LZOOutputStream -80657 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/16/1.4673373-
[framework] 2015-12-16 16:45:32,889 - com.infogen.hdfs.InfoGen_LZOOutputStream -81137 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/1.4674986-
[framework] 2015-12-16 16:45:33,070 - com.infogen.hdfs.InfoGen_LZOOutputStream -81318 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/20/1.4561854-
[framework] 2015-12-16 16:45:33,960 - com.infogen.hdfs.InfoGen_LZOOutputStream -82208 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/18/1.4676179-
[framework] 2015-12-16 16:45:34,078 - org.apache.hadoop.io.compress.CodecPool -82326 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:34,203 - com.infogen.hdfs.InfoGen_LZOOutputStream -82451 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/19/1.4676845-
[framework] 2015-12-16 16:45:34,311 - com.infogen.hdfs.InfoGen_LZOOutputStream -82559 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/21/1.4561920-
[framework] 2015-12-16 16:45:34,515 - com.infogen.hdfs.InfoGen_LZOOutputStream -82763 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/20/1.4677290-
[framework] 2015-12-16 16:45:34,653 - org.apache.hadoop.io.compress.CodecPool -82901 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:34,699 - com.infogen.hdfs.InfoGen_LZOOutputStream -82947 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/21/1.4677307-
[framework] 2015-12-16 16:45:34,806 - com.infogen.hdfs.InfoGen_LZOOutputStream -83054 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/22/1.4561999-
[framework] 2015-12-16 16:45:34,888 - com.infogen.hdfs.InfoGen_LZOOutputStream -83136 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/22/1.4677326-
[framework] 2015-12-16 16:45:35,012 - org.apache.hadoop.io.compress.CodecPool -83260 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:35,055 - com.infogen.hdfs.InfoGen_LZOOutputStream -83303 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/23/1.4677341-
[framework] 2015-12-16 16:45:35,145 - org.apache.hadoop.io.compress.CodecPool -83393 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:35,187 - com.infogen.hdfs.InfoGen_LZOOutputStream -83435 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/0/1.4677357-
[framework] 2015-12-16 16:45:35,285 - com.infogen.hdfs.InfoGen_LZOOutputStream -83533 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-5/23/1.4562073-
[framework] 2015-12-16 16:45:35,365 - com.infogen.hdfs.InfoGen_LZOOutputStream -83613 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/1/1.4677368-
[framework] 2015-12-16 16:45:35,445 - org.apache.hadoop.io.compress.CodecPool -83693 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:35,556 - com.infogen.hdfs.InfoGen_LZOOutputStream -83804 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/2/1.4677381-
[framework] 2015-12-16 16:45:35,686 - org.apache.hadoop.io.compress.CodecPool -83934 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:35,732 - com.infogen.hdfs.InfoGen_LZOOutputStream -83980 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/3/1.4677382-
[framework] 2015-12-16 16:45:35,835 - com.infogen.hdfs.InfoGen_LZOOutputStream -84083 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/0/1.4562158-
[framework] 2015-12-16 16:45:35,940 - com.infogen.hdfs.InfoGen_LZOOutputStream -84188 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/4/1.4677384-
[framework] 2015-12-16 16:45:36,028 - org.apache.hadoop.io.compress.CodecPool -84276 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:36,069 - com.infogen.hdfs.InfoGen_LZOOutputStream -84317 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/5/1.4677388-
[framework] 2015-12-16 16:45:36,179 - org.apache.hadoop.io.compress.CodecPool -84427 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:36,229 - com.infogen.hdfs.InfoGen_LZOOutputStream -84477 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/6/1.4677391-
[framework] 2015-12-16 16:45:36,319 - com.infogen.hdfs.InfoGen_LZOOutputStream -84567 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/1/1.4562250-
[framework] 2015-12-16 16:45:36,393 - com.infogen.hdfs.InfoGen_LZOOutputStream -84641 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/7/1.4677399-
[framework] 2015-12-16 16:45:36,495 - org.apache.hadoop.io.compress.CodecPool -84743 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:36,881 - com.infogen.hdfs.InfoGen_LZOOutputStream -85129 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/2/1.4562325-
[framework] 2015-12-16 16:45:37,452 - com.infogen.hdfs.InfoGen_LZOOutputStream -85700 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/3/1.4562405-
[framework] 2015-12-16 16:45:37,893 - com.infogen.hdfs.InfoGen_LZOOutputStream -86141 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/4/1.4562471-
[framework] 2015-12-16 16:45:38,459 - com.infogen.hdfs.InfoGen_LZOOutputStream -86707 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/5/1.4562537-
[framework] 2015-12-16 16:45:40,530 - com.infogen.hdfs.InfoGen_LZOOutputStream -88778 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/6/1.4562607-
[framework] 2015-12-16 16:45:40,881 - com.infogen.hdfs.InfoGen_LZOOutputStream -89129 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/8/1.4696450-
[framework] 2015-12-16 16:45:41,037 - com.infogen.hdfs.InfoGen_LZOOutputStream -89285 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/9/1.4696461-
[framework] 2015-12-16 16:45:41,145 - com.infogen.hdfs.InfoGen_LZOOutputStream -89393 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/7/1.4562675-
[framework] 2015-12-16 16:45:41,285 - com.infogen.hdfs.InfoGen_LZOOutputStream -89533 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/10/1.4696706-
[framework] 2015-12-16 16:45:41,633 - com.infogen.hdfs.InfoGen_LZOOutputStream -89881 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/11/1.4697276-
[framework] 2015-12-16 16:45:41,751 - com.infogen.hdfs.InfoGen_LZOOutputStream -89999 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/8/1.4563235-
[framework] 2015-12-16 16:45:41,960 - com.infogen.hdfs.InfoGen_LZOOutputStream -90208 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/12/1.4697778-
[framework] 2015-12-16 16:45:42,100 - com.infogen.hdfs.InfoGen_LZOOutputStream -90348 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/13/1.4697788-
[framework] 2015-12-16 16:45:42,794 - com.infogen.hdfs.InfoGen_LZOOutputStream -91042 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/9/1.4563304-
[framework] 2015-12-16 16:45:42,808 - com.infogen.hdfs.InfoGen_LZOOutputStream -91056 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/14/1.4697852-
[framework] 2015-12-16 16:45:43,279 - com.infogen.hdfs.InfoGen_LZOOutputStream -91527 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/15/1.4698772-
[framework] 2015-12-16 16:45:43,395 - com.infogen.hdfs.InfoGen_LZOOutputStream -91643 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/10/1.4563390-
[framework] 2015-12-16 16:45:43,635 - com.infogen.hdfs.InfoGen_LZOOutputStream -91883 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/16/1.4699134-
[framework] 2015-12-16 16:45:43,952 - com.infogen.hdfs.InfoGen_LZOOutputStream -92200 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/17/1.4699701-
[framework] 2015-12-16 16:45:44,117 - org.apache.hadoop.io.compress.CodecPool -92365 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:44,242 - com.infogen.hdfs.InfoGen_LZOOutputStream -92490 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/11/1.4563505-
[framework] 2015-12-16 16:45:44,337 - com.infogen.hdfs.InfoGen_LZOOutputStream -92585 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/18/1.4700757-
[framework] 2015-12-16 16:45:44,551 - com.infogen.hdfs.InfoGen_LZOOutputStream -92799 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/19/1.4700822-
[framework] 2015-12-16 16:45:44,701 - org.apache.hadoop.io.compress.CodecPool -92949 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:44,745 - com.infogen.hdfs.InfoGen_LZOOutputStream -92993 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/20/1.4700869-
[framework] 2015-12-16 16:45:44,917 - com.infogen.hdfs.InfoGen_LZOOutputStream -93165 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/12/1.4563580-
[framework] 2015-12-16 16:45:45,077 - com.infogen.hdfs.InfoGen_LZOOutputStream -93325 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/21/1.4701062-
[framework] 2015-12-16 16:45:45,217 - org.apache.hadoop.io.compress.CodecPool -93465 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:45,310 - com.infogen.hdfs.InfoGen_LZOOutputStream -93558 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/22/1.4701299-
[framework] 2015-12-16 16:45:45,467 - com.infogen.hdfs.InfoGen_LZOOutputStream -93715 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/13/1.4563650-
[framework] 2015-12-16 16:45:45,575 - com.infogen.hdfs.InfoGen_LZOOutputStream -93823 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/23/1.4701320-
[framework] 2015-12-16 16:45:45,669 - org.apache.hadoop.io.compress.CodecPool -93917 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:45,711 - com.infogen.hdfs.InfoGen_LZOOutputStream -93959 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/0/1.4701342-
[framework] 2015-12-16 16:45:46,037 - org.apache.hadoop.io.compress.CodecPool -94285 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:46,099 - com.infogen.hdfs.InfoGen_LZOOutputStream -94347 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/1/1.4701376-
[framework] 2015-12-16 16:45:46,200 - org.apache.hadoop.io.compress.CodecPool -94448 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:46,244 - com.infogen.hdfs.InfoGen_LZOOutputStream -94492 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/3/1.4701379-
[framework] 2015-12-16 16:45:46,334 - org.apache.hadoop.io.compress.CodecPool -94582 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:46,405 - com.infogen.hdfs.InfoGen_LZOOutputStream -94653 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/4/1.4701384-
[framework] 2015-12-16 16:45:46,525 - org.apache.hadoop.io.compress.CodecPool -94773 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:46,578 - com.infogen.hdfs.InfoGen_LZOOutputStream -94826 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/5/1.4701388-
[framework] 2015-12-16 16:45:46,649 - com.infogen.hdfs.InfoGen_LZOOutputStream -94897 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/14/1.4563727-
[framework] 2015-12-16 16:45:46,733 - com.infogen.hdfs.InfoGen_LZOOutputStream -94981 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/7/1.4701390-
[framework] 2015-12-16 16:45:46,825 - org.apache.hadoop.io.compress.CodecPool -95073 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:47,124 - com.infogen.hdfs.InfoGen_LZOOutputStream -95372 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/15/1.4563962-
[framework] 2015-12-16 16:45:47,565 - com.infogen.hdfs.InfoGen_LZOOutputStream -95813 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/16/1.4564183-
[framework] 2015-12-16 16:45:48,062 - com.infogen.hdfs.InfoGen_LZOOutputStream -96310 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/17/1.4564260-
[framework] 2015-12-16 16:45:48,831 - com.infogen.hdfs.InfoGen_LZOOutputStream -97079 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/18/1.4564337-
[framework] 2015-12-16 16:45:49,633 - com.infogen.hdfs.InfoGen_LZOOutputStream -97881 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/19/1.4564422-
[framework] 2015-12-16 16:45:50,379 - com.infogen.hdfs.InfoGen_LZOOutputStream -98627 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/8/1.4718588-
[framework] 2015-12-16 16:45:50,496 - com.infogen.hdfs.InfoGen_LZOOutputStream -98744 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/9/1.4718595-
[framework] 2015-12-16 16:45:50,809 - com.infogen.hdfs.InfoGen_LZOOutputStream -99057 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/10/1.4719035-
[framework] 2015-12-16 16:45:51,004 - com.infogen.hdfs.InfoGen_LZOOutputStream -99252 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/11/1.4719530-
[framework] 2015-12-16 16:45:51,239 - com.infogen.hdfs.InfoGen_LZOOutputStream -99487 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/12/1.4719752-
[framework] 2015-12-16 16:45:51,430 - com.infogen.hdfs.InfoGen_LZOOutputStream -99678 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/20/1.4564492-
[framework] 2015-12-16 16:45:51,456 - com.infogen.hdfs.InfoGen_LZOOutputStream -99704 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/13/1.4719857-
[framework] 2015-12-16 16:45:51,666 - com.infogen.hdfs.InfoGen_LZOOutputStream -99914 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/14/1.4719988-
[framework] 2015-12-16 16:45:51,731 - org.apache.hadoop.io.compress.CodecPool -99979 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:51,851 - com.infogen.hdfs.InfoGen_LZOOutputStream -100099 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/15/1.4720405-
[framework] 2015-12-16 16:45:51,856 - com.infogen.hdfs.InfoGen_LZOOutputStream -100104 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/21/1.4564576-
[framework] 2015-12-16 16:45:52,271 - com.infogen.hdfs.InfoGen_LZOOutputStream -100519 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/16/1.4722266-
[framework] 2015-12-16 16:45:52,365 - org.apache.hadoop.io.compress.CodecPool -100613 [main] INFO  org.apache.hadoop.io.compress.CodecPool  - Got brand-new compressor [.lzo]
[framework] 2015-12-16 16:45:52,439 - com.infogen.hdfs.InfoGen_LZOOutputStream -100687 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/22/1.4564647-
[framework] 2015-12-16 16:45:52,930 - com.infogen.hdfs.InfoGen_LZOOutputStream -101178 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-6/23/1.4564718-
[framework] 2015-12-16 16:45:53,297 - com.infogen.hdfs.InfoGen_LZOOutputStream -101545 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/0/1.4564777-
[framework] 2015-12-16 16:45:53,933 - com.infogen.hdfs.InfoGen_LZOOutputStream -102181 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/1/1.4564849-
[framework] 2015-12-16 16:45:54,362 - com.infogen.hdfs.InfoGen_LZOOutputStream -102610 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/2/1.4564922-
[framework] 2015-12-16 16:45:54,797 - com.infogen.hdfs.InfoGen_LZOOutputStream -103045 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/3/1.4564990-
[framework] 2015-12-16 16:45:55,196 - com.infogen.hdfs.InfoGen_LZOOutputStream -103444 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/4/1.4565069-
[framework] 2015-12-16 16:45:55,954 - com.infogen.hdfs.InfoGen_LZOOutputStream -104202 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/5/1.4565136-
[framework] 2015-12-16 16:45:56,339 - com.infogen.hdfs.InfoGen_LZOOutputStream -104587 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/6/1.4565207-
[framework] 2015-12-16 16:45:57,010 - com.infogen.hdfs.InfoGen_LZOOutputStream -105258 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/7/1.4565283-
[framework] 2015-12-16 16:45:57,530 - com.infogen.hdfs.InfoGen_LZOOutputStream -105778 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/8/1.4565737-
[framework] 2015-12-16 16:45:58,002 - com.infogen.hdfs.InfoGen_LZOOutputStream -106250 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/9/1.4565804-
[framework] 2015-12-16 16:45:58,495 - com.infogen.hdfs.InfoGen_LZOOutputStream -106743 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/10/1.4566067-
[framework] 2015-12-16 16:45:59,154 - com.infogen.hdfs.InfoGen_LZOOutputStream -107402 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/11/1.4566804-
[framework] 2015-12-16 16:46:00,188 - com.infogen.hdfs.InfoGen_LZOOutputStream -108436 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/12/1.4568307-
[framework] 2015-12-16 16:46:00,838 - com.infogen.hdfs.InfoGen_LZOOutputStream -109086 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/13/1.4568364-
[framework] 2015-12-16 16:46:01,709 - com.infogen.hdfs.InfoGen_LZOOutputStream -109957 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/14/1.4568555-
[framework] 2015-12-16 16:46:02,096 - com.infogen.hdfs.InfoGen_LZOOutputStream -110344 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/15/1.4569046-
[framework] 2015-12-16 16:46:02,470 - com.infogen.hdfs.InfoGen_LZOOutputStream -110718 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/16/1.4569858-
[framework] 2015-12-16 16:46:02,794 - com.infogen.hdfs.InfoGen_LZOOutputStream -111042 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/17/1.4571349-
[framework] 2015-12-16 16:46:03,442 - com.infogen.hdfs.InfoGen_LZOOutputStream -111690 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/18/1.4572295-
[framework] 2015-12-16 16:46:04,100 - com.infogen.hdfs.InfoGen_LZOOutputStream -112348 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/19/1.4572661-
[framework] 2015-12-16 16:46:04,858 - com.infogen.hdfs.InfoGen_LZOOutputStream -113106 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/20/1.4573839-
[framework] 2015-12-16 16:46:07,086 - com.infogen.hdfs.InfoGen_LZOOutputStream -115334 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/21/1.4574970-
[framework] 2015-12-16 16:46:07,643 - com.infogen.hdfs.InfoGen_LZOOutputStream -115891 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/22/1.4575096-
[framework] 2015-12-16 16:46:08,384 - com.infogen.hdfs.InfoGen_LZOOutputStream -116632 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-7/23/1.4575191-
[framework] 2015-12-16 16:46:09,009 - com.infogen.hdfs.InfoGen_LZOOutputStream -117257 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/0/1.4575261-
[framework] 2015-12-16 16:46:09,517 - com.infogen.hdfs.InfoGen_LZOOutputStream -117765 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/1/1.4575344-
[framework] 2015-12-16 16:46:10,015 - com.infogen.hdfs.InfoGen_LZOOutputStream -118263 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/2/1.4575427-
[framework] 2015-12-16 16:46:10,527 - com.infogen.hdfs.InfoGen_LZOOutputStream -118775 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/3/1.4575499-
[framework] 2015-12-16 16:46:10,892 - com.infogen.hdfs.InfoGen_LZOOutputStream -119140 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/4/1.4575564-
[framework] 2015-12-16 16:46:11,276 - com.infogen.hdfs.InfoGen_LZOOutputStream -119524 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/5/1.4575633-
[framework] 2015-12-16 16:46:11,651 - com.infogen.hdfs.InfoGen_LZOOutputStream -119899 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/6/1.4575685-
[framework] 2015-12-16 16:46:12,475 - com.infogen.hdfs.InfoGen_LZOOutputStream -120723 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/7/1.4575753-
[framework] 2015-12-16 16:46:12,893 - com.infogen.hdfs.InfoGen_LZOOutputStream -121141 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/8/1.4575824-
[framework] 2015-12-16 16:46:13,391 - com.infogen.hdfs.InfoGen_LZOOutputStream -121639 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/9/1.4575896-
[framework] 2015-12-16 16:46:14,000 - com.infogen.hdfs.InfoGen_LZOOutputStream -122248 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/10/1.4576268-
[framework] 2015-12-16 16:46:14,475 - com.infogen.hdfs.InfoGen_LZOOutputStream -122723 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/11/1.4577741-
[framework] 2015-12-16 16:46:15,147 - com.infogen.hdfs.InfoGen_LZOOutputStream -123395 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/12/1.4579671-
[framework] 2015-12-16 16:46:15,819 - com.infogen.hdfs.InfoGen_LZOOutputStream -124067 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/13/1.4580278-
[framework] 2015-12-16 16:46:16,827 - com.infogen.hdfs.InfoGen_LZOOutputStream -125075 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/14/1.4581029-
[framework] 2015-12-16 16:46:17,442 - com.infogen.hdfs.InfoGen_LZOOutputStream -125690 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/15/1.4582541-
[framework] 2015-12-16 16:46:17,990 - com.infogen.hdfs.InfoGen_LZOOutputStream -126238 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/16/1.4582968-
[framework] 2015-12-16 16:46:18,333 - com.infogen.hdfs.InfoGen_LZOOutputStream -126581 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/17/1.4585031-
[framework] 2015-12-16 16:46:19,113 - com.infogen.hdfs.InfoGen_LZOOutputStream -127361 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/18/1.4587331-
[framework] 2015-12-16 16:46:20,014 - com.infogen.hdfs.InfoGen_LZOOutputStream -128262 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/19/1.4588866-
[framework] 2015-12-16 16:46:20,504 - com.infogen.hdfs.InfoGen_LZOOutputStream -128752 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/20/1.4589188-
[framework] 2015-12-16 16:46:20,990 - com.infogen.hdfs.InfoGen_LZOOutputStream -129238 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/21/1.4589749-
[framework] 2015-12-16 16:46:21,398 - com.infogen.hdfs.InfoGen_LZOOutputStream -129646 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/22/1.4589854-
[framework] 2015-12-16 16:46:21,765 - com.infogen.hdfs.InfoGen_LZOOutputStream -130013 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-8/23/1.4589915-
[framework] 2015-12-16 16:46:22,164 - com.infogen.hdfs.InfoGen_LZOOutputStream -130412 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/0/1.4589999-
[framework] 2015-12-16 16:46:22,639 - com.infogen.hdfs.InfoGen_LZOOutputStream -130887 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/1/1.4590074-
[framework] 2015-12-16 16:46:23,223 - com.infogen.hdfs.InfoGen_LZOOutputStream -131471 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/2/1.4590145-
[framework] 2015-12-16 16:46:23,703 - com.infogen.hdfs.InfoGen_LZOOutputStream -131951 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/3/1.4590213-
[framework] 2015-12-16 16:46:24,090 - com.infogen.hdfs.InfoGen_LZOOutputStream -132338 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/4/1.4590293-
[framework] 2015-12-16 16:46:24,489 - com.infogen.hdfs.InfoGen_LZOOutputStream -132737 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/5/1.4590374-
[framework] 2015-12-16 16:46:24,862 - com.infogen.hdfs.InfoGen_LZOOutputStream -133110 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/6/1.4590443-
[framework] 2015-12-16 16:46:26,463 - com.infogen.hdfs.InfoGen_LZOOutputStream -134711 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/7/1.4590510-
[framework] 2015-12-16 16:46:26,846 - com.infogen.hdfs.InfoGen_LZOOutputStream -135094 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/8/1.4590588-
[framework] 2015-12-16 16:46:27,272 - com.infogen.hdfs.InfoGen_LZOOutputStream -135520 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/9/1.4590678-
[framework] 2015-12-16 16:46:28,812 - com.infogen.hdfs.InfoGen_LZOOutputStream -137060 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/10/1.4591359-
[framework] 2015-12-16 16:46:29,604 - com.infogen.hdfs.InfoGen_LZOOutputStream -137852 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/11/1.4592199-
[framework] 2015-12-16 16:46:30,005 - com.infogen.hdfs.InfoGen_LZOOutputStream -138253 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/12/1.4598713-
[framework] 2015-12-16 16:46:30,495 - com.infogen.hdfs.InfoGen_LZOOutputStream -138743 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/13/1.4607103-
[framework] 2015-12-16 16:46:31,051 - com.infogen.hdfs.InfoGen_LZOOutputStream -139299 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/14/1.4607328-
[framework] 2015-12-16 16:46:31,562 - com.infogen.hdfs.InfoGen_LZOOutputStream -139810 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/15/1.4609030-
[framework] 2015-12-16 16:46:32,162 - com.infogen.hdfs.InfoGen_LZOOutputStream -140410 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/16/1.4610729-
[framework] 2015-12-16 16:46:32,934 - com.infogen.hdfs.InfoGen_LZOOutputStream -141182 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/17/1.4612066-
[framework] 2015-12-16 16:46:33,446 - com.infogen.hdfs.InfoGen_LZOOutputStream -141694 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/18/1.4615863-
[framework] 2015-12-16 16:46:34,210 - com.infogen.hdfs.InfoGen_LZOOutputStream -142458 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/19/1.4617020-
[framework] 2015-12-16 16:46:34,818 - com.infogen.hdfs.InfoGen_LZOOutputStream -143066 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/20/1.4617965-
[framework] 2015-12-16 16:46:35,210 - com.infogen.hdfs.InfoGen_LZOOutputStream -143458 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/21/1.4620188-
[framework] 2015-12-16 16:46:35,663 - com.infogen.hdfs.InfoGen_LZOOutputStream -143911 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/22/1.4620689-
[framework] 2015-12-16 16:46:36,110 - com.infogen.hdfs.InfoGen_LZOOutputStream -144358 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-9/23/1.4620773-
[framework] 2015-12-16 16:46:36,527 - com.infogen.hdfs.InfoGen_LZOOutputStream -144775 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/0/1.4620850-
[framework] 2015-12-16 16:46:37,118 - com.infogen.hdfs.InfoGen_LZOOutputStream -145366 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/1/1.4620930-
[framework] 2015-12-16 16:46:37,557 - com.infogen.hdfs.InfoGen_LZOOutputStream -145805 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/2/1.4621001-
[framework] 2015-12-16 16:46:37,995 - com.infogen.hdfs.InfoGen_LZOOutputStream -146243 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/3/1.4621084-
[framework] 2015-12-16 16:46:38,701 - com.infogen.hdfs.InfoGen_LZOOutputStream -146949 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/4/1.4621160-
[framework] 2015-12-16 16:46:39,134 - com.infogen.hdfs.InfoGen_LZOOutputStream -147382 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/5/1.4621228-
[framework] 2015-12-16 16:46:39,652 - com.infogen.hdfs.InfoGen_LZOOutputStream -147900 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/6/1.4621302-
[framework] 2015-12-16 16:46:40,323 - com.infogen.hdfs.InfoGen_LZOOutputStream -148571 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/7/1.4621368-
[framework] 2015-12-16 16:46:40,914 - com.infogen.hdfs.InfoGen_LZOOutputStream -149162 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/8/1.4621464-
[framework] 2015-12-16 16:46:41,426 - com.infogen.hdfs.InfoGen_LZOOutputStream -149674 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/9/1.4621530-
[framework] 2015-12-16 16:46:41,950 - com.infogen.hdfs.InfoGen_LZOOutputStream -150198 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/10/1.4622142-
[framework] 2015-12-16 16:46:42,685 - com.infogen.hdfs.InfoGen_LZOOutputStream -150933 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/11/1.4624106-
[framework] 2015-12-16 16:46:43,159 - com.infogen.hdfs.InfoGen_LZOOutputStream -151407 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/12/1.4624990-
[framework] 2015-12-16 16:46:43,750 - com.infogen.hdfs.InfoGen_LZOOutputStream -151998 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/13/1.4625234-
[framework] 2015-12-16 16:46:44,492 - com.infogen.hdfs.InfoGen_LZOOutputStream -152740 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/14/1.4625383-
[framework] 2015-12-16 16:46:45,227 - com.infogen.hdfs.InfoGen_LZOOutputStream -153475 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/15/1.4626461-
[framework] 2015-12-16 16:46:46,091 - com.infogen.hdfs.InfoGen_LZOOutputStream -154339 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/16/1.4627515-
[framework] 2015-12-16 16:46:46,837 - com.infogen.hdfs.InfoGen_LZOOutputStream -155085 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/17/1.4631070-
[framework] 2015-12-16 16:46:47,415 - com.infogen.hdfs.InfoGen_LZOOutputStream -155663 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/18/1.4633530-
[framework] 2015-12-16 16:46:49,041 - com.infogen.hdfs.InfoGen_LZOOutputStream -157289 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/19/1.4634378-
[framework] 2015-12-16 16:46:49,565 - com.infogen.hdfs.InfoGen_LZOOutputStream -157813 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/20/1.4635058-
[framework] 2015-12-16 16:46:50,075 - com.infogen.hdfs.InfoGen_LZOOutputStream -158323 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/21/1.4636481-
[framework] 2015-12-16 16:46:50,644 - com.infogen.hdfs.InfoGen_LZOOutputStream -158892 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/22/1.4636584-
[framework] 2015-12-16 16:46:51,141 - com.infogen.hdfs.InfoGen_LZOOutputStream -159389 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-10/23/1.4636707-
[framework] 2015-12-16 16:46:51,632 - com.infogen.hdfs.InfoGen_LZOOutputStream -159880 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/0/1.4636869-
[framework] 2015-12-16 16:46:52,082 - com.infogen.hdfs.InfoGen_LZOOutputStream -160330 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/1/1.4636979-
[framework] 2015-12-16 16:46:52,824 - com.infogen.hdfs.InfoGen_LZOOutputStream -161072 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/2/1.4637102-
[framework] 2015-12-16 16:46:53,264 - com.infogen.hdfs.InfoGen_LZOOutputStream -161512 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/3/1.4637195-
[framework] 2015-12-16 16:46:53,960 - com.infogen.hdfs.InfoGen_LZOOutputStream -162208 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/4/1.4637295-
[framework] 2015-12-16 16:46:54,773 - com.infogen.hdfs.InfoGen_LZOOutputStream -163021 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/5/1.4637403-
[framework] 2015-12-16 16:46:55,322 - com.infogen.hdfs.InfoGen_LZOOutputStream -163570 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/6/1.4637515-
[framework] 2015-12-16 16:46:55,939 - com.infogen.hdfs.InfoGen_LZOOutputStream -164187 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/7/1.4637620-
[framework] 2015-12-16 16:46:56,630 - com.infogen.hdfs.InfoGen_LZOOutputStream -164878 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/8/1.4637739-
[framework] 2015-12-16 16:46:57,099 - com.infogen.hdfs.InfoGen_LZOOutputStream -165347 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/9/1.4637835-
[framework] 2015-12-16 16:46:57,688 - com.infogen.hdfs.InfoGen_LZOOutputStream -165936 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/10/1.4640398-
[framework] 2015-12-16 16:46:58,155 - com.infogen.hdfs.InfoGen_LZOOutputStream -166403 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/11/1.4641508-
[framework] 2015-12-16 16:46:58,771 - com.infogen.hdfs.InfoGen_LZOOutputStream -167019 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/12/1.4642517-
[framework] 2015-12-16 16:46:59,254 - com.infogen.hdfs.InfoGen_LZOOutputStream -167502 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/13/1.4642993-
[framework] 2015-12-16 16:46:59,918 - com.infogen.hdfs.InfoGen_LZOOutputStream -168166 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/14/1.4643091-
[framework] 2015-12-16 16:47:00,629 - com.infogen.hdfs.InfoGen_LZOOutputStream -168877 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/15/1.4643976-
[framework] 2015-12-16 16:47:01,295 - com.infogen.hdfs.InfoGen_LZOOutputStream -169543 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/16/1.4645519-
[framework] 2015-12-16 16:47:01,720 - com.infogen.hdfs.InfoGen_LZOOutputStream -169968 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/17/1.4646424-
[framework] 2015-12-16 16:47:03,170 - com.infogen.hdfs.InfoGen_LZOOutputStream -171418 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/18/1.4647149-
[framework] 2015-12-16 16:47:03,556 - com.infogen.hdfs.InfoGen_LZOOutputStream -171804 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/19/1.4647631-
[framework] 2015-12-16 16:47:04,069 - com.infogen.hdfs.InfoGen_LZOOutputStream -172317 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/20/1.4647912-
[framework] 2015-12-16 16:47:04,612 - com.infogen.hdfs.InfoGen_LZOOutputStream -172860 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/21/1.4648250-
[framework] 2015-12-16 16:47:05,228 - com.infogen.hdfs.InfoGen_LZOOutputStream -173476 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/22/1.4648375-
[framework] 2015-12-16 16:47:05,786 - com.infogen.hdfs.InfoGen_LZOOutputStream -174034 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-11/23/1.4648473-
[framework] 2015-12-16 16:47:06,661 - com.infogen.hdfs.InfoGen_LZOOutputStream -174909 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/0/1.4648564-
[framework] 2015-12-16 16:47:07,110 - com.infogen.hdfs.InfoGen_LZOOutputStream -175358 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/1/1.4648686-
[framework] 2015-12-16 16:47:07,645 - com.infogen.hdfs.InfoGen_LZOOutputStream -175893 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/2/1.4648924-
[framework] 2015-12-16 16:47:08,151 - com.infogen.hdfs.InfoGen_LZOOutputStream -176399 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/3/1.4649026-
[framework] 2015-12-16 16:47:08,859 - com.infogen.hdfs.InfoGen_LZOOutputStream -177107 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/4/1.4649144-
[framework] 2015-12-16 16:47:09,462 - com.infogen.hdfs.InfoGen_LZOOutputStream -177710 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/5/1.4649235-
[framework] 2015-12-16 16:47:09,948 - com.infogen.hdfs.InfoGen_LZOOutputStream -178196 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/6/1.4649318-
[framework] 2015-12-16 16:47:10,384 - com.infogen.hdfs.InfoGen_LZOOutputStream -178632 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/7/1.4649417-
[framework] 2015-12-16 16:47:10,867 - com.infogen.hdfs.InfoGen_LZOOutputStream -179115 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/8/1.4649531-
[framework] 2015-12-16 16:47:11,500 - com.infogen.hdfs.InfoGen_LZOOutputStream -179748 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/9/1.4649642-
[framework] 2015-12-16 16:47:12,025 - com.infogen.hdfs.InfoGen_LZOOutputStream -180273 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/10/1.4649819-
[framework] 2015-12-16 16:47:12,565 - com.infogen.hdfs.InfoGen_LZOOutputStream -180813 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/11/1.4649948-
[framework] 2015-12-16 16:47:13,325 - com.infogen.hdfs.InfoGen_LZOOutputStream -181573 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/12/1.4650386-
[framework] 2015-12-16 16:47:14,143 - com.infogen.hdfs.InfoGen_LZOOutputStream -182391 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/13/1.4650487-
[framework] 2015-12-16 16:47:14,893 - com.infogen.hdfs.InfoGen_LZOOutputStream -183141 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/14/1.4650934-
[framework] 2015-12-16 16:47:15,743 - com.infogen.hdfs.InfoGen_LZOOutputStream -183991 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/15/1.4651463-
[framework] 2015-12-16 16:47:16,290 - com.infogen.hdfs.InfoGen_LZOOutputStream -184538 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/16/1.4651929-
[framework] 2015-12-16 16:47:16,823 - com.infogen.hdfs.InfoGen_LZOOutputStream -185071 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/17/1.4652404-
[framework] 2015-12-16 16:47:17,308 - com.infogen.hdfs.InfoGen_LZOOutputStream -185556 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/18/1.4652890-
[framework] 2015-12-16 16:47:17,874 - com.infogen.hdfs.InfoGen_LZOOutputStream -186122 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/19/1.4653352-
[framework] 2015-12-16 16:47:18,381 - com.infogen.hdfs.InfoGen_LZOOutputStream -186629 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/20/1.4653823-
[framework] 2015-12-16 16:47:18,848 - com.infogen.hdfs.InfoGen_LZOOutputStream -187096 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/21/1.4654280-
[framework] 2015-12-16 16:47:19,498 - com.infogen.hdfs.InfoGen_LZOOutputStream -187746 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/22/1.4654706-
[framework] 2015-12-16 16:47:20,014 - com.infogen.hdfs.InfoGen_LZOOutputStream -188262 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-12/23/1.4655178-
[framework] 2015-12-16 16:47:21,031 - com.infogen.hdfs.InfoGen_LZOOutputStream -189279 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/0/1.4655637-
[framework] 2015-12-16 16:47:21,489 - com.infogen.hdfs.InfoGen_LZOOutputStream -189737 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/1/1.4656126-
[framework] 2015-12-16 16:47:22,014 - com.infogen.hdfs.InfoGen_LZOOutputStream -190262 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/2/1.4656585-
[framework] 2015-12-16 16:47:22,530 - com.infogen.hdfs.InfoGen_LZOOutputStream -190778 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/3/1.4657052-
[framework] 2015-12-16 16:47:22,972 - com.infogen.hdfs.InfoGen_LZOOutputStream -191220 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/4/1.4657528-
[framework] 2015-12-16 16:47:23,689 - com.infogen.hdfs.InfoGen_LZOOutputStream -191937 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/5/1.4657998-
[framework] 2015-12-16 16:47:24,189 - com.infogen.hdfs.InfoGen_LZOOutputStream -192437 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/6/1.4658458-
[framework] 2015-12-16 16:47:24,836 - com.infogen.hdfs.InfoGen_LZOOutputStream -193084 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/7/1.4658906-
[framework] 2015-12-16 16:47:25,505 - com.infogen.hdfs.InfoGen_LZOOutputStream -193753 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/8/1.4659342-
[framework] 2015-12-16 16:47:26,137 - com.infogen.hdfs.InfoGen_LZOOutputStream -194385 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/9/1.4659780-
[framework] 2015-12-16 16:47:26,685 - com.infogen.hdfs.InfoGen_LZOOutputStream -194933 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/10/1.4660189-
[framework] 2015-12-16 16:47:27,388 - com.infogen.hdfs.InfoGen_LZOOutputStream -195636 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/11/1.4660643-
[framework] 2015-12-16 16:47:28,156 - com.infogen.hdfs.InfoGen_LZOOutputStream -196404 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/12/1.4661127-
[framework] 2015-12-16 16:47:29,019 - com.infogen.hdfs.InfoGen_LZOOutputStream -197267 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/13/1.4661583-
[framework] 2015-12-16 16:47:29,770 - com.infogen.hdfs.InfoGen_LZOOutputStream -198018 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/14/1.4662035-
[framework] 2015-12-16 16:47:30,516 - com.infogen.hdfs.InfoGen_LZOOutputStream -198764 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/15/1.4662497-
[framework] 2015-12-16 16:47:31,375 - com.infogen.hdfs.InfoGen_LZOOutputStream -199623 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/16/1.4662984-
[framework] 2015-12-16 16:47:32,291 - com.infogen.hdfs.InfoGen_LZOOutputStream -200539 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/17/1.4663432-
[framework] 2015-12-16 16:47:32,889 - com.infogen.hdfs.InfoGen_LZOOutputStream -201137 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/18/1.4663907-
[framework] 2015-12-16 16:47:33,494 - com.infogen.hdfs.InfoGen_LZOOutputStream -201742 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/19/1.4664383-
[framework] 2015-12-16 16:47:34,363 - com.infogen.hdfs.InfoGen_LZOOutputStream -202611 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/20/1.4664841-
[framework] 2015-12-16 16:47:35,018 - com.infogen.hdfs.InfoGen_LZOOutputStream -203266 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/21/1.4665351-
[framework] 2015-12-16 16:47:35,574 - com.infogen.hdfs.InfoGen_LZOOutputStream -203822 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/22/1.4665807-
[framework] 2015-12-16 16:47:36,108 - com.infogen.hdfs.InfoGen_LZOOutputStream -204356 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-13/23/1.4666298-
[framework] 2015-12-16 16:47:36,934 - com.infogen.hdfs.InfoGen_LZOOutputStream -205182 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/0/1.4666804-
[framework] 2015-12-16 16:47:37,799 - com.infogen.hdfs.InfoGen_LZOOutputStream -206047 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/1/1.4666925-
[framework] 2015-12-16 16:47:38,363 - com.infogen.hdfs.InfoGen_LZOOutputStream -206611 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/2/1.4667039-
[framework] 2015-12-16 16:47:39,073 - com.infogen.hdfs.InfoGen_LZOOutputStream -207321 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/3/1.4667142-
[framework] 2015-12-16 16:47:39,646 - com.infogen.hdfs.InfoGen_LZOOutputStream -207894 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/4/1.4667238-
[framework] 2015-12-16 16:47:40,301 - com.infogen.hdfs.InfoGen_LZOOutputStream -208549 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/5/1.4667349-
[framework] 2015-12-16 16:47:40,899 - com.infogen.hdfs.InfoGen_LZOOutputStream -209147 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/6/1.4667455-
[framework] 2015-12-16 16:47:41,340 - com.infogen.hdfs.InfoGen_LZOOutputStream -209588 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/7/1.4667561-
[framework] 2015-12-16 16:47:41,942 - com.infogen.hdfs.InfoGen_LZOOutputStream -210190 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/8/1.4667656-
[framework] 2015-12-16 16:47:42,718 - com.infogen.hdfs.InfoGen_LZOOutputStream -210966 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/9/1.4667779-
[framework] 2015-12-16 16:47:43,484 - com.infogen.hdfs.InfoGen_LZOOutputStream -211732 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/10/1.4668127-
[framework] 2015-12-16 16:47:44,015 - com.infogen.hdfs.InfoGen_LZOOutputStream -212263 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/11/1.4669620-
[framework] 2015-12-16 16:47:44,588 - com.infogen.hdfs.InfoGen_LZOOutputStream -212836 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/12/1.4670920-
[framework] 2015-12-16 16:47:45,239 - com.infogen.hdfs.InfoGen_LZOOutputStream -213487 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/13/1.4671122-
[framework] 2015-12-16 16:47:45,889 - com.infogen.hdfs.InfoGen_LZOOutputStream -214137 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/14/1.4671387-
[framework] 2015-12-16 16:47:46,588 - com.infogen.hdfs.InfoGen_LZOOutputStream -214836 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/15/1.4672445-
[framework] 2015-12-16 16:47:47,196 - com.infogen.hdfs.InfoGen_LZOOutputStream -215444 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/16/1.4673373-
[framework] 2015-12-16 16:47:47,771 - com.infogen.hdfs.InfoGen_LZOOutputStream -216019 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/17/1.4674986-
[framework] 2015-12-16 16:47:48,327 - com.infogen.hdfs.InfoGen_LZOOutputStream -216575 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/18/1.4676179-
[framework] 2015-12-16 16:47:48,868 - com.infogen.hdfs.InfoGen_LZOOutputStream -217116 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/19/1.4676845-
[framework] 2015-12-16 16:47:49,487 - com.infogen.hdfs.InfoGen_LZOOutputStream -217735 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/20/1.4677290-
[framework] 2015-12-16 16:47:49,968 - com.infogen.hdfs.InfoGen_LZOOutputStream -218216 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/21/1.4677307-
[framework] 2015-12-16 16:47:51,537 - com.infogen.hdfs.InfoGen_LZOOutputStream -219785 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/22/1.4677326-
[framework] 2015-12-16 16:47:51,953 - com.infogen.hdfs.InfoGen_LZOOutputStream -220201 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-14/23/1.4677341-
[framework] 2015-12-16 16:47:52,434 - com.infogen.hdfs.InfoGen_LZOOutputStream -220682 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/0/1.4677357-
[framework] 2015-12-16 16:47:53,295 - com.infogen.hdfs.InfoGen_LZOOutputStream -221543 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/1/1.4677368-
[framework] 2015-12-16 16:47:53,845 - com.infogen.hdfs.InfoGen_LZOOutputStream -222093 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/2/1.4677381-
[framework] 2015-12-16 16:47:54,278 - com.infogen.hdfs.InfoGen_LZOOutputStream -222526 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/3/1.4677382-
[framework] 2015-12-16 16:47:54,811 - com.infogen.hdfs.InfoGen_LZOOutputStream -223059 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/4/1.4677384-
[framework] 2015-12-16 16:47:55,267 - com.infogen.hdfs.InfoGen_LZOOutputStream -223515 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/5/1.4677388-
[framework] 2015-12-16 16:47:55,820 - com.infogen.hdfs.InfoGen_LZOOutputStream -224068 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/6/1.4677391-
[framework] 2015-12-16 16:47:56,302 - com.infogen.hdfs.InfoGen_LZOOutputStream -224550 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/7/1.4677399-
[framework] 2015-12-16 16:47:56,816 - com.infogen.hdfs.InfoGen_LZOOutputStream -225064 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/8/1.4696450-
[framework] 2015-12-16 16:47:57,344 - com.infogen.hdfs.InfoGen_LZOOutputStream -225592 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/9/1.4696461-
[framework] 2015-12-16 16:47:57,874 - com.infogen.hdfs.InfoGen_LZOOutputStream -226122 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/10/1.4696706-
[framework] 2015-12-16 16:47:58,361 - com.infogen.hdfs.InfoGen_LZOOutputStream -226609 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/11/1.4697276-
[framework] 2015-12-16 16:47:58,960 - com.infogen.hdfs.InfoGen_LZOOutputStream -227208 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/12/1.4697778-
[framework] 2015-12-16 16:47:59,515 - com.infogen.hdfs.InfoGen_LZOOutputStream -227763 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/13/1.4697788-
[framework] 2015-12-16 16:48:00,007 - com.infogen.hdfs.InfoGen_LZOOutputStream -228255 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/14/1.4697852-
[framework] 2015-12-16 16:48:00,493 - com.infogen.hdfs.InfoGen_LZOOutputStream -228741 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/15/1.4698772-
[framework] 2015-12-16 16:48:00,903 - com.infogen.hdfs.InfoGen_LZOOutputStream -229151 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/16/1.4699134-
[framework] 2015-12-16 16:48:01,409 - com.infogen.hdfs.InfoGen_LZOOutputStream -229657 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/17/1.4699701-
[framework] 2015-12-16 16:48:02,284 - com.infogen.hdfs.InfoGen_LZOOutputStream -230532 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/18/1.4700757-
[framework] 2015-12-16 16:48:03,001 - com.infogen.hdfs.InfoGen_LZOOutputStream -231249 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/19/1.4700822-
[framework] 2015-12-16 16:48:03,542 - com.infogen.hdfs.InfoGen_LZOOutputStream -231790 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/20/1.4700869-
[framework] 2015-12-16 16:48:04,083 - com.infogen.hdfs.InfoGen_LZOOutputStream -232331 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/21/1.4701062-
[framework] 2015-12-16 16:48:04,629 - com.infogen.hdfs.InfoGen_LZOOutputStream -232877 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/22/1.4701299-
[framework] 2015-12-16 16:48:05,206 - com.infogen.hdfs.InfoGen_LZOOutputStream -233454 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-15/23/1.4701320-
[framework] 2015-12-16 16:48:05,992 - com.infogen.hdfs.InfoGen_LZOOutputStream -234240 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/0/1.4701342-
[framework] 2015-12-16 16:48:06,485 - com.infogen.hdfs.InfoGen_LZOOutputStream -234733 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/1/1.4701376-
[framework] 2015-12-16 16:48:07,263 - com.infogen.hdfs.InfoGen_LZOOutputStream -235511 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/3/1.4701379-
[framework] 2015-12-16 16:48:07,724 - com.infogen.hdfs.InfoGen_LZOOutputStream -235972 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/4/1.4701384-
[framework] 2015-12-16 16:48:08,258 - com.infogen.hdfs.InfoGen_LZOOutputStream -236506 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/5/1.4701388-
[framework] 2015-12-16 16:48:09,290 - com.infogen.hdfs.InfoGen_LZOOutputStream -237538 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/7/1.4701390-
[framework] 2015-12-16 16:48:09,875 - com.infogen.hdfs.InfoGen_LZOOutputStream -238123 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/8/1.4718588-
[framework] 2015-12-16 16:48:10,482 - com.infogen.hdfs.InfoGen_LZOOutputStream -238730 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/9/1.4718595-
[framework] 2015-12-16 16:48:11,190 - com.infogen.hdfs.InfoGen_LZOOutputStream -239438 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/10/1.4719035-
[framework] 2015-12-16 16:48:12,973 - com.infogen.hdfs.InfoGen_LZOOutputStream -241221 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/11/1.4719530-
[framework] 2015-12-16 16:48:13,687 - com.infogen.hdfs.InfoGen_LZOOutputStream -241935 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/12/1.4719752-
[framework] 2015-12-16 16:48:14,120 - com.infogen.hdfs.InfoGen_LZOOutputStream -242368 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/13/1.4719857-
[framework] 2015-12-16 16:48:14,562 - com.infogen.hdfs.InfoGen_LZOOutputStream -242810 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/14/1.4719988-
[framework] 2015-12-16 16:48:15,147 - com.infogen.hdfs.InfoGen_LZOOutputStream -243395 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/15/1.4720405-
[framework] 2015-12-16 16:48:16,691 - com.infogen.hdfs.InfoGen_LZOOutputStream -244939 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/16/1.4722266-
[framework] 2015-12-16 16:48:26,102 - com.infogen.hdfs.InfoGen_LZOOutputStream -254350 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/16/1.4722983-
[framework] 2015-12-16 16:49:26,056 - com.infogen.hdfs.InfoGen_LZOOutputStream -314304 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/16/1.4722983-
[framework] 2015-12-16 16:49:26,587 - com.infogen.hdfs.InfoGen_LZOOutputStream -314835 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/16/1.4723000-
[framework] 2015-12-16 16:50:26,543 - com.infogen.hdfs.InfoGen_LZOOutputStream -374791 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/16/1.4723000-
[framework] 2015-12-16 16:50:36,693 - com.infogen.hdfs.InfoGen_LZOOutputStream -384941 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/16/1.4723014-
[framework] 2015-12-16 16:51:36,642 - com.infogen.hdfs.InfoGen_LZOOutputStream -444890 [Thread-0] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #关闭流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/16/1.4723014-
[framework] 2015-12-16 16:51:37,428 - com.infogen.hdfs.InfoGen_LZOOutputStream -445676 [main] INFO  com.infogen.hdfs.InfoGen_LZOOutputStream  - #创建流-写入LZO文件并使用索引:hdfs://spark101:8020/infogen/output/infogen_topic_tracking/2015-12-16/16/1.4723030-
[framework] 2015-12-17 17:50:03,144 - com.infogen.etl.MemoryStats -1    [main] INFO  com.infogen.etl.MemoryStats  - anull
